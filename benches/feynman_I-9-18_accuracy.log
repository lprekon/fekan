83d17905575e6a3faabe350f707955336d8e8c31
Using arguments Cli { command: Build(BuildArgs { model_type: Regressor(RegressorArgs { labels: None, params: GenericBuildParams { degree: 3, num_coefficients: 4, hidden_layer_sizes: Some([4, 2, 1]), training_parameters: TrainArgs { data_file: "/tmp/tmp.RvFHk1bRcY.json", num_epochs: 500, knot_update_interval: 100, knot_adaptivity: 0.1, learning_rate: 0.001, knot_extension_targets: Some([10, 20, 50]), knot_extension_times: Some([50, 100, 250]), validate_each_epoch: true, validation_split: 0.2, model_output_file: None, no_save: true } } }) }), log_output: true, num_threads: None }
Thread count not specified. Using 16 threads
Loading regression data from file: "/tmp/tmp.RvFHk1bRcY.json"
creating validation set
Data loaded. Training: 80000, Validation: 20000
2024-07-24 21:30:55.271846241 +00:00 Epoch 1: Training Loss: 42.675499761567345, Validation Loss: 16.896211625949743
2024-07-24 21:30:55.715379690 +00:00 Epoch 2: Training Loss: 42.637938916201826, Validation Loss: 16.86124949654539
2024-07-24 21:30:56.153264672 +00:00 Epoch 3: Training Loss: 42.61043162337656, Validation Loss: 16.83505531618707
2024-07-24 21:30:56.587940503 +00:00 Epoch 4: Training Loss: 42.58976873264191, Validation Loss: 16.815217053571153
2024-07-24 21:30:57.030440071 +00:00 Epoch 5: Training Loss: 42.57427648099665, Validation Loss: 16.799975163192638
2024-07-24 21:30:57.454183738 +00:00 Epoch 6: Training Loss: 42.562642127218425, Validation Loss: 16.787874724938977
2024-07-24 21:30:57.889952379 +00:00 Epoch 7: Training Loss: 42.55387756081831, Validation Loss: 16.777908323657677
2024-07-24 21:30:58.328648164 +00:00 Epoch 8: Training Loss: 42.5472471044451, Validation Loss: 16.769537636188694
2024-07-24 21:30:58.757325096 +00:00 Epoch 9: Training Loss: 42.54235273782772, Validation Loss: 16.762149120136836
2024-07-24 21:30:59.180303777 +00:00 Epoch 10: Training Loss: 42.53878586787006, Validation Loss: 16.75543708786818
2024-07-24 21:30:59.604556844 +00:00 Epoch 11: Training Loss: 42.53645110570795, Validation Loss: 16.748914822753516
2024-07-24 21:31:00.027796388 +00:00 Epoch 12: Training Loss: 42.53534500368333, Validation Loss: 16.74223501171537
2024-07-24 21:31:00.461508468 +00:00 Epoch 13: Training Loss: 42.53535838635065, Validation Loss: 16.73594429232435
2024-07-24 21:31:00.892062901 +00:00 Epoch 14: Training Loss: 42.53701129532482, Validation Loss: 16.731838497145706
2024-07-24 21:31:01.313228441 +00:00 Epoch 15: Training Loss: 42.54181596759641, Validation Loss: 16.734330770274127
2024-07-24 21:31:01.742073074 +00:00 Epoch 16: Training Loss: 42.54822151520417, Validation Loss: 16.73678401087933
2024-07-24 21:31:02.174056323 +00:00 Epoch 17: Training Loss: 42.55028458440418, Validation Loss: 16.723434013741596
2024-07-24 21:31:02.604710702 +00:00 Epoch 18: Training Loss: 42.54439704657968, Validation Loss: 16.70533600586652
2024-07-24 21:31:03.028847167 +00:00 Epoch 19: Training Loss: 42.540036616459375, Validation Loss: 16.695446410808064
2024-07-24 21:31:03.460486548 +00:00 Epoch 20: Training Loss: 42.53717448680908, Validation Loss: 16.672681543657756
2024-07-24 21:31:03.886923093 +00:00 Epoch 21: Training Loss: 42.53323981388002, Validation Loss: 16.681078980478713
2024-07-24 21:31:04.308507291 +00:00 Epoch 22: Training Loss: 42.54581238137294, Validation Loss: 16.6991925482721
2024-07-24 21:31:04.728067648 +00:00 Epoch 23: Training Loss: 42.540104545619414, Validation Loss: 16.671518188514856
2024-07-24 21:31:05.153855555 +00:00 Epoch 24: Training Loss: 42.53405514338486, Validation Loss: 16.66538964983059
2024-07-24 21:31:05.584267441 +00:00 Epoch 25: Training Loss: 42.5226309371381, Validation Loss: 16.67050368161698
2024-07-24 21:31:06.015959528 +00:00 Epoch 26: Training Loss: 42.54546175349266, Validation Loss: 16.67521953207526
2024-07-24 21:31:06.440114563 +00:00 Epoch 27: Training Loss: 42.536060145641244, Validation Loss: 16.676188900809066
2024-07-24 21:31:06.865272032 +00:00 Epoch 28: Training Loss: 42.562022076409704, Validation Loss: 16.725176533907952
2024-07-24 21:31:07.285595511 +00:00 Epoch 29: Training Loss: 42.54755276249146, Validation Loss: 16.717568801040553
2024-07-24 21:31:07.710229017 +00:00 Epoch 30: Training Loss: 42.54000544438159, Validation Loss: 16.714655067484394
2024-07-24 21:31:08.147079295 +00:00 Epoch 31: Training Loss: 42.53643414430738, Validation Loss: 16.70971739662711
2024-07-24 21:31:08.565891090 +00:00 Epoch 32: Training Loss: 42.53374926744523, Validation Loss: 16.70154457300869
2024-07-24 21:31:08.991869388 +00:00 Epoch 33: Training Loss: 42.52942311731095, Validation Loss: 16.689840085049696
2024-07-24 21:31:09.407338350 +00:00 Epoch 34: Training Loss: 42.530577176931736, Validation Loss: 16.67678684288565
2024-07-24 21:31:09.830933364 +00:00 Epoch 35: Training Loss: 42.52469301271414, Validation Loss: 16.67068966343397
2024-07-24 21:31:10.263015098 +00:00 Epoch 36: Training Loss: 42.544600597268364, Validation Loss: 16.67245283982047
2024-07-24 21:31:10.696207920 +00:00 Epoch 37: Training Loss: 42.558035187462266, Validation Loss: 16.671254471063033
2024-07-24 21:31:11.120785893 +00:00 Epoch 38: Training Loss: 42.521237553750396, Validation Loss: 16.67189922173224
2024-07-24 21:31:11.535074627 +00:00 Epoch 39: Training Loss: 42.5166840280991, Validation Loss: 16.668939887912458
2024-07-24 21:31:11.954309626 +00:00 Epoch 40: Training Loss: 42.53788608522092, Validation Loss: 16.66271653827877
2024-07-24 21:31:12.383721626 +00:00 Epoch 41: Training Loss: 42.51436630729688, Validation Loss: 16.66701379337551
2024-07-24 21:31:12.819919889 +00:00 Epoch 42: Training Loss: 42.51984590519822, Validation Loss: 16.673427823421687
2024-07-24 21:31:13.243100708 +00:00 Epoch 43: Training Loss: 42.55069952957607, Validation Loss: 16.677800515177395
2024-07-24 21:31:13.664930560 +00:00 Epoch 44: Training Loss: 42.52391091207239, Validation Loss: 16.674659595410233
2024-07-24 21:31:14.084948660 +00:00 Epoch 45: Training Loss: 42.53166196825647, Validation Loss: 16.683462571659287
2024-07-24 21:31:14.513070987 +00:00 Epoch 46: Training Loss: 42.559018281669566, Validation Loss: 16.704896907540906
2024-07-24 21:31:14.941954196 +00:00 Epoch 47: Training Loss: 42.51892860579401, Validation Loss: 16.66978792533198
2024-07-24 21:31:15.372128281 +00:00 Epoch 48: Training Loss: 42.5169245084786, Validation Loss: 16.66936397776876
2024-07-24 21:31:15.799601921 +00:00 Epoch 49: Training Loss: 42.52113555424279, Validation Loss: 16.664323916455817
2024-07-24 21:31:16.217565104 +00:00 Epoch 50: Training Loss: 42.52347391210564, Validation Loss: 16.674916929535996
2024-07-24 21:31:16.218624097 +00:00 Extending knot vectors from 8 to 10
2024-07-24 21:31:16.808546406 +00:00 Epoch 51: Training Loss: 42.522290265008735, Validation Loss: 16.665585089973977
2024-07-24 21:31:17.406629728 +00:00 Epoch 52: Training Loss: 42.52723679654821, Validation Loss: 16.66717409876686
2024-07-24 21:31:17.993783089 +00:00 Epoch 53: Training Loss: 42.51496013681578, Validation Loss: 16.66436968506049
2024-07-24 21:31:18.580359151 +00:00 Epoch 54: Training Loss: 42.544396758308324, Validation Loss: 16.6795865873379
2024-07-24 21:31:19.156451754 +00:00 Epoch 55: Training Loss: 42.51276352968288, Validation Loss: 16.665743551173613
2024-07-24 21:31:19.757617519 +00:00 Epoch 56: Training Loss: 42.54344549220098, Validation Loss: 16.671523556689046
2024-07-24 21:31:20.353586434 +00:00 Epoch 57: Training Loss: 42.518935363611305, Validation Loss: 16.665410174441398
2024-07-24 21:31:20.947615225 +00:00 Epoch 58: Training Loss: 42.53515601886088, Validation Loss: 16.679337874889637
2024-07-24 21:31:21.537280604 +00:00 Epoch 59: Training Loss: 42.57343258060915, Validation Loss: 16.688819223124998
2024-07-24 21:31:22.124338750 +00:00 Epoch 60: Training Loss: 42.51430358158755, Validation Loss: 16.659719866453372
2024-07-24 21:31:22.712045080 +00:00 Epoch 61: Training Loss: 42.52506129593941, Validation Loss: 16.66725591414385
2024-07-24 21:31:23.302948444 +00:00 Epoch 62: Training Loss: 42.52468247928249, Validation Loss: 16.660555730259166
2024-07-24 21:31:23.887928716 +00:00 Epoch 63: Training Loss: 42.54616066338272, Validation Loss: 16.65764165418165
2024-07-24 21:31:24.474413829 +00:00 Epoch 64: Training Loss: 42.51186230900648, Validation Loss: 16.666133887778326
2024-07-24 21:31:25.065598533 +00:00 Epoch 65: Training Loss: 42.51765312341674, Validation Loss: 16.670547068132418
2024-07-24 21:31:25.659580034 +00:00 Epoch 66: Training Loss: 42.524146321336865, Validation Loss: 16.662760169495737
2024-07-24 21:31:26.250382311 +00:00 Epoch 67: Training Loss: 42.53692472901791, Validation Loss: 16.667822002972134
2024-07-24 21:31:26.844475452 +00:00 Epoch 68: Training Loss: 42.52479569834337, Validation Loss: 16.676356838066848
2024-07-24 21:31:27.441643005 +00:00 Epoch 69: Training Loss: 42.51266286928833, Validation Loss: 16.662091068622445
2024-07-24 21:31:28.025430876 +00:00 Epoch 70: Training Loss: 42.51730050493447, Validation Loss: 16.663638840364392
2024-07-24 21:31:28.605951434 +00:00 Epoch 71: Training Loss: 42.52373508741661, Validation Loss: 16.65922279007117
2024-07-24 21:31:29.197037021 +00:00 Epoch 72: Training Loss: 42.50680283472207, Validation Loss: 16.662176643850955
2024-07-24 21:31:29.805869462 +00:00 Epoch 73: Training Loss: 42.523573356554174, Validation Loss: 16.679036479584312
2024-07-24 21:31:30.422560755 +00:00 Epoch 74: Training Loss: 42.52847069625916, Validation Loss: 16.714878016082626
2024-07-24 21:31:31.032361484 +00:00 Epoch 75: Training Loss: 42.51439664771087, Validation Loss: 16.71719882928551
2024-07-24 21:31:31.635620466 +00:00 Epoch 76: Training Loss: 42.51576586810209, Validation Loss: 16.667283325252797
2024-07-24 21:31:32.244652117 +00:00 Epoch 77: Training Loss: 42.50344353634147, Validation Loss: 16.663028839925282
2024-07-24 21:31:32.861070268 +00:00 Epoch 78: Training Loss: 42.52587224833232, Validation Loss: 16.663985999482158
2024-07-24 21:31:33.464822766 +00:00 Epoch 79: Training Loss: 42.54348021094315, Validation Loss: 16.66577161836812
2024-07-24 21:31:34.062334927 +00:00 Epoch 80: Training Loss: 42.51494170988585, Validation Loss: 16.664755407815356
2024-07-24 21:31:34.670152529 +00:00 Epoch 81: Training Loss: 42.51287447613145, Validation Loss: 16.662278129038388
2024-07-24 21:31:35.262412986 +00:00 Epoch 82: Training Loss: 42.52608251112017, Validation Loss: 16.743538798535372
2024-07-24 21:31:35.858645963 +00:00 Epoch 83: Training Loss: 42.573587620756115, Validation Loss: 16.744265106097366
2024-07-24 21:31:36.461165694 +00:00 Epoch 84: Training Loss: 42.54920889933079, Validation Loss: 16.671973601486496
2024-07-24 21:31:37.058698313 +00:00 Epoch 85: Training Loss: 42.52293737835403, Validation Loss: 16.666995095648506
2024-07-24 21:31:37.652403110 +00:00 Epoch 86: Training Loss: 42.533829674621785, Validation Loss: 16.67011128008402
2024-07-24 21:31:38.267801954 +00:00 Epoch 87: Training Loss: 42.51227572420014, Validation Loss: 16.664349591204527
2024-07-24 21:31:38.859406397 +00:00 Epoch 88: Training Loss: 42.50457258206269, Validation Loss: 16.66061763217111
2024-07-24 21:31:39.444960291 +00:00 Epoch 89: Training Loss: 42.51067501045485, Validation Loss: 16.670870164179803
2024-07-24 21:31:40.030238987 +00:00 Epoch 90: Training Loss: 42.51742188016334, Validation Loss: 16.70237511332239
2024-07-24 21:31:40.629728216 +00:00 Epoch 91: Training Loss: 42.56647337432744, Validation Loss: 16.734496704052418
2024-07-24 21:31:41.222132480 +00:00 Epoch 92: Training Loss: 42.545197458887145, Validation Loss: 16.6658923271471
2024-07-24 21:31:41.801786693 +00:00 Epoch 93: Training Loss: 42.51608070965899, Validation Loss: 16.66381611111499
2024-07-24 21:31:42.387247421 +00:00 Epoch 94: Training Loss: 42.532636139313986, Validation Loss: 16.672625108053253
2024-07-24 21:31:42.980482389 +00:00 Epoch 95: Training Loss: 42.52326500126984, Validation Loss: 16.66722766239898
2024-07-24 21:31:43.562886402 +00:00 Epoch 96: Training Loss: 42.51209199286611, Validation Loss: 16.701275917370026
2024-07-24 21:31:44.148013093 +00:00 Epoch 97: Training Loss: 42.505004344292075, Validation Loss: 16.685308188069456
2024-07-24 21:31:44.733852246 +00:00 Epoch 98: Training Loss: 42.502703538201864, Validation Loss: 16.661896873788454
2024-07-24 21:31:45.321597050 +00:00 Epoch 99: Training Loss: 42.50552254402342, Validation Loss: 16.676590276326067
2024-07-24 21:31:45.928605705 +00:00 Epoch 100: Training Loss: 42.509505038352486, Validation Loss: 16.66233106082881
2024-07-24 21:31:45.931536144 +00:00 Extending knot vectors from 10 to 20
2024-07-24 21:31:47.532204665 +00:00 Epoch 101: Training Loss: 42.55325155692865, Validation Loss: 16.682746126972496
2024-07-24 21:31:49.116871181 +00:00 Epoch 102: Training Loss: 42.556194368137305, Validation Loss: 16.670973807635903
2024-07-24 21:31:50.702868116 +00:00 Epoch 103: Training Loss: 42.558665827703415, Validation Loss: 16.667893261993928
2024-07-24 21:31:52.296560897 +00:00 Epoch 104: Training Loss: 42.58548724922007, Validation Loss: 16.706495600647408
2024-07-24 21:31:53.882168458 +00:00 Epoch 105: Training Loss: 42.536405398589835, Validation Loss: 16.69044297997424
2024-07-24 21:31:55.467986954 +00:00 Epoch 106: Training Loss: 42.53026086622431, Validation Loss: 16.690269715489634
2024-07-24 21:31:57.054030812 +00:00 Epoch 107: Training Loss: 42.52991660400293, Validation Loss: 16.688992675504668
2024-07-24 21:31:58.637517999 +00:00 Epoch 108: Training Loss: 42.53861129465929, Validation Loss: 16.678485120186735
2024-07-24 21:32:00.219880672 +00:00 Epoch 109: Training Loss: 42.53178055566999, Validation Loss: 16.701806091328415
2024-07-24 21:32:01.794118849 +00:00 Epoch 110: Training Loss: 42.610232232016195, Validation Loss: 16.763010049553177
2024-07-24 21:32:03.382063116 +00:00 Epoch 111: Training Loss: 42.56405756453923, Validation Loss: 16.74487655136512
2024-07-24 21:32:04.960299796 +00:00 Epoch 112: Training Loss: 42.55161912484588, Validation Loss: 16.725598467669297
2024-07-24 21:32:06.526428962 +00:00 Epoch 113: Training Loss: 42.537488815231505, Validation Loss: 16.703295706737077
2024-07-24 21:32:08.103084301 +00:00 Epoch 114: Training Loss: 42.531344631131276, Validation Loss: 16.70296437657094
2024-07-24 21:32:09.680803946 +00:00 Epoch 115: Training Loss: 42.529043855178216, Validation Loss: 16.708959616733868
2024-07-24 21:32:11.256629294 +00:00 Epoch 116: Training Loss: 42.52445061189837, Validation Loss: 16.70622408490682
2024-07-24 21:32:12.830460453 +00:00 Epoch 117: Training Loss: 42.52270968050509, Validation Loss: 16.70473232232024
2024-07-24 21:32:14.410118932 +00:00 Epoch 118: Training Loss: 42.52504884185707, Validation Loss: 16.69286627129195
2024-07-24 21:32:15.988417582 +00:00 Epoch 119: Training Loss: 42.529753596704566, Validation Loss: 16.689317357153815
2024-07-24 21:32:17.567724713 +00:00 Epoch 120: Training Loss: 42.528828683502965, Validation Loss: 16.68190409166972
2024-07-24 21:32:19.144061883 +00:00 Epoch 121: Training Loss: 42.53872598766725, Validation Loss: 16.67398211301984
2024-07-24 21:32:20.723348007 +00:00 Epoch 122: Training Loss: 42.51716669055642, Validation Loss: 16.68680494781633
2024-07-24 21:32:22.297664066 +00:00 Epoch 123: Training Loss: 42.5147883759462, Validation Loss: 16.682698090157924
2024-07-24 21:32:23.872961880 +00:00 Epoch 124: Training Loss: 42.52048843393195, Validation Loss: 16.692130477158567
2024-07-24 21:32:25.446692838 +00:00 Epoch 125: Training Loss: 42.55368724856274, Validation Loss: 16.70579691841482
2024-07-24 21:32:27.024337609 +00:00 Epoch 126: Training Loss: 42.53701726614783, Validation Loss: 16.660033521329822
2024-07-24 21:32:28.604878446 +00:00 Epoch 127: Training Loss: 42.51511088639144, Validation Loss: 16.66251641342426
2024-07-24 21:32:30.174634670 +00:00 Epoch 128: Training Loss: 42.531045686135585, Validation Loss: 16.660450367664815
2024-07-24 21:32:31.758721987 +00:00 Epoch 129: Training Loss: 42.535367984068266, Validation Loss: 16.669526780263563
2024-07-24 21:32:33.350340135 +00:00 Epoch 130: Training Loss: 42.53396001414674, Validation Loss: 16.66717348467432
2024-07-24 21:32:34.918508594 +00:00 Epoch 131: Training Loss: 42.54279046068057, Validation Loss: 16.66289953182769
2024-07-24 21:32:36.497908583 +00:00 Epoch 132: Training Loss: 42.5303348603099, Validation Loss: 16.6671207607507
2024-07-24 21:32:38.078623546 +00:00 Epoch 133: Training Loss: 42.54936992433604, Validation Loss: 16.661344239257453
2024-07-24 21:32:39.648669031 +00:00 Epoch 134: Training Loss: 42.531900408842446, Validation Loss: 16.697702153664803
2024-07-24 21:32:41.226386023 +00:00 Epoch 135: Training Loss: 42.57433485398939, Validation Loss: 16.716709343933804
2024-07-24 21:32:42.799340766 +00:00 Epoch 136: Training Loss: 42.539928626495815, Validation Loss: 16.70419199820618
2024-07-24 21:32:44.373040153 +00:00 Epoch 137: Training Loss: 42.52419555277038, Validation Loss: 16.691375910160275
2024-07-24 21:32:45.953162850 +00:00 Epoch 138: Training Loss: 42.5228459237426, Validation Loss: 16.694967148617184
2024-07-24 21:32:47.518769503 +00:00 Epoch 139: Training Loss: 42.52089998172118, Validation Loss: 16.69855376687201
2024-07-24 21:32:49.087522993 +00:00 Epoch 140: Training Loss: 42.519548155606884, Validation Loss: 16.700934209274887
2024-07-24 21:32:50.671837413 +00:00 Epoch 141: Training Loss: 42.519798780956954, Validation Loss: 16.703705340773666
2024-07-24 21:32:52.235316116 +00:00 Epoch 142: Training Loss: 42.52002924469059, Validation Loss: 16.698449346452698
2024-07-24 21:32:53.806996174 +00:00 Epoch 143: Training Loss: 42.52076648736919, Validation Loss: 16.691676609194626
2024-07-24 21:32:55.381599208 +00:00 Epoch 144: Training Loss: 42.51940839903013, Validation Loss: 16.692996769149655
2024-07-24 21:32:56.962185750 +00:00 Epoch 145: Training Loss: 42.518708396883035, Validation Loss: 16.68566608415157
2024-07-24 21:32:58.543281530 +00:00 Epoch 146: Training Loss: 42.5279737950368, Validation Loss: 16.669006256520994
2024-07-24 21:33:00.114987541 +00:00 Epoch 147: Training Loss: 42.5166590251721, Validation Loss: 16.671501295532877
2024-07-24 21:33:01.697663931 +00:00 Epoch 148: Training Loss: 42.504620584810105, Validation Loss: 16.672352250070496
2024-07-24 21:33:03.270440167 +00:00 Epoch 149: Training Loss: 42.52309887306587, Validation Loss: 16.6630477622402
2024-07-24 21:33:04.839810305 +00:00 Epoch 150: Training Loss: 42.50497418318637, Validation Loss: 16.66162245900834
2024-07-24 21:33:06.413119339 +00:00 Epoch 151: Training Loss: 42.50526619884834, Validation Loss: 16.676844181133834
2024-07-24 21:33:07.991002217 +00:00 Epoch 152: Training Loss: 42.50251614864308, Validation Loss: 16.677690080114637
2024-07-24 21:33:09.559205744 +00:00 Epoch 153: Training Loss: 42.50539430535916, Validation Loss: 16.668624974381807
2024-07-24 21:33:11.135717782 +00:00 Epoch 154: Training Loss: 42.52278276673715, Validation Loss: 16.662502861301174
2024-07-24 21:33:12.708709207 +00:00 Epoch 155: Training Loss: 42.51969690508144, Validation Loss: 16.69425752783912
2024-07-24 21:33:14.274150691 +00:00 Epoch 156: Training Loss: 42.55770113319196, Validation Loss: 16.706746829300116
2024-07-24 21:33:15.852253438 +00:00 Epoch 157: Training Loss: 42.52581432319981, Validation Loss: 16.697976074073228
2024-07-24 21:33:17.427717285 +00:00 Epoch 158: Training Loss: 42.51921837842285, Validation Loss: 16.695897678389123
2024-07-24 21:33:18.992405300 +00:00 Epoch 159: Training Loss: 42.515921666279844, Validation Loss: 16.693057148847757
2024-07-24 21:33:20.572537168 +00:00 Epoch 160: Training Loss: 42.51883804086803, Validation Loss: 16.678463594026056
2024-07-24 21:33:22.142188837 +00:00 Epoch 161: Training Loss: 42.52371285914347, Validation Loss: 16.662428366830444
2024-07-24 21:33:23.711066236 +00:00 Epoch 162: Training Loss: 42.523419118042426, Validation Loss: 16.662477708796125
2024-07-24 21:33:25.284453237 +00:00 Epoch 163: Training Loss: 42.50364002764002, Validation Loss: 16.662700580196688
2024-07-24 21:33:26.862846066 +00:00 Epoch 164: Training Loss: 42.51471410304736, Validation Loss: 16.676607328212313
2024-07-24 21:33:28.459237175 +00:00 Epoch 165: Training Loss: 42.51976204617121, Validation Loss: 16.680485362130298
2024-07-24 21:33:30.026676253 +00:00 Epoch 166: Training Loss: 42.53800920677749, Validation Loss: 16.68000401523763
2024-07-24 21:33:31.607281468 +00:00 Epoch 167: Training Loss: 42.52572495593224, Validation Loss: 16.694976496514208
2024-07-24 21:33:33.179322630 +00:00 Epoch 168: Training Loss: 42.541911122213385, Validation Loss: 16.69984327463027
2024-07-24 21:33:34.756396542 +00:00 Epoch 169: Training Loss: 42.520854580429656, Validation Loss: 16.691748310792974
2024-07-24 21:33:36.360944157 +00:00 Epoch 170: Training Loss: 42.51686659331771, Validation Loss: 16.689853072844034
2024-07-24 21:33:37.965759398 +00:00 Epoch 171: Training Loss: 42.51533167765556, Validation Loss: 16.69042378482064
2024-07-24 21:33:39.572392865 +00:00 Epoch 172: Training Loss: 42.51568809041045, Validation Loss: 16.687245459354177
2024-07-24 21:33:41.173525160 +00:00 Epoch 173: Training Loss: 42.51490802705069, Validation Loss: 16.68562657850234
2024-07-24 21:33:42.771346018 +00:00 Epoch 174: Training Loss: 42.51949851038847, Validation Loss: 16.677434809507986
2024-07-24 21:33:44.372934400 +00:00 Epoch 175: Training Loss: 42.516686470951356, Validation Loss: 16.665973756824208
2024-07-24 21:33:45.970244700 +00:00 Epoch 176: Training Loss: 42.514048462813385, Validation Loss: 16.664636826338278
2024-07-24 21:33:47.574317566 +00:00 Epoch 177: Training Loss: 42.522777192269096, Validation Loss: 16.663552207539045
2024-07-24 21:33:49.161615551 +00:00 Epoch 178: Training Loss: 42.508640608682285, Validation Loss: 16.688959083846626
2024-07-24 21:33:50.764050264 +00:00 Epoch 179: Training Loss: 42.52206392851434, Validation Loss: 16.6927402129592
2024-07-24 21:33:52.368729265 +00:00 Epoch 180: Training Loss: 42.51588309537962, Validation Loss: 16.68690073025027
2024-07-24 21:33:53.973180386 +00:00 Epoch 181: Training Loss: 42.51483300694271, Validation Loss: 16.683508516488796
2024-07-24 21:33:55.576475952 +00:00 Epoch 182: Training Loss: 42.5142700400639, Validation Loss: 16.688012553638785
2024-07-24 21:33:57.159175594 +00:00 Epoch 183: Training Loss: 42.5145394416264, Validation Loss: 16.686701147190572
2024-07-24 21:33:58.741372875 +00:00 Epoch 184: Training Loss: 42.516276774266544, Validation Loss: 16.6799162345576
2024-07-24 21:34:00.319450932 +00:00 Epoch 185: Training Loss: 42.51425606217047, Validation Loss: 16.680253414564316
2024-07-24 21:34:01.887619679 +00:00 Epoch 186: Training Loss: 42.50960418889731, Validation Loss: 16.66715582603756
2024-07-24 21:34:03.470719147 +00:00 Epoch 187: Training Loss: 42.52990647188898, Validation Loss: 16.6725889839844
2024-07-24 21:34:05.040893494 +00:00 Epoch 188: Training Loss: 42.51994420282472, Validation Loss: 16.672634372813555
2024-07-24 21:34:06.618309793 +00:00 Epoch 189: Training Loss: 42.491101581681214, Validation Loss: 16.666340526368426
2024-07-24 21:34:08.230195164 +00:00 Epoch 190: Training Loss: 42.49641043686625, Validation Loss: 16.661055627086814
2024-07-24 21:34:09.823270688 +00:00 Epoch 191: Training Loss: 42.49967284136081, Validation Loss: 16.662107197316782
2024-07-24 21:34:11.425102088 +00:00 Epoch 192: Training Loss: 42.505972369453566, Validation Loss: 16.667707947721397
2024-07-24 21:34:13.027403879 +00:00 Epoch 193: Training Loss: 42.52560869245591, Validation Loss: 16.673387872250725
2024-07-24 21:34:14.626210966 +00:00 Epoch 194: Training Loss: 42.51239060666701, Validation Loss: 16.662843385635732
2024-07-24 21:34:16.224306907 +00:00 Epoch 195: Training Loss: 42.51500023090558, Validation Loss: 16.66236586790749
2024-07-24 21:34:17.821086098 +00:00 Epoch 196: Training Loss: 42.5121949593285, Validation Loss: 16.661824961894318
2024-07-24 21:34:19.425389362 +00:00 Epoch 197: Training Loss: 42.51290194082812, Validation Loss: 16.679913678482478
2024-07-24 21:34:21.020924202 +00:00 Epoch 198: Training Loss: 42.49581011399002, Validation Loss: 16.675873479760888
2024-07-24 21:34:22.616273797 +00:00 Epoch 199: Training Loss: 42.505724127039805, Validation Loss: 16.665746824256384
2024-07-24 21:34:24.216384400 +00:00 Epoch 200: Training Loss: 42.515680437867665, Validation Loss: 16.66104819800187
2024-07-24 21:34:25.817129666 +00:00 Epoch 201: Training Loss: 42.50394160360264, Validation Loss: 16.71001747019722
2024-07-24 21:34:27.414147580 +00:00 Epoch 202: Training Loss: 42.528005664524365, Validation Loss: 16.69728573135179
2024-07-24 21:34:29.012289540 +00:00 Epoch 203: Training Loss: 42.51902140511404, Validation Loss: 16.691683556435052
2024-07-24 21:34:30.613406333 +00:00 Epoch 204: Training Loss: 42.512852556493286, Validation Loss: 16.688936156011156
2024-07-24 21:34:32.209310450 +00:00 Epoch 205: Training Loss: 42.51258214026344, Validation Loss: 16.686872868574223
2024-07-24 21:34:33.803949552 +00:00 Epoch 206: Training Loss: 42.51222838653019, Validation Loss: 16.68698208603811
2024-07-24 21:34:35.398931539 +00:00 Epoch 207: Training Loss: 42.512178305100925, Validation Loss: 16.68713088811881
2024-07-24 21:34:36.995281002 +00:00 Epoch 208: Training Loss: 42.5120865489058, Validation Loss: 16.687971640212716
2024-07-24 21:34:38.599714688 +00:00 Epoch 209: Training Loss: 42.51171732000405, Validation Loss: 16.687091222288135
2024-07-24 21:34:40.187514133 +00:00 Epoch 210: Training Loss: 42.510708110158824, Validation Loss: 16.68615628769499
2024-07-24 21:34:41.766338167 +00:00 Epoch 211: Training Loss: 42.51060815604154, Validation Loss: 16.68322434173484
2024-07-24 21:34:43.368067232 +00:00 Epoch 212: Training Loss: 42.50988991509132, Validation Loss: 16.686878449884134
2024-07-24 21:34:44.967192883 +00:00 Epoch 213: Training Loss: 42.51077116841755, Validation Loss: 16.681339872174824
2024-07-24 21:34:46.570016024 +00:00 Epoch 214: Training Loss: 42.512836941954696, Validation Loss: 16.668829457885984
2024-07-24 21:34:48.163800900 +00:00 Epoch 215: Training Loss: 42.511379727576646, Validation Loss: 16.676204958708524
2024-07-24 21:34:49.748996247 +00:00 Epoch 216: Training Loss: 42.51814564639565, Validation Loss: 16.66538292896836
2024-07-24 21:34:51.325053567 +00:00 Epoch 217: Training Loss: 42.50473308687132, Validation Loss: 16.665461736122214
2024-07-24 21:34:52.887770006 +00:00 Epoch 218: Training Loss: 42.51806831350239, Validation Loss: 16.66264921699617
2024-07-24 21:34:54.449446897 +00:00 Epoch 219: Training Loss: 42.49918937750628, Validation Loss: 16.66420008230096
2024-07-24 21:34:56.026322726 +00:00 Epoch 220: Training Loss: 42.500022523223684, Validation Loss: 16.669091315642756
2024-07-24 21:34:57.600187701 +00:00 Epoch 221: Training Loss: 42.51200721001658, Validation Loss: 16.680427119393723
2024-07-24 21:34:59.174563693 +00:00 Epoch 222: Training Loss: 42.51474563533598, Validation Loss: 16.680084184639348
2024-07-24 21:35:00.763426787 +00:00 Epoch 223: Training Loss: 42.511517811782554, Validation Loss: 16.6838269958612
2024-07-24 21:35:02.330767477 +00:00 Epoch 224: Training Loss: 42.5097039096871, Validation Loss: 16.683706159886764
2024-07-24 21:35:03.923541899 +00:00 Epoch 225: Training Loss: 42.51066440757294, Validation Loss: 16.679766966339166
2024-07-24 21:35:05.514439297 +00:00 Epoch 226: Training Loss: 42.511194741447056, Validation Loss: 16.665371638847105
2024-07-24 21:35:07.105137279 +00:00 Epoch 227: Training Loss: 42.49624402156631, Validation Loss: 16.663975459446757
2024-07-24 21:35:08.707089019 +00:00 Epoch 228: Training Loss: 42.49606039115329, Validation Loss: 16.665678722943653
2024-07-24 21:35:10.295236120 +00:00 Epoch 229: Training Loss: 42.50106154117117, Validation Loss: 16.662215310232384
2024-07-24 21:35:11.887539771 +00:00 Epoch 230: Training Loss: 42.509689119777754, Validation Loss: 16.66595211083281
2024-07-24 21:35:13.476900480 +00:00 Epoch 231: Training Loss: 42.516007912130235, Validation Loss: 16.685293156772335
2024-07-24 21:35:15.041329746 +00:00 Epoch 232: Training Loss: 42.5113689003869, Validation Loss: 16.679377997864073
2024-07-24 21:35:16.634122164 +00:00 Epoch 233: Training Loss: 42.511769776829276, Validation Loss: 16.675913202828717
2024-07-24 21:35:18.219342774 +00:00 Epoch 234: Training Loss: 42.50810993416858, Validation Loss: 16.679811075511527
2024-07-24 21:35:19.828392757 +00:00 Epoch 235: Training Loss: 42.50582732615064, Validation Loss: 16.66751971401684
2024-07-24 21:35:21.431049093 +00:00 Epoch 236: Training Loss: 42.51464948499944, Validation Loss: 16.665232591637665
2024-07-24 21:35:23.025301202 +00:00 Epoch 237: Training Loss: 42.515167832143085, Validation Loss: 16.66306115628578
2024-07-24 21:35:24.627399453 +00:00 Epoch 238: Training Loss: 42.498785034025495, Validation Loss: 16.68397777393866
2024-07-24 21:35:26.231150403 +00:00 Epoch 239: Training Loss: 42.526311648367596, Validation Loss: 16.698472450107307
2024-07-24 21:35:27.822588524 +00:00 Epoch 240: Training Loss: 42.51672059249797, Validation Loss: 16.692000181751634
2024-07-24 21:35:29.416992337 +00:00 Epoch 241: Training Loss: 42.512867956214556, Validation Loss: 16.690450270206902
2024-07-24 21:35:31.026462930 +00:00 Epoch 242: Training Loss: 42.51215543069488, Validation Loss: 16.688853802515936
2024-07-24 21:35:32.644445789 +00:00 Epoch 243: Training Loss: 42.51115508497815, Validation Loss: 16.686118530333413
2024-07-24 21:35:34.256213194 +00:00 Epoch 244: Training Loss: 42.51027654864949, Validation Loss: 16.68474329803641
2024-07-24 21:35:35.868778690 +00:00 Epoch 245: Training Loss: 42.51010379272001, Validation Loss: 16.684032609558773
2024-07-24 21:35:37.483325964 +00:00 Epoch 246: Training Loss: 42.50984190878581, Validation Loss: 16.684105348703262
2024-07-24 21:35:39.093499690 +00:00 Epoch 247: Training Loss: 42.50945563944853, Validation Loss: 16.684346960039008
2024-07-24 21:35:40.698829190 +00:00 Epoch 248: Training Loss: 42.50939678996152, Validation Loss: 16.685333883834225
2024-07-24 21:35:42.300801505 +00:00 Epoch 249: Training Loss: 42.50903790146132, Validation Loss: 16.68593475839485
2024-07-24 21:35:43.906533788 +00:00 Epoch 250: Training Loss: 42.50853044202816, Validation Loss: 16.68528040580039
2024-07-24 21:35:43.924212101 +00:00 Extending knot vectors from 20 to 50
2024-07-24 21:35:49.391974327 +00:00 Epoch 251: Training Loss: 42.53592872813601, Validation Loss: 16.739494685903598
2024-07-24 21:35:54.800511417 +00:00 Epoch 252: Training Loss: 42.529638355040184, Validation Loss: 16.739390562947523
2024-07-24 21:36:00.156451335 +00:00 Epoch 253: Training Loss: 42.52394900074477, Validation Loss: 16.735951059903336
2024-07-24 21:36:05.527871732 +00:00 Epoch 254: Training Loss: 42.522519172556905, Validation Loss: 16.730242967060715
2024-07-24 21:36:10.887374456 +00:00 Epoch 255: Training Loss: 42.520397871840544, Validation Loss: 16.73074976373354
2024-07-24 21:36:16.229864134 +00:00 Epoch 256: Training Loss: 42.5188894668985, Validation Loss: 16.723548900878335
2024-07-24 21:36:21.566658258 +00:00 Epoch 257: Training Loss: 42.516117047267564, Validation Loss: 16.72104094055306
2024-07-24 21:36:26.910730066 +00:00 Epoch 258: Training Loss: 42.5236139159348, Validation Loss: 16.717986626903244
2024-07-24 21:36:32.248868148 +00:00 Epoch 259: Training Loss: 42.515349942902176, Validation Loss: 16.71877380614714
2024-07-24 21:36:37.590650704 +00:00 Epoch 260: Training Loss: 42.51746556248395, Validation Loss: 16.696145599579893
2024-07-24 21:36:42.932488607 +00:00 Epoch 261: Training Loss: 42.5183210470092, Validation Loss: 16.686458713366928
2024-07-24 21:36:48.300386912 +00:00 Epoch 262: Training Loss: 42.537634913359234, Validation Loss: 16.7031916961991
2024-07-24 21:36:53.660531964 +00:00 Epoch 263: Training Loss: 42.54167640189053, Validation Loss: 16.68704521882475
2024-07-24 21:36:58.998652099 +00:00 Epoch 264: Training Loss: 42.53334008970053, Validation Loss: 16.67373716605127
2024-07-24 21:37:04.327112184 +00:00 Epoch 265: Training Loss: 42.53227626827003, Validation Loss: 16.66899163406561
2024-07-24 21:37:09.634931302 +00:00 Epoch 266: Training Loss: 42.52316963631666, Validation Loss: 16.67177151922815
2024-07-24 21:37:14.959221671 +00:00 Epoch 267: Training Loss: 42.54485537156237, Validation Loss: 16.903899707807916
2024-07-24 21:37:20.289660347 +00:00 Epoch 268: Training Loss: 42.632289211100634, Validation Loss: 16.77897628078132
2024-07-24 21:37:25.623242807 +00:00 Epoch 269: Training Loss: 42.59391529507195, Validation Loss: 16.73886721268701
2024-07-24 21:37:30.953669946 +00:00 Epoch 270: Training Loss: 42.56851067541082, Validation Loss: 16.700652704283666
2024-07-24 21:37:36.276753033 +00:00 Epoch 271: Training Loss: 42.55506867233329, Validation Loss: 16.69037788047545
2024-07-24 21:37:41.658759795 +00:00 Epoch 272: Training Loss: 42.54468857544252, Validation Loss: 16.683614924738304
2024-07-24 21:37:46.990295924 +00:00 Epoch 273: Training Loss: 42.54104304354487, Validation Loss: 16.68148650096426
2024-07-24 21:37:52.446422162 +00:00 Epoch 274: Training Loss: 42.5372793927918, Validation Loss: 16.679745440219286
2024-07-24 21:37:57.953054355 +00:00 Epoch 275: Training Loss: 42.53472191881778, Validation Loss: 16.67830898371109
2024-07-24 21:38:03.362303999 +00:00 Epoch 276: Training Loss: 42.53351580564936, Validation Loss: 16.676229970938923
2024-07-24 21:38:08.855973359 +00:00 Epoch 277: Training Loss: 42.53919052487195, Validation Loss: 16.672075792226
2024-07-24 21:38:14.305348263 +00:00 Epoch 278: Training Loss: 42.52919908269327, Validation Loss: 16.681583509792112
2024-07-24 21:38:19.757123442 +00:00 Epoch 279: Training Loss: 42.57492748099126, Validation Loss: 16.698680767778473
2024-07-24 21:38:25.216600837 +00:00 Epoch 280: Training Loss: 42.567098052985834, Validation Loss: 16.7069691024272
2024-07-24 21:38:30.647133968 +00:00 Epoch 281: Training Loss: 42.59120220756343, Validation Loss: 16.915294611647045
2024-07-24 21:38:36.096111226 +00:00 Epoch 282: Training Loss: 42.65983732484605, Validation Loss: 16.829437552556094
2024-07-24 21:38:41.517574801 +00:00 Epoch 283: Training Loss: 42.60325091708063, Validation Loss: 16.727023129023095
2024-07-24 21:38:46.966322417 +00:00 Epoch 284: Training Loss: 42.56779002469591, Validation Loss: 16.721172514488295
2024-07-24 21:38:52.414417090 +00:00 Epoch 285: Training Loss: 42.539749283000575, Validation Loss: 16.694874711424923
2024-07-24 21:38:57.851922314 +00:00 Epoch 286: Training Loss: 42.53326497495524, Validation Loss: 16.715724698575325
2024-07-24 21:39:03.218659571 +00:00 Epoch 287: Training Loss: 42.55083295188216, Validation Loss: 16.725363065839115
2024-07-24 21:39:08.568675770 +00:00 Epoch 288: Training Loss: 42.595074807641176, Validation Loss: 16.73475050384596
2024-07-24 21:39:13.949806218 +00:00 Epoch 289: Training Loss: 42.56798532805284, Validation Loss: 16.723069544617715
2024-07-24 21:39:19.286833802 +00:00 Epoch 290: Training Loss: 42.55833559236552, Validation Loss: 16.705170517981017
2024-07-24 21:39:24.642161513 +00:00 Epoch 291: Training Loss: 42.54693627496742, Validation Loss: 16.694807526168663
2024-07-24 21:39:29.989216449 +00:00 Epoch 292: Training Loss: 42.57940050952259, Validation Loss: 16.703835992048436
2024-07-24 21:39:35.320882762 +00:00 Epoch 293: Training Loss: 42.55941141049079, Validation Loss: 16.73202769354675
2024-07-24 21:39:40.662187211 +00:00 Epoch 294: Training Loss: 42.538040443933276, Validation Loss: 16.728741952710077
2024-07-24 21:39:46.003490938 +00:00 Epoch 295: Training Loss: 42.54240326353873, Validation Loss: 16.719135842642093
2024-07-24 21:39:51.342164653 +00:00 Epoch 296: Training Loss: 42.54264129776309, Validation Loss: 16.720708118211228
2024-07-24 21:39:56.670463880 +00:00 Epoch 297: Training Loss: 42.56589947852264, Validation Loss: 16.69258550661403
2024-07-24 21:40:02.008977278 +00:00 Epoch 298: Training Loss: 42.56169221761501, Validation Loss: 16.696037347660717
2024-07-24 21:40:07.336212840 +00:00 Epoch 299: Training Loss: 42.58128938620533, Validation Loss: 16.706981329887515
2024-07-24 21:40:12.667726296 +00:00 Epoch 300: Training Loss: 42.57674143181863, Validation Loss: 16.766841294174007
2024-07-24 21:40:17.995877828 +00:00 Epoch 301: Training Loss: 42.60405855594904, Validation Loss: 16.733084776604382
2024-07-24 21:40:23.315053235 +00:00 Epoch 302: Training Loss: 42.57009217064876, Validation Loss: 16.692499839783626
2024-07-24 21:40:28.635500142 +00:00 Epoch 303: Training Loss: 42.566968074412124, Validation Loss: 16.71418001107047
2024-07-24 21:40:33.958973182 +00:00 Epoch 304: Training Loss: 42.57890714190484, Validation Loss: 16.69818537641121
2024-07-24 21:40:39.289442161 +00:00 Epoch 305: Training Loss: 42.611157500363106, Validation Loss: 16.874952317387688
2024-07-24 21:40:44.610664570 +00:00 Epoch 306: Training Loss: 42.58594054095287, Validation Loss: 16.728260614391903
2024-07-24 21:40:49.945733451 +00:00 Epoch 307: Training Loss: 42.55857386710262, Validation Loss: 16.909705163130518
2024-07-24 21:40:55.278791812 +00:00 Epoch 308: Training Loss: 42.68206915933962, Validation Loss: 16.893958230354865
2024-07-24 21:41:00.616927183 +00:00 Epoch 309: Training Loss: 42.67332434679825, Validation Loss: 16.87982248110357
2024-07-24 21:41:05.963908808 +00:00 Epoch 310: Training Loss: 42.66363870652365, Validation Loss: 16.865892036257044
2024-07-24 21:41:11.286030863 +00:00 Epoch 311: Training Loss: 42.649877858816, Validation Loss: 16.85588779748804
2024-07-24 21:41:16.623695490 +00:00 Epoch 312: Training Loss: 42.64036013661628, Validation Loss: 16.83653600663988
2024-07-24 21:41:21.960158519 +00:00 Epoch 313: Training Loss: 42.630458320302814, Validation Loss: 16.821334132705314
2024-07-24 21:41:27.288704505 +00:00 Epoch 314: Training Loss: 42.61777199121839, Validation Loss: 16.80983450943045
2024-07-24 21:41:32.633576068 +00:00 Epoch 315: Training Loss: 42.60745163160099, Validation Loss: 16.798336184073488
2024-07-24 21:41:37.987487051 +00:00 Epoch 316: Training Loss: 42.59957160896084, Validation Loss: 16.789070680301315
2024-07-24 21:41:43.344774387 +00:00 Epoch 317: Training Loss: 42.58855409443259, Validation Loss: 16.777060728891474
2024-07-24 21:41:48.681041996 +00:00 Epoch 318: Training Loss: 42.581790387303066, Validation Loss: 16.769724159622566
2024-07-24 21:41:54.047613046 +00:00 Epoch 319: Training Loss: 42.57356574548185, Validation Loss: 16.760563093186285
2024-07-24 21:41:59.403236853 +00:00 Epoch 320: Training Loss: 42.56650956701832, Validation Loss: 16.755139255101287
2024-07-24 21:42:04.754073208 +00:00 Epoch 321: Training Loss: 42.5616278428698, Validation Loss: 16.75256193058232
2024-07-24 21:42:10.086699277 +00:00 Epoch 322: Training Loss: 42.558239826396594, Validation Loss: 16.749890755020296
2024-07-24 21:42:15.392269346 +00:00 Epoch 323: Training Loss: 42.554852560224234, Validation Loss: 16.746701831330107
2024-07-24 21:42:20.737255874 +00:00 Epoch 324: Training Loss: 42.55234527271858, Validation Loss: 16.74300308632077
2024-07-24 21:42:26.067910351 +00:00 Epoch 325: Training Loss: 42.54933241792472, Validation Loss: 16.740766505894538
2024-07-24 21:42:31.423782375 +00:00 Epoch 326: Training Loss: 42.54765206286021, Validation Loss: 16.738926163576046
2024-07-24 21:42:36.749859277 +00:00 Epoch 327: Training Loss: 42.545916271610224, Validation Loss: 16.736639519043194
2024-07-24 21:42:42.103898227 +00:00 Epoch 328: Training Loss: 42.54287686914055, Validation Loss: 16.734718720225892
2024-07-24 21:42:47.453338549 +00:00 Epoch 329: Training Loss: 42.53981754662033, Validation Loss: 16.73248428032984
2024-07-24 21:42:52.793787856 +00:00 Epoch 330: Training Loss: 42.537833585133995, Validation Loss: 16.73015798051613
2024-07-24 21:42:58.137913484 +00:00 Epoch 331: Training Loss: 42.53668645257859, Validation Loss: 16.71548560544271
2024-07-24 21:43:03.498161965 +00:00 Epoch 332: Training Loss: 42.531453208776334, Validation Loss: 16.71352125916669
2024-07-24 21:43:08.863565478 +00:00 Epoch 333: Training Loss: 42.53044621982389, Validation Loss: 16.712212548972374
2024-07-24 21:43:14.177741996 +00:00 Epoch 334: Training Loss: 42.529974066911876, Validation Loss: 16.71061719319818
2024-07-24 21:43:19.546556371 +00:00 Epoch 335: Training Loss: 42.52896666837507, Validation Loss: 16.709389638942113
2024-07-24 21:43:24.879874114 +00:00 Epoch 336: Training Loss: 42.52787540642177, Validation Loss: 16.708139955901594
2024-07-24 21:43:30.228533847 +00:00 Epoch 337: Training Loss: 42.529692624498544, Validation Loss: 16.707970457932856
2024-07-24 21:43:35.562649278 +00:00 Epoch 338: Training Loss: 42.5269760447682, Validation Loss: 16.706219998175598
2024-07-24 21:43:40.954563561 +00:00 Epoch 339: Training Loss: 42.52737906702645, Validation Loss: 16.704802312500966
2024-07-24 21:43:46.311694085 +00:00 Epoch 340: Training Loss: 42.529439599958785, Validation Loss: 16.701296502754474
2024-07-24 21:43:51.659544020 +00:00 Epoch 341: Training Loss: 42.53558628225797, Validation Loss: 16.700669389725313
2024-07-24 21:43:57.059522169 +00:00 Epoch 342: Training Loss: 42.537682319810216, Validation Loss: 16.693241923201118
2024-07-24 21:44:02.579585107 +00:00 Epoch 343: Training Loss: 42.545837790521254, Validation Loss: 16.67600855650439
2024-07-24 21:44:08.105144455 +00:00 Epoch 344: Training Loss: 42.54290856206454, Validation Loss: 16.69471473531773
2024-07-24 21:44:13.586622282 +00:00 Epoch 345: Training Loss: 42.53046984307757, Validation Loss: 16.692555242268654
2024-07-24 21:44:19.112183993 +00:00 Epoch 346: Training Loss: 42.51237918179086, Validation Loss: 16.68342154569327
2024-07-24 21:44:24.480632975 +00:00 Epoch 347: Training Loss: 42.525290082027226, Validation Loss: 16.67576941207426
2024-07-24 21:44:29.855518340 +00:00 Epoch 348: Training Loss: 42.532228472642636, Validation Loss: 16.714528995162084
2024-07-24 21:44:35.271808202 +00:00 Epoch 349: Training Loss: 42.57026183764127, Validation Loss: 16.732004205778033
2024-07-24 21:44:40.659380535 +00:00 Epoch 350: Training Loss: 42.528700853408125, Validation Loss: 16.696290898658315
2024-07-24 21:44:46.044993264 +00:00 Epoch 351: Training Loss: 42.53466330745591, Validation Loss: 16.71029415277773
2024-07-24 21:44:51.416961702 +00:00 Epoch 352: Training Loss: 42.55752722109159, Validation Loss: 16.714485869300027
2024-07-24 21:44:56.791316238 +00:00 Epoch 353: Training Loss: 42.55101814543801, Validation Loss: 16.71284081418234
2024-07-24 21:45:02.206907774 +00:00 Epoch 354: Training Loss: 42.5477275208129, Validation Loss: 16.70894381419897
2024-07-24 21:45:07.546613571 +00:00 Epoch 355: Training Loss: 42.54511895622894, Validation Loss: 16.70981781971386
2024-07-24 21:45:12.884263263 +00:00 Epoch 356: Training Loss: 42.544435769963435, Validation Loss: 16.710006275507673
2024-07-24 21:45:18.216237453 +00:00 Epoch 357: Training Loss: 42.54471355464988, Validation Loss: 16.709340948218546
2024-07-24 21:45:23.539348758 +00:00 Epoch 358: Training Loss: 42.542910689173915, Validation Loss: 16.71064019842303
2024-07-24 21:45:28.903384127 +00:00 Epoch 359: Training Loss: 42.54388068483891, Validation Loss: 16.69169760331408
2024-07-24 21:45:34.232118652 +00:00 Epoch 360: Training Loss: 42.53123585511733, Validation Loss: 16.69147653164267
2024-07-24 21:45:39.595180578 +00:00 Epoch 361: Training Loss: 42.53336192699703, Validation Loss: 16.68968138997691
2024-07-24 21:45:44.933001629 +00:00 Epoch 362: Training Loss: 42.54539087729515, Validation Loss: 16.69992392833
2024-07-24 21:45:50.253234280 +00:00 Epoch 363: Training Loss: 42.5271396466601, Validation Loss: 16.691381469018093
2024-07-24 21:45:55.599468905 +00:00 Epoch 364: Training Loss: 42.54184537962759, Validation Loss: 16.69758288981365
2024-07-24 21:46:00.920140416 +00:00 Epoch 365: Training Loss: 42.56043149443781, Validation Loss: 16.738851219806392
2024-07-24 21:46:06.245507849 +00:00 Epoch 366: Training Loss: 42.551971374497704, Validation Loss: 16.897893319090308
2024-07-24 21:46:11.583962013 +00:00 Epoch 367: Training Loss: 42.68861721686617, Validation Loss: 16.90617447019728
2024-07-24 21:46:16.897284981 +00:00 Epoch 368: Training Loss: 42.684083711810224, Validation Loss: 16.90263318867609
2024-07-24 21:46:22.209511092 +00:00 Epoch 369: Training Loss: 42.679881445206405, Validation Loss: 16.898888043127318
2024-07-24 21:46:27.533254445 +00:00 Epoch 370: Training Loss: 42.67580334867355, Validation Loss: 16.894112532518196
2024-07-24 21:46:32.854584887 +00:00 Epoch 371: Training Loss: 42.67162861790092, Validation Loss: 16.889636426840017
2024-07-24 21:46:38.182532784 +00:00 Epoch 372: Training Loss: 42.66747056372671, Validation Loss: 16.885411957052796
2024-07-24 21:46:43.518163148 +00:00 Epoch 373: Training Loss: 42.663254977805636, Validation Loss: 16.881584468262897
2024-07-24 21:46:48.846649219 +00:00 Epoch 374: Training Loss: 42.658795323382996, Validation Loss: 16.87787586130698
2024-07-24 21:46:54.189493818 +00:00 Epoch 375: Training Loss: 42.65406159823306, Validation Loss: 16.87362915796536
2024-07-24 21:46:59.522848108 +00:00 Epoch 376: Training Loss: 42.64918739934491, Validation Loss: 16.868631503466716
2024-07-24 21:47:04.863024106 +00:00 Epoch 377: Training Loss: 42.64387225070324, Validation Loss: 16.8615118171148
2024-07-24 21:47:10.193519430 +00:00 Epoch 378: Training Loss: 42.638523455549375, Validation Loss: 16.854046247013997
2024-07-24 21:47:15.525812939 +00:00 Epoch 379: Training Loss: 42.63333323635906, Validation Loss: 16.84699626418952
2024-07-24 21:47:20.869637881 +00:00 Epoch 380: Training Loss: 42.62839012275933, Validation Loss: 16.841071689044053
2024-07-24 21:47:26.214527822 +00:00 Epoch 381: Training Loss: 42.62372827572727, Validation Loss: 16.835263918091517
2024-07-24 21:47:31.532095866 +00:00 Epoch 382: Training Loss: 42.61945781074008, Validation Loss: 16.829753920141417
2024-07-24 21:47:36.870057275 +00:00 Epoch 383: Training Loss: 42.6152629685965, Validation Loss: 16.824532056470424
2024-07-24 21:47:42.205603694 +00:00 Epoch 384: Training Loss: 42.61130847010351, Validation Loss: 16.81955850906269
2024-07-24 21:47:47.539173062 +00:00 Epoch 385: Training Loss: 42.60744912813633, Validation Loss: 16.814838274243655
2024-07-24 21:47:52.861282053 +00:00 Epoch 386: Training Loss: 42.60386679682081, Validation Loss: 16.81033499573122
2024-07-24 21:47:58.226132039 +00:00 Epoch 387: Training Loss: 42.60016164966221, Validation Loss: 16.80606151643129
2024-07-24 21:48:03.586333459 +00:00 Epoch 388: Training Loss: 42.59680689864685, Validation Loss: 16.80741216144908
2024-07-24 21:48:09.077320300 +00:00 Epoch 389: Training Loss: 42.593883594741605, Validation Loss: 16.80073139049203
2024-07-24 21:48:14.572951667 +00:00 Epoch 390: Training Loss: 42.593222406111664, Validation Loss: 16.8182336416701
2024-07-24 21:48:20.012428326 +00:00 Epoch 391: Training Loss: 42.58980904001563, Validation Loss: 16.794451598260075
2024-07-24 21:48:25.314734019 +00:00 Epoch 392: Training Loss: 42.59508563315014, Validation Loss: 16.79576369342982
2024-07-24 21:48:30.532276258 +00:00 Epoch 393: Training Loss: 42.588732727346404, Validation Loss: 16.789615652361878
2024-07-24 21:48:35.760875609 +00:00 Epoch 394: Training Loss: 42.580074559437136, Validation Loss: 16.794058807143585
2024-07-24 21:48:40.984610261 +00:00 Epoch 395: Training Loss: 42.57514815684385, Validation Loss: 16.779619257777608
2024-07-24 21:48:46.257207872 +00:00 Epoch 396: Training Loss: 42.572910145598854, Validation Loss: 16.840836119119153
2024-07-24 21:48:51.472291458 +00:00 Epoch 397: Training Loss: 42.583526682966294, Validation Loss: 16.772778874585153
2024-07-24 21:48:56.702783376 +00:00 Epoch 398: Training Loss: 42.56770270165128, Validation Loss: 16.83446598040253
2024-07-24 21:49:01.929150070 +00:00 Epoch 399: Training Loss: 42.57641832352013, Validation Loss: 16.771389359926648
2024-07-24 21:49:07.132524517 +00:00 Epoch 400: Training Loss: 42.570459789702596, Validation Loss: 16.838629868702267
2024-07-24 21:49:12.563639252 +00:00 Epoch 401: Training Loss: 42.572622102706234, Validation Loss: 16.766962220843716
2024-07-24 21:49:17.835856738 +00:00 Epoch 402: Training Loss: 42.56693529721501, Validation Loss: 16.8384126315851
2024-07-24 21:49:23.139642999 +00:00 Epoch 403: Training Loss: 42.56672281256642, Validation Loss: 16.76727115838652
2024-07-24 21:49:28.399844087 +00:00 Epoch 404: Training Loss: 42.57683503859896, Validation Loss: 16.766232071198683
2024-07-24 21:49:33.720436593 +00:00 Epoch 405: Training Loss: 42.563983493399775, Validation Loss: 16.793345570855067
2024-07-24 21:49:39.026822636 +00:00 Epoch 406: Training Loss: 42.552418918445866, Validation Loss: 16.84300540169446
2024-07-24 21:49:44.259163584 +00:00 Epoch 407: Training Loss: 42.59152595153026, Validation Loss: 16.768124820161997
2024-07-24 21:49:49.529474084 +00:00 Epoch 408: Training Loss: 42.56316435871654, Validation Loss: 16.764427535616
2024-07-24 21:49:54.881493451 +00:00 Epoch 409: Training Loss: 42.567044676685036, Validation Loss: 16.764357439724265
2024-07-24 21:50:00.255093814 +00:00 Epoch 410: Training Loss: 42.56675770654078, Validation Loss: 16.767244867098963
2024-07-24 21:50:05.508208383 +00:00 Epoch 411: Training Loss: 42.5568106633019, Validation Loss: 16.757701805661966
2024-07-24 21:50:10.706356972 +00:00 Epoch 412: Training Loss: 42.548540897805, Validation Loss: 16.849005632578898
2024-07-24 21:50:15.893611868 +00:00 Epoch 413: Training Loss: 42.61401802270777, Validation Loss: 16.834179534685596
2024-07-24 21:50:21.076798480 +00:00 Epoch 414: Training Loss: 42.60483676139791, Validation Loss: 16.823796626443396
2024-07-24 21:50:26.288561452 +00:00 Epoch 415: Training Loss: 42.575293182655585, Validation Loss: 16.757979929371153
2024-07-24 21:50:31.501579539 +00:00 Epoch 416: Training Loss: 42.55130561340403, Validation Loss: 16.8397748713821
2024-07-24 21:50:36.699362790 +00:00 Epoch 417: Training Loss: 42.60733492400565, Validation Loss: 16.81692973134243
2024-07-24 21:50:41.897364374 +00:00 Epoch 418: Training Loss: 42.573804994518866, Validation Loss: 16.75286140924841
2024-07-24 21:50:47.089628853 +00:00 Epoch 419: Training Loss: 42.550119870725155, Validation Loss: 16.838445924402976
2024-07-24 21:50:52.284984392 +00:00 Epoch 420: Training Loss: 42.61569825389115, Validation Loss: 16.826739139962775
2024-07-24 21:50:57.467060733 +00:00 Epoch 421: Training Loss: 42.59590475054867, Validation Loss: 16.78902324072903
2024-07-24 21:51:02.655416566 +00:00 Epoch 422: Training Loss: 42.54396406528659, Validation Loss: 16.7386470681011
2024-07-24 21:51:07.831192540 +00:00 Epoch 423: Training Loss: 42.53917821610105, Validation Loss: 16.82421716075876
2024-07-24 21:51:13.005424373 +00:00 Epoch 424: Training Loss: 42.55473290672132, Validation Loss: 16.763433711419474
2024-07-24 21:51:18.164864490 +00:00 Epoch 425: Training Loss: 42.54081876111484, Validation Loss: 16.730392190531308
2024-07-24 21:51:23.333866374 +00:00 Epoch 426: Training Loss: 42.53791275792227, Validation Loss: 16.753483524109036
2024-07-24 21:51:28.520155525 +00:00 Epoch 427: Training Loss: 42.53759370406318, Validation Loss: 16.81670913806374
2024-07-24 21:51:33.675579703 +00:00 Epoch 428: Training Loss: 42.536423989621376, Validation Loss: 16.753401270638648
2024-07-24 21:51:38.842534152 +00:00 Epoch 429: Training Loss: 42.52955950528999, Validation Loss: 16.774652500879075
2024-07-24 21:51:44.012681872 +00:00 Epoch 430: Training Loss: 42.52738173973373, Validation Loss: 16.72904508703974
2024-07-24 21:51:49.205470746 +00:00 Epoch 431: Training Loss: 42.52534839141097, Validation Loss: 16.7763298167047
2024-07-24 21:51:54.371388199 +00:00 Epoch 432: Training Loss: 42.52755595882654, Validation Loss: 16.816969577794673
2024-07-24 21:51:59.578537197 +00:00 Epoch 433: Training Loss: 42.530334287502576, Validation Loss: 16.795709896002833
2024-07-24 21:52:04.788201821 +00:00 Epoch 434: Training Loss: 42.5395977151582, Validation Loss: 16.823113459159533
2024-07-24 21:52:10.000341975 +00:00 Epoch 435: Training Loss: 42.53357014802688, Validation Loss: 16.75829959930772
2024-07-24 21:52:15.220672383 +00:00 Epoch 436: Training Loss: 42.529747503695354, Validation Loss: 16.781261942031826
2024-07-24 21:52:20.450612501 +00:00 Epoch 437: Training Loss: 42.52928906772155, Validation Loss: 16.803177941097623
2024-07-24 21:52:25.675984263 +00:00 Epoch 438: Training Loss: 42.52875581808723, Validation Loss: 16.79946134349062
2024-07-24 21:52:30.908946206 +00:00 Epoch 439: Training Loss: 42.538051266307, Validation Loss: 16.764666311095205
2024-07-24 21:52:36.114453008 +00:00 Epoch 440: Training Loss: 42.531339303275345, Validation Loss: 16.81051087972115
2024-07-24 21:52:41.334443244 +00:00 Epoch 441: Training Loss: 42.53219531218553, Validation Loss: 16.758468514444417
2024-07-24 21:52:46.553816179 +00:00 Epoch 442: Training Loss: 42.53699104092689, Validation Loss: 16.796848863918225
2024-07-24 21:52:51.768591306 +00:00 Epoch 443: Training Loss: 42.535753043746865, Validation Loss: 16.794914363187438
2024-07-24 21:52:56.976147459 +00:00 Epoch 444: Training Loss: 42.52830446611939, Validation Loss: 16.799425837590142
2024-07-24 21:53:02.227260838 +00:00 Epoch 445: Training Loss: 42.528259499848495, Validation Loss: 16.77800069715367
2024-07-24 21:53:07.455205263 +00:00 Epoch 446: Training Loss: 42.53574207979708, Validation Loss: 16.777458411187972
2024-07-24 21:53:12.696035958 +00:00 Epoch 447: Training Loss: 42.541996683118015, Validation Loss: 16.767395616094767
2024-07-24 21:53:17.927945287 +00:00 Epoch 448: Training Loss: 42.54287382916026, Validation Loss: 16.75401610408946
2024-07-24 21:53:23.173746240 +00:00 Epoch 449: Training Loss: 42.536504541999854, Validation Loss: 16.752570072711194
2024-07-24 21:53:28.423061889 +00:00 Epoch 450: Training Loss: 42.533160881800484, Validation Loss: 16.753041789806712
2024-07-24 21:53:33.687893524 +00:00 Epoch 451: Training Loss: 42.537746447541025, Validation Loss: 16.733564070344848
2024-07-24 21:53:38.923571253 +00:00 Epoch 452: Training Loss: 42.53312212142267, Validation Loss: 16.740670206782717
2024-07-24 21:53:44.148205383 +00:00 Epoch 453: Training Loss: 42.53278523847048, Validation Loss: 16.739005625485056
2024-07-24 21:53:49.373085889 +00:00 Epoch 454: Training Loss: 42.533507572685686, Validation Loss: 16.71803993078249
2024-07-24 21:53:54.617668986 +00:00 Epoch 455: Training Loss: 42.53043576359597, Validation Loss: 16.741162747518885
2024-07-24 21:53:59.875042267 +00:00 Epoch 456: Training Loss: 42.527859801520066, Validation Loss: 16.732748762785874
2024-07-24 21:54:05.215188630 +00:00 Epoch 457: Training Loss: 42.53516166830381, Validation Loss: 16.73770446889399
2024-07-24 21:54:10.490869323 +00:00 Epoch 458: Training Loss: 42.52860890940251, Validation Loss: 16.729227759008513
2024-07-24 21:54:15.905662547 +00:00 Epoch 459: Training Loss: 42.52571773838095, Validation Loss: 16.713445131183207
2024-07-24 21:54:21.235827300 +00:00 Epoch 460: Training Loss: 42.53296934792994, Validation Loss: 16.720352054948368
2024-07-24 21:54:26.565826483 +00:00 Epoch 461: Training Loss: 42.526947553532, Validation Loss: 16.71740848402376
2024-07-24 21:54:31.885066916 +00:00 Epoch 462: Training Loss: 42.533933898348145, Validation Loss: 16.712054029771508
2024-07-24 21:54:37.138857381 +00:00 Epoch 463: Training Loss: 42.5334772593635, Validation Loss: 16.723411142278213
2024-07-24 21:54:42.370191722 +00:00 Epoch 464: Training Loss: 42.52913139517828, Validation Loss: 16.687293340546702
2024-07-24 21:54:47.602806753 +00:00 Epoch 465: Training Loss: 42.51932408085741, Validation Loss: 16.704654797940627
2024-07-24 21:54:52.827135572 +00:00 Epoch 466: Training Loss: 42.52694219339841, Validation Loss: 16.677136041052403
2024-07-24 21:54:58.047820821 +00:00 Epoch 467: Training Loss: 42.53799997767009, Validation Loss: 16.678704325640126
2024-07-24 21:55:03.257095037 +00:00 Epoch 468: Training Loss: 42.53664269192638, Validation Loss: 16.70599662699652
2024-07-24 21:55:08.470501070 +00:00 Epoch 469: Training Loss: 42.53977667808474, Validation Loss: 16.696975642541073
2024-07-24 21:55:13.683041189 +00:00 Epoch 470: Training Loss: 42.530143198876104, Validation Loss: 16.681461554132262
2024-07-24 21:55:18.892850339 +00:00 Epoch 471: Training Loss: 42.508461305260006, Validation Loss: 16.68472814892558
2024-07-24 21:55:24.110193795 +00:00 Epoch 472: Training Loss: 42.52178646385839, Validation Loss: 16.682603497721257
2024-07-24 21:55:29.319425543 +00:00 Epoch 473: Training Loss: 42.52933836161915, Validation Loss: 16.71282138105561
2024-07-24 21:55:34.537974257 +00:00 Epoch 474: Training Loss: 42.527541876186945, Validation Loss: 16.70166272833798
2024-07-24 21:55:39.757986868 +00:00 Epoch 475: Training Loss: 42.52573311464797, Validation Loss: 16.698970852020324
2024-07-24 21:55:44.960149478 +00:00 Epoch 476: Training Loss: 42.52219450580447, Validation Loss: 16.69662257914866
2024-07-24 21:55:50.181123804 +00:00 Epoch 477: Training Loss: 42.52008082953522, Validation Loss: 16.691747660551577
2024-07-24 21:55:55.400686010 +00:00 Epoch 478: Training Loss: 42.51939503384291, Validation Loss: 16.68656319513933
2024-07-24 21:56:00.631918619 +00:00 Epoch 479: Training Loss: 42.51879441973601, Validation Loss: 16.685185303531295
2024-07-24 21:56:05.882724670 +00:00 Epoch 480: Training Loss: 42.50779280096647, Validation Loss: 16.696373048060895
2024-07-24 21:56:11.174599026 +00:00 Epoch 481: Training Loss: 42.51787139566464, Validation Loss: 16.668502419409727
2024-07-24 21:56:16.433453574 +00:00 Epoch 482: Training Loss: 42.499243827645046, Validation Loss: 16.68542713800029
2024-07-24 21:56:21.725900792 +00:00 Epoch 483: Training Loss: 42.51646249701437, Validation Loss: 16.68282736387636
2024-07-24 21:56:27.014009248 +00:00 Epoch 484: Training Loss: 42.51743953018561, Validation Loss: 16.73929637159079
2024-07-24 21:56:32.296623014 +00:00 Epoch 485: Training Loss: 42.54335271976797, Validation Loss: 16.68720665177657
2024-07-24 21:56:37.526747754 +00:00 Epoch 486: Training Loss: 42.542781432436044, Validation Loss: 16.666658344833767
2024-07-24 21:56:42.649417389 +00:00 Epoch 487: Training Loss: 42.52002890691562, Validation Loss: 16.685942686283852
2024-07-24 21:56:47.779624728 +00:00 Epoch 488: Training Loss: 42.51965215602769, Validation Loss: 16.691817256899963
2024-07-24 21:56:52.855616440 +00:00 Epoch 489: Training Loss: 42.522671475845435, Validation Loss: 16.692647300694052
2024-07-24 21:56:58.018052233 +00:00 Epoch 490: Training Loss: 42.51744937084549, Validation Loss: 16.689208023105405
2024-07-24 21:57:03.223979752 +00:00 Epoch 491: Training Loss: 42.523346966384345, Validation Loss: 16.690003824413004
2024-07-24 21:57:08.406301432 +00:00 Epoch 492: Training Loss: 42.51993378851544, Validation Loss: 16.689621894098316
2024-07-24 21:57:13.622232487 +00:00 Epoch 493: Training Loss: 42.518474759345516, Validation Loss: 16.68959791203207
2024-07-24 21:57:18.697601522 +00:00 Epoch 494: Training Loss: 42.516706754568894, Validation Loss: 16.689212325884377
2024-07-24 21:57:23.789806197 +00:00 Epoch 495: Training Loss: 42.52099785930228, Validation Loss: 16.68860317447678
2024-07-24 21:57:28.896634532 +00:00 Epoch 496: Training Loss: 42.52308883810395, Validation Loss: 16.676391641121985
2024-07-24 21:57:33.977043635 +00:00 Epoch 497: Training Loss: 42.52389272303169, Validation Loss: 16.68955340920112
2024-07-24 21:57:39.201657847 +00:00 Epoch 498: Training Loss: 42.53024922735861, Validation Loss: 16.69897519296138
2024-07-24 21:57:44.423819652 +00:00 Epoch 499: Training Loss: 42.5075055347188, Validation Loss: 16.6862488607617
2024-07-24 21:57:49.630592556 +00:00 Epoch 500: Training Loss: 42.51126852622481, Validation Loss: 16.67522701520865
