1bd9ddd50414715d10079b7f1d021fc7ec46c34a
Using arguments Cli { command: Build(BuildArgs { model_type: Regressor(RegressorArgs { labels: None, params: GenericBuildParams { degree: 3, num_coefficients: 4, hidden_layer_sizes: Some([6, 4, 1]), training_parameters: TrainArgs { data_file: "/tmp/tmp.tC5vR1xjvb.json", num_epochs: 500, knot_update_interval: 100, knot_adaptivity: 0.1, learning_rate: 0.001, knot_extension_targets: Some([10, 20, 50]), knot_extension_times: Some([50, 100, 250]), validate_each_epoch: true, validation_split: 0.2, model_output_file: None, no_save: true } } }) }), log_output: true, num_threads: None }
Thread count not specified. Using 8 threads
Loading regression data from file: "/tmp/tmp.tC5vR1xjvb.json"
creating validation set
Data loaded. Training: 80000, Validation: 20000
2024-07-30 20:34:40.216368450 +00:00 Epoch 1: Training Loss: 12.995515535654814, Validation Loss: 5.520262132284069
2024-07-30 20:34:41.416801918 +00:00 Epoch 2: Training Loss: 12.697652995998627, Validation Loss: 5.381189046643968
2024-07-30 20:34:42.602946975 +00:00 Epoch 3: Training Loss: 12.617547775463011, Validation Loss: 5.340571520644745
2024-07-30 20:34:43.788321257 +00:00 Epoch 4: Training Loss: 12.591242290381873, Validation Loss: 5.326950372326106
2024-07-30 20:34:44.985761970 +00:00 Epoch 5: Training Loss: 12.580722126551532, Validation Loss: 5.322580624082936
2024-07-30 20:34:46.193881552 +00:00 Epoch 6: Training Loss: 12.576694429308636, Validation Loss: 5.321964433679741
2024-07-30 20:34:47.390010339 +00:00 Epoch 7: Training Loss: 12.575355447208551, Validation Loss: 5.322911118282588
2024-07-30 20:34:48.587432230 +00:00 Epoch 8: Training Loss: 12.575381183980198, Validation Loss: 5.3247716168956325
2024-07-30 20:34:49.787927321 +00:00 Epoch 9: Training Loss: 12.576003364435177, Validation Loss: 5.327059079945086
2024-07-30 20:34:50.987809541 +00:00 Epoch 10: Training Loss: 12.576934489705797, Validation Loss: 5.329388589473515
2024-07-30 20:34:52.192894693 +00:00 Epoch 11: Training Loss: 12.577678927757486, Validation Loss: 5.331504871547703
2024-07-30 20:34:53.380299581 +00:00 Epoch 12: Training Loss: 12.578086028466872, Validation Loss: 5.3333189344776
2024-07-30 20:34:54.575128100 +00:00 Epoch 13: Training Loss: 12.578152385487163, Validation Loss: 5.334879256211097
2024-07-30 20:34:55.771222160 +00:00 Epoch 14: Training Loss: 12.577934275349307, Validation Loss: 5.336115004700064
2024-07-30 20:34:56.961014268 +00:00 Epoch 15: Training Loss: 12.577625407299708, Validation Loss: 5.337105351820118
2024-07-30 20:34:58.156423810 +00:00 Epoch 16: Training Loss: 12.577316640903192, Validation Loss: 5.337770858174072
2024-07-30 20:34:59.354998875 +00:00 Epoch 17: Training Loss: 12.57675403145841, Validation Loss: 5.338214841773817
2024-07-30 20:35:00.548449960 +00:00 Epoch 18: Training Loss: 12.575890218438214, Validation Loss: 5.338443329070113
2024-07-30 20:35:01.745828847 +00:00 Epoch 19: Training Loss: 12.574977423823375, Validation Loss: 5.338377960254239
2024-07-30 20:35:02.952267843 +00:00 Epoch 20: Training Loss: 12.574111988565313, Validation Loss: 5.3380915685504124
2024-07-30 20:35:04.158411868 +00:00 Epoch 21: Training Loss: 12.573154106081665, Validation Loss: 5.337632057747034
2024-07-30 20:35:05.360681498 +00:00 Epoch 22: Training Loss: 12.57208068545925, Validation Loss: 5.337026946549349
2024-07-30 20:35:06.551346010 +00:00 Epoch 23: Training Loss: 12.570993414437808, Validation Loss: 5.336301863795389
2024-07-30 20:35:07.748953257 +00:00 Epoch 24: Training Loss: 12.569942011278693, Validation Loss: 5.335488433086141
2024-07-30 20:35:08.947267277 +00:00 Epoch 25: Training Loss: 12.56892827903037, Validation Loss: 5.3346112741678295
2024-07-30 20:35:10.145016097 +00:00 Epoch 26: Training Loss: 12.567946234734553, Validation Loss: 5.333678346768411
2024-07-30 20:35:11.317524704 +00:00 Epoch 27: Training Loss: 12.566985472583763, Validation Loss: 5.3327009622962
2024-07-30 20:35:12.501072886 +00:00 Epoch 28: Training Loss: 12.56602586030508, Validation Loss: 5.331687802279408
2024-07-30 20:35:13.688400550 +00:00 Epoch 29: Training Loss: 12.565098393500229, Validation Loss: 5.330644336547426
2024-07-30 20:35:14.885504839 +00:00 Epoch 30: Training Loss: 12.56418663660351, Validation Loss: 5.329579602181085
2024-07-30 20:35:16.057505734 +00:00 Epoch 31: Training Loss: 12.563250188692441, Validation Loss: 5.3285018818008005
2024-07-30 20:35:17.241464604 +00:00 Epoch 32: Training Loss: 12.562213688357234, Validation Loss: 5.327415074606568
2024-07-30 20:35:18.431359160 +00:00 Epoch 33: Training Loss: 12.561173106624082, Validation Loss: 5.326320264720853
2024-07-30 20:35:19.633297266 +00:00 Epoch 34: Training Loss: 12.560124598916385, Validation Loss: 5.325218526283051
2024-07-30 20:35:20.818816744 +00:00 Epoch 35: Training Loss: 12.559069284915408, Validation Loss: 5.324109390581243
2024-07-30 20:35:22.003252445 +00:00 Epoch 36: Training Loss: 12.558010714676135, Validation Loss: 5.322995295743894
2024-07-30 20:35:23.193827491 +00:00 Epoch 37: Training Loss: 12.556961401608842, Validation Loss: 5.321876966545281
2024-07-30 20:35:24.392492844 +00:00 Epoch 38: Training Loss: 12.555914814231697, Validation Loss: 5.320753993891973
2024-07-30 20:35:25.586316374 +00:00 Epoch 39: Training Loss: 12.55486565569488, Validation Loss: 5.319626729326724
2024-07-30 20:35:26.770889718 +00:00 Epoch 40: Training Loss: 12.553815284179798, Validation Loss: 5.318494862274977
2024-07-30 20:35:27.951393356 +00:00 Epoch 41: Training Loss: 12.552765550470838, Validation Loss: 5.317357515172137
2024-07-30 20:35:29.133926154 +00:00 Epoch 42: Training Loss: 12.551717662310802, Validation Loss: 5.316214748423337
2024-07-30 20:35:30.312268402 +00:00 Epoch 43: Training Loss: 12.550682293617397, Validation Loss: 5.315065911039382
2024-07-30 20:35:31.489778400 +00:00 Epoch 44: Training Loss: 12.549649166813502, Validation Loss: 5.313911693931122
2024-07-30 20:35:32.666273923 +00:00 Epoch 45: Training Loss: 12.548614444145853, Validation Loss: 5.312753456300676
2024-07-30 20:35:33.830139306 +00:00 Epoch 46: Training Loss: 12.547584500614622, Validation Loss: 5.311592612979561
2024-07-30 20:35:34.997994492 +00:00 Epoch 47: Training Loss: 12.54654943772308, Validation Loss: 5.310429362573168
2024-07-30 20:35:36.182578669 +00:00 Epoch 48: Training Loss: 12.545507964646022, Validation Loss: 5.309263182710731
2024-07-30 20:35:37.361523118 +00:00 Epoch 49: Training Loss: 12.544467836323129, Validation Loss: 5.3080949246637585
2024-07-30 20:35:38.545174928 +00:00 Epoch 50: Training Loss: 12.543416994346714, Validation Loss: 5.306924920843144
2024-07-30 20:35:38.547081423 +00:00 Extending knot vectors from 8 to 10
2024-07-30 20:35:40.236470452 +00:00 Epoch 51: Training Loss: 12.544739463611531, Validation Loss: 5.2995060743105595
2024-07-30 20:35:41.956909429 +00:00 Epoch 52: Training Loss: 12.541219492137069, Validation Loss: 5.295097376737582
2024-07-30 20:35:43.705135395 +00:00 Epoch 53: Training Loss: 12.539695756213737, Validation Loss: 5.29133889810162
2024-07-30 20:35:45.436710383 +00:00 Epoch 54: Training Loss: 12.53840962357128, Validation Loss: 5.288075403015039
2024-07-30 20:35:47.156517198 +00:00 Epoch 55: Training Loss: 12.537294449290586, Validation Loss: 5.285199442841935
2024-07-30 20:35:48.865079391 +00:00 Epoch 56: Training Loss: 12.536319608403923, Validation Loss: 5.282642390499863
2024-07-30 20:35:50.608617340 +00:00 Epoch 57: Training Loss: 12.535421124382747, Validation Loss: 5.280345552649842
2024-07-30 20:35:52.316189357 +00:00 Epoch 58: Training Loss: 12.534558969545564, Validation Loss: 5.278256648646016
2024-07-30 20:35:54.041380977 +00:00 Epoch 59: Training Loss: 12.533774011547214, Validation Loss: 5.276342228093641
2024-07-30 20:35:55.785383176 +00:00 Epoch 60: Training Loss: 12.53302709661149, Validation Loss: 5.274574603393014
2024-07-30 20:35:57.511862792 +00:00 Epoch 61: Training Loss: 12.53231803776627, Validation Loss: 5.272938278918453
2024-07-30 20:35:59.216569143 +00:00 Epoch 62: Training Loss: 12.531654855963103, Validation Loss: 5.271407966660336
2024-07-30 20:36:00.938729320 +00:00 Epoch 63: Training Loss: 12.53104121681336, Validation Loss: 5.269959371186718
2024-07-30 20:36:02.650850303 +00:00 Epoch 64: Training Loss: 12.53043886572901, Validation Loss: 5.268604049074581
2024-07-30 20:36:04.365675974 +00:00 Epoch 65: Training Loss: 12.529925824808771, Validation Loss: 5.2673086877530935
2024-07-30 20:36:06.091818282 +00:00 Epoch 66: Training Loss: 12.529511663277, Validation Loss: 5.2660686361387
2024-07-30 20:36:07.828880480 +00:00 Epoch 67: Training Loss: 12.529137052429155, Validation Loss: 5.2648899748096
2024-07-30 20:36:09.570760967 +00:00 Epoch 68: Training Loss: 12.528719726210266, Validation Loss: 5.263830420902896
2024-07-30 20:36:11.292974430 +00:00 Epoch 69: Training Loss: 12.528333742141017, Validation Loss: 5.262802407735686
2024-07-30 20:36:13.018827645 +00:00 Epoch 70: Training Loss: 12.527921869356398, Validation Loss: 5.261856989286699
2024-07-30 20:36:14.773576697 +00:00 Epoch 71: Training Loss: 12.527474837779728, Validation Loss: 5.260941832805564
2024-07-30 20:36:16.481125293 +00:00 Epoch 72: Training Loss: 12.526970924036368, Validation Loss: 5.2600700451999325
2024-07-30 20:36:18.180694616 +00:00 Epoch 73: Training Loss: 12.52640559265357, Validation Loss: 5.2592782563793365
2024-07-30 20:36:19.913891578 +00:00 Epoch 74: Training Loss: 12.52574840687016, Validation Loss: 5.258602102720004
2024-07-30 20:36:21.638795084 +00:00 Epoch 75: Training Loss: 12.524639029087767, Validation Loss: 5.258018266233903
2024-07-30 20:36:23.378422165 +00:00 Epoch 76: Training Loss: 12.523121637190739, Validation Loss: 5.257478548313278
2024-07-30 20:36:25.127675555 +00:00 Epoch 77: Training Loss: 12.521684120503581, Validation Loss: 5.256873047407285
2024-07-30 20:36:26.840079768 +00:00 Epoch 78: Training Loss: 12.52002733383851, Validation Loss: 5.256078701147881
2024-07-30 20:36:28.564085996 +00:00 Epoch 79: Training Loss: 12.518518084007562, Validation Loss: 5.255078330288113
2024-07-30 20:36:30.265515638 +00:00 Epoch 80: Training Loss: 12.516950835522861, Validation Loss: 5.2540807083865
2024-07-30 20:36:31.973097102 +00:00 Epoch 81: Training Loss: 12.515310191351409, Validation Loss: 5.2531732028309275
2024-07-30 20:36:33.688008090 +00:00 Epoch 82: Training Loss: 12.513620775865238, Validation Loss: 5.252180209128304
2024-07-30 20:36:35.421248131 +00:00 Epoch 83: Training Loss: 12.51189940635177, Validation Loss: 5.251046941408066
2024-07-30 20:36:37.156938728 +00:00 Epoch 84: Training Loss: 12.510278528438562, Validation Loss: 5.249793124300985
2024-07-30 20:36:38.883957687 +00:00 Epoch 85: Training Loss: 12.508683788070115, Validation Loss: 5.2484856715743975
2024-07-30 20:36:40.606632134 +00:00 Epoch 86: Training Loss: 12.507089655050647, Validation Loss: 5.24716721735773
2024-07-30 20:36:42.312114296 +00:00 Epoch 87: Training Loss: 12.505491422988621, Validation Loss: 5.245765899005908
2024-07-30 20:36:44.027649518 +00:00 Epoch 88: Training Loss: 12.503850181574425, Validation Loss: 5.2443319396340184
2024-07-30 20:36:45.761132254 +00:00 Epoch 89: Training Loss: 12.502240384055929, Validation Loss: 5.242940560201175
2024-07-30 20:36:47.467088269 +00:00 Epoch 90: Training Loss: 12.500706878414313, Validation Loss: 5.241606674194889
2024-07-30 20:36:49.169060029 +00:00 Epoch 91: Training Loss: 12.499149202125622, Validation Loss: 5.240232351510073
2024-07-30 20:36:50.880760350 +00:00 Epoch 92: Training Loss: 12.497494702836875, Validation Loss: 5.238762866459485
2024-07-30 20:36:52.589892444 +00:00 Epoch 93: Training Loss: 12.495751371618049, Validation Loss: 5.237206802181268
2024-07-30 20:36:54.277730580 +00:00 Epoch 94: Training Loss: 12.493939240475846, Validation Loss: 5.235539495340302
2024-07-30 20:36:55.988733551 +00:00 Epoch 95: Training Loss: 12.492053806885622, Validation Loss: 5.233714079023088
2024-07-30 20:36:57.697803532 +00:00 Epoch 96: Training Loss: 12.490096015500326, Validation Loss: 5.231664992355311
2024-07-30 20:36:59.419838381 +00:00 Epoch 97: Training Loss: 12.488178683732327, Validation Loss: 5.229517508722225
2024-07-30 20:37:01.154279600 +00:00 Epoch 98: Training Loss: 12.486350424716871, Validation Loss: 5.227386283447851
2024-07-30 20:37:02.879297273 +00:00 Epoch 99: Training Loss: 12.484489810621136, Validation Loss: 5.225180190913065
2024-07-30 20:37:04.599540370 +00:00 Epoch 100: Training Loss: 12.482326329085442, Validation Loss: 5.222824010570029
2024-07-30 20:37:04.604672708 +00:00 Extending knot vectors from 10 to 20
2024-07-30 20:37:09.497403165 +00:00 Epoch 101: Training Loss: 12.641202415370795, Validation Loss: 5.332598684041497
2024-07-30 20:37:14.258486696 +00:00 Epoch 102: Training Loss: 12.633886474071849, Validation Loss: 5.325595093356552
2024-07-30 20:37:19.013589930 +00:00 Epoch 103: Training Loss: 12.627541471443779, Validation Loss: 5.319551388973862
2024-07-30 20:37:23.759831229 +00:00 Epoch 104: Training Loss: 12.621764521808958, Validation Loss: 5.314347381469093
2024-07-30 20:37:28.501431729 +00:00 Epoch 105: Training Loss: 12.616594022744104, Validation Loss: 5.309892882459503
2024-07-30 20:37:33.259977426 +00:00 Epoch 106: Training Loss: 12.611989216196184, Validation Loss: 5.306144815701021
2024-07-30 20:37:37.967201269 +00:00 Epoch 107: Training Loss: 12.607833402848593, Validation Loss: 5.302997143436245
2024-07-30 20:37:42.675500354 +00:00 Epoch 108: Training Loss: 12.604059654977615, Validation Loss: 5.300368433045156
2024-07-30 20:37:47.383260192 +00:00 Epoch 109: Training Loss: 12.600683177290229, Validation Loss: 5.298187672731044
2024-07-30 20:37:52.097405548 +00:00 Epoch 110: Training Loss: 12.597641771639218, Validation Loss: 5.296396166368576
2024-07-30 20:37:56.863929014 +00:00 Epoch 111: Training Loss: 12.594956726461653, Validation Loss: 5.294917697385836
2024-07-30 20:38:01.659494500 +00:00 Epoch 112: Training Loss: 12.592493148301124, Validation Loss: 5.2937460553770945
2024-07-30 20:38:06.406493752 +00:00 Epoch 113: Training Loss: 12.590266149215386, Validation Loss: 5.292824892262314
2024-07-30 20:38:11.153031668 +00:00 Epoch 114: Training Loss: 12.588271905591219, Validation Loss: 5.292107838265287
2024-07-30 20:38:15.898506366 +00:00 Epoch 115: Training Loss: 12.586470704157158, Validation Loss: 5.291552533053125
2024-07-30 20:38:20.627608358 +00:00 Epoch 116: Training Loss: 12.584844300097258, Validation Loss: 5.291127582306589
2024-07-30 20:38:25.386330945 +00:00 Epoch 117: Training Loss: 12.58332253295328, Validation Loss: 5.2908091825637955
2024-07-30 20:38:30.124010724 +00:00 Epoch 118: Training Loss: 12.58190648556803, Validation Loss: 5.29060404030701
2024-07-30 20:38:34.869378317 +00:00 Epoch 119: Training Loss: 12.580625610997457, Validation Loss: 5.29054653219253
2024-07-30 20:38:39.592040691 +00:00 Epoch 120: Training Loss: 12.579466198898183, Validation Loss: 5.29056091064522
2024-07-30 20:38:44.379939950 +00:00 Epoch 121: Training Loss: 12.578401236711212, Validation Loss: 5.290634251510109
2024-07-30 20:38:49.111540944 +00:00 Epoch 122: Training Loss: 12.577408367653746, Validation Loss: 5.290740558659335
2024-07-30 20:38:53.838924120 +00:00 Epoch 123: Training Loss: 12.576499290232544, Validation Loss: 5.290864764401769
2024-07-30 20:38:58.570088665 +00:00 Epoch 124: Training Loss: 12.57562439752496, Validation Loss: 5.291020747756493
2024-07-30 20:39:03.298457499 +00:00 Epoch 125: Training Loss: 12.574802125540208, Validation Loss: 5.291225370384986
2024-07-30 20:39:08.073257486 +00:00 Epoch 126: Training Loss: 12.574035066274194, Validation Loss: 5.2914311200764175
2024-07-30 20:39:12.791398953 +00:00 Epoch 127: Training Loss: 12.57330481719234, Validation Loss: 5.291629074392049
2024-07-30 20:39:17.547789906 +00:00 Epoch 128: Training Loss: 12.57259739659929, Validation Loss: 5.291815180926107
2024-07-30 20:39:22.283628546 +00:00 Epoch 129: Training Loss: 12.571926109018452, Validation Loss: 5.2919878680853785
2024-07-30 20:39:27.077100641 +00:00 Epoch 130: Training Loss: 12.571288023887377, Validation Loss: 5.292137884641376
2024-07-30 20:39:31.842403 +00:00 Epoch 131: Training Loss: 12.57068389893194, Validation Loss: 5.292269111383629
2024-07-30 20:39:36.614856824 +00:00 Epoch 132: Training Loss: 12.570108648323616, Validation Loss: 5.292378847678162
2024-07-30 20:39:41.365106271 +00:00 Epoch 133: Training Loss: 12.56956182870833, Validation Loss: 5.292471018723297
2024-07-30 20:39:46.140566055 +00:00 Epoch 134: Training Loss: 12.569037445744216, Validation Loss: 5.29262330015743
2024-07-30 20:39:50.936596346 +00:00 Epoch 135: Training Loss: 12.5685296821094, Validation Loss: 5.292753019848229
2024-07-30 20:39:55.699407585 +00:00 Epoch 136: Training Loss: 12.568035505395033, Validation Loss: 5.292864251540169
2024-07-30 20:40:00.488655549 +00:00 Epoch 137: Training Loss: 12.56755990305513, Validation Loss: 5.292958207027179
2024-07-30 20:40:05.250962743 +00:00 Epoch 138: Training Loss: 12.567096387725798, Validation Loss: 5.293038078754268
2024-07-30 20:40:10.004969374 +00:00 Epoch 139: Training Loss: 12.566631733218184, Validation Loss: 5.293104712352607
2024-07-30 20:40:14.748897071 +00:00 Epoch 140: Training Loss: 12.566161442499402, Validation Loss: 5.293157755664925
2024-07-30 20:40:19.500955715 +00:00 Epoch 141: Training Loss: 12.565697927422255, Validation Loss: 5.293199298667829
2024-07-30 20:40:24.273140237 +00:00 Epoch 142: Training Loss: 12.565247807608404, Validation Loss: 5.293231472613653
2024-07-30 20:40:29.055951576 +00:00 Epoch 143: Training Loss: 12.564808998998881, Validation Loss: 5.293251251140694
2024-07-30 20:40:33.810171882 +00:00 Epoch 144: Training Loss: 12.56438930610837, Validation Loss: 5.293259145939722
2024-07-30 20:40:38.568232445 +00:00 Epoch 145: Training Loss: 12.563981148165647, Validation Loss: 5.293257854678547
2024-07-30 20:40:43.325706851 +00:00 Epoch 146: Training Loss: 12.563583197582926, Validation Loss: 5.293251341329176
2024-07-30 20:40:48.022934284 +00:00 Epoch 147: Training Loss: 12.563196860568958, Validation Loss: 5.293248001927413
2024-07-30 20:40:52.749075409 +00:00 Epoch 148: Training Loss: 12.562818590167348, Validation Loss: 5.293245121127894
2024-07-30 20:40:57.500495502 +00:00 Epoch 149: Training Loss: 12.562452485110411, Validation Loss: 5.293251114696212
2024-07-30 20:41:02.269432986 +00:00 Epoch 150: Training Loss: 12.56209215025268, Validation Loss: 5.293275574651587
2024-07-30 20:41:07.003029816 +00:00 Epoch 151: Training Loss: 12.561739000882005, Validation Loss: 5.2933016830420465
2024-07-30 20:41:11.780072221 +00:00 Epoch 152: Training Loss: 12.561385756837229, Validation Loss: 5.293329666264906
2024-07-30 20:41:16.512986758 +00:00 Epoch 153: Training Loss: 12.561019988439234, Validation Loss: 5.293355220318936
2024-07-30 20:41:21.211909464 +00:00 Epoch 154: Training Loss: 12.560655107632906, Validation Loss: 5.293379402116767
2024-07-30 20:41:25.912544526 +00:00 Epoch 155: Training Loss: 12.560290113633723, Validation Loss: 5.293404026524588
2024-07-30 20:41:30.597167823 +00:00 Epoch 156: Training Loss: 12.559923240637794, Validation Loss: 5.293432625913058
2024-07-30 20:41:35.315842853 +00:00 Epoch 157: Training Loss: 12.559556551983306, Validation Loss: 5.2934641106225495
2024-07-30 20:41:40.037522519 +00:00 Epoch 158: Training Loss: 12.559184467073635, Validation Loss: 5.293496757343032
2024-07-30 20:41:44.752296358 +00:00 Epoch 159: Training Loss: 12.558807437033106, Validation Loss: 5.293529542407459
2024-07-30 20:41:49.449133270 +00:00 Epoch 160: Training Loss: 12.558428252582631, Validation Loss: 5.293561851363153
2024-07-30 20:41:54.162017747 +00:00 Epoch 161: Training Loss: 12.55804623517077, Validation Loss: 5.293591984752685
2024-07-30 20:41:58.898994413 +00:00 Epoch 162: Training Loss: 12.557660608575393, Validation Loss: 5.293617433283344
2024-07-30 20:42:03.627313440 +00:00 Epoch 163: Training Loss: 12.557270582066598, Validation Loss: 5.293637080409784
2024-07-30 20:42:08.378366915 +00:00 Epoch 164: Training Loss: 12.55687825243326, Validation Loss: 5.2936465079540405
2024-07-30 20:42:13.094348556 +00:00 Epoch 165: Training Loss: 12.556488882158455, Validation Loss: 5.293649768642312
2024-07-30 20:42:17.832654431 +00:00 Epoch 166: Training Loss: 12.556104257047886, Validation Loss: 5.293698585335175
2024-07-30 20:42:22.600694084 +00:00 Epoch 167: Training Loss: 12.555725737856408, Validation Loss: 5.293759119845844
2024-07-30 20:42:27.356777525 +00:00 Epoch 168: Training Loss: 12.555354403002665, Validation Loss: 5.2938082988289175
2024-07-30 20:42:32.089017426 +00:00 Epoch 169: Training Loss: 12.55499002615527, Validation Loss: 5.293842640500742
2024-07-30 20:42:36.810806200 +00:00 Epoch 170: Training Loss: 12.554633729727284, Validation Loss: 5.293864914325042
2024-07-30 20:42:41.571526088 +00:00 Epoch 171: Training Loss: 12.554285483901602, Validation Loss: 5.293871144138882
2024-07-30 20:42:46.368559796 +00:00 Epoch 172: Training Loss: 12.553946786020402, Validation Loss: 5.293863715506509
2024-07-30 20:42:51.088811138 +00:00 Epoch 173: Training Loss: 12.553614510138424, Validation Loss: 5.2938453242679415
2024-07-30 20:42:55.815835 +00:00 Epoch 174: Training Loss: 12.553289140271833, Validation Loss: 5.29381722978744
2024-07-30 20:43:00.552401445 +00:00 Epoch 175: Training Loss: 12.552971432680415, Validation Loss: 5.293779876780008
2024-07-30 20:43:05.270861135 +00:00 Epoch 176: Training Loss: 12.55266072847173, Validation Loss: 5.293732123861798
2024-07-30 20:43:10.037659963 +00:00 Epoch 177: Training Loss: 12.552354728397077, Validation Loss: 5.293673660120895
2024-07-30 20:43:14.767686160 +00:00 Epoch 178: Training Loss: 12.552052119563369, Validation Loss: 5.293601648785388
2024-07-30 20:43:19.463699396 +00:00 Epoch 179: Training Loss: 12.551748997910105, Validation Loss: 5.293521026079957
2024-07-30 20:43:24.197797034 +00:00 Epoch 180: Training Loss: 12.551451076423263, Validation Loss: 5.293430885053522
2024-07-30 20:43:28.944036931 +00:00 Epoch 181: Training Loss: 12.551153964883328, Validation Loss: 5.2933313396457615
2024-07-30 20:43:33.682377307 +00:00 Epoch 182: Training Loss: 12.55085970324805, Validation Loss: 5.293223936554175
2024-07-30 20:43:38.443282446 +00:00 Epoch 183: Training Loss: 12.550567448562687, Validation Loss: 5.293110732422019
2024-07-30 20:43:43.148621013 +00:00 Epoch 184: Training Loss: 12.550277201498218, Validation Loss: 5.292988677258383
2024-07-30 20:43:47.857111227 +00:00 Epoch 185: Training Loss: 12.549987436864082, Validation Loss: 5.29285982425067
2024-07-30 20:43:52.597279900 +00:00 Epoch 186: Training Loss: 12.549697619008594, Validation Loss: 5.292723290460858
2024-07-30 20:43:57.352555940 +00:00 Epoch 187: Training Loss: 12.549407654584744, Validation Loss: 5.29257768575843
2024-07-30 20:44:02.092156793 +00:00 Epoch 188: Training Loss: 12.549116044100886, Validation Loss: 5.292425983655488
2024-07-30 20:44:06.826781528 +00:00 Epoch 189: Training Loss: 12.54882465116337, Validation Loss: 5.292269100718154
2024-07-30 20:44:11.560860242 +00:00 Epoch 190: Training Loss: 12.548538146068656, Validation Loss: 5.2921101496710365
2024-07-30 20:44:16.282435144 +00:00 Epoch 191: Training Loss: 12.54825319391185, Validation Loss: 5.291951563311743
2024-07-30 20:44:21.012883667 +00:00 Epoch 192: Training Loss: 12.547966329068576, Validation Loss: 5.291792347332223
2024-07-30 20:44:25.725280264 +00:00 Epoch 193: Training Loss: 12.54768053378817, Validation Loss: 5.291632068006068
2024-07-30 20:44:30.455066144 +00:00 Epoch 194: Training Loss: 12.547396113712589, Validation Loss: 5.291468996623574
2024-07-30 20:44:35.206569783 +00:00 Epoch 195: Training Loss: 12.547114286116633, Validation Loss: 5.291304798589201
2024-07-30 20:44:39.938582018 +00:00 Epoch 196: Training Loss: 12.546835980709183, Validation Loss: 5.291143452607354
2024-07-30 20:44:44.694670114 +00:00 Epoch 197: Training Loss: 12.546556954161069, Validation Loss: 5.290984509029055
2024-07-30 20:44:49.395299599 +00:00 Epoch 198: Training Loss: 12.546272677170109, Validation Loss: 5.290821873700173
2024-07-30 20:44:54.108996886 +00:00 Epoch 199: Training Loss: 12.545987741840523, Validation Loss: 5.290665575872219
2024-07-30 20:44:58.789536131 +00:00 Epoch 200: Training Loss: 12.54569986161436, Validation Loss: 5.290511559713465
2024-07-30 20:45:03.486496613 +00:00 Epoch 201: Training Loss: 12.545409636058107, Validation Loss: 5.290360435846913
2024-07-30 20:45:08.174680248 +00:00 Epoch 202: Training Loss: 12.545121112435382, Validation Loss: 5.290212271340265
2024-07-30 20:45:12.895086065 +00:00 Epoch 203: Training Loss: 12.544835028039564, Validation Loss: 5.290066052688796
2024-07-30 20:45:17.577932467 +00:00 Epoch 204: Training Loss: 12.544550476556816, Validation Loss: 5.2899233270167185
2024-07-30 20:45:22.276719840 +00:00 Epoch 205: Training Loss: 12.544269957648469, Validation Loss: 5.289782866916109
2024-07-30 20:45:26.957196190 +00:00 Epoch 206: Training Loss: 12.543991453199729, Validation Loss: 5.289647125314447
2024-07-30 20:45:31.613913499 +00:00 Epoch 207: Training Loss: 12.543714499646526, Validation Loss: 5.2895139056469365
2024-07-30 20:45:36.272008441 +00:00 Epoch 208: Training Loss: 12.543441243875602, Validation Loss: 5.289382066898517
2024-07-30 20:45:41.016685891 +00:00 Epoch 209: Training Loss: 12.543169103434868, Validation Loss: 5.289247171147624
2024-07-30 20:45:45.695700048 +00:00 Epoch 210: Training Loss: 12.542902983552294, Validation Loss: 5.28911155149871
2024-07-30 20:45:50.378616305 +00:00 Epoch 211: Training Loss: 12.542639451891535, Validation Loss: 5.288995580125858
2024-07-30 20:45:55.096713922 +00:00 Epoch 212: Training Loss: 12.542380329304931, Validation Loss: 5.288906099239918
2024-07-30 20:45:59.814922802 +00:00 Epoch 213: Training Loss: 12.542122955424317, Validation Loss: 5.288815378304982
2024-07-30 20:46:04.507706980 +00:00 Epoch 214: Training Loss: 12.54186107613009, Validation Loss: 5.288722701647965
2024-07-30 20:46:09.277835214 +00:00 Epoch 215: Training Loss: 12.541602413598534, Validation Loss: 5.288627753057118
2024-07-30 20:46:14.021251876 +00:00 Epoch 216: Training Loss: 12.541346236537443, Validation Loss: 5.288529680691833
2024-07-30 20:46:18.759740004 +00:00 Epoch 217: Training Loss: 12.541089542623302, Validation Loss: 5.288429990602177
2024-07-30 20:46:23.478036324 +00:00 Epoch 218: Training Loss: 12.540833967025328, Validation Loss: 5.288327429478321
2024-07-30 20:46:28.201997170 +00:00 Epoch 219: Training Loss: 12.540581654309195, Validation Loss: 5.288221743575057
2024-07-30 20:46:32.927385232 +00:00 Epoch 220: Training Loss: 12.540331779188751, Validation Loss: 5.288112581402884
2024-07-30 20:46:37.645299051 +00:00 Epoch 221: Training Loss: 12.540081040264242, Validation Loss: 5.2880012643366685
2024-07-30 20:46:42.397363855 +00:00 Epoch 222: Training Loss: 12.539827476341053, Validation Loss: 5.28788648845916
2024-07-30 20:46:47.141221431 +00:00 Epoch 223: Training Loss: 12.539574523384193, Validation Loss: 5.287767268538825
2024-07-30 20:46:51.840641161 +00:00 Epoch 224: Training Loss: 12.539318479080451, Validation Loss: 5.287643331824073
2024-07-30 20:46:56.602804337 +00:00 Epoch 225: Training Loss: 12.539062864249583, Validation Loss: 5.287514679090378
2024-07-30 20:47:01.364854998 +00:00 Epoch 226: Training Loss: 12.538805540420453, Validation Loss: 5.287382649602091
2024-07-30 20:47:06.121620083 +00:00 Epoch 227: Training Loss: 12.538548428812149, Validation Loss: 5.287255047138323
2024-07-30 20:47:10.901661376 +00:00 Epoch 228: Training Loss: 12.538288220012573, Validation Loss: 5.287124493362757
2024-07-30 20:47:15.693606491 +00:00 Epoch 229: Training Loss: 12.538025891320515, Validation Loss: 5.286991342591933
2024-07-30 20:47:20.437741710 +00:00 Epoch 230: Training Loss: 12.537759241849226, Validation Loss: 5.286856421640551
2024-07-30 20:47:25.235933509 +00:00 Epoch 231: Training Loss: 12.53749585845378, Validation Loss: 5.286715765271224
2024-07-30 20:47:29.981226712 +00:00 Epoch 232: Training Loss: 12.537203909568879, Validation Loss: 5.2865625719272185
2024-07-30 20:47:34.801488078 +00:00 Epoch 233: Training Loss: 12.53691272786023, Validation Loss: 5.286400435434647
2024-07-30 20:47:39.589820045 +00:00 Epoch 234: Training Loss: 12.536623614070317, Validation Loss: 5.286227408709744
2024-07-30 20:47:44.366526753 +00:00 Epoch 235: Training Loss: 12.536335739417597, Validation Loss: 5.286045277575659
2024-07-30 20:47:49.144089105 +00:00 Epoch 236: Training Loss: 12.536049501025218, Validation Loss: 5.285853801824691
2024-07-30 20:47:53.906122712 +00:00 Epoch 237: Training Loss: 12.535765475682476, Validation Loss: 5.285650614045667
2024-07-30 20:47:58.678618759 +00:00 Epoch 238: Training Loss: 12.535478757141082, Validation Loss: 5.285437599071332
2024-07-30 20:48:03.453859881 +00:00 Epoch 239: Training Loss: 12.535194395273772, Validation Loss: 5.2852163361738675
2024-07-30 20:48:08.175322074 +00:00 Epoch 240: Training Loss: 12.534911901690934, Validation Loss: 5.284987566650643
2024-07-30 20:48:12.880808529 +00:00 Epoch 241: Training Loss: 12.534626994474921, Validation Loss: 5.284750799741669
2024-07-30 20:48:17.641873694 +00:00 Epoch 242: Training Loss: 12.534343452893571, Validation Loss: 5.28450299167194
2024-07-30 20:48:22.420175228 +00:00 Epoch 243: Training Loss: 12.534063323058584, Validation Loss: 5.2842445298260445
2024-07-30 20:48:27.187764884 +00:00 Epoch 244: Training Loss: 12.53378770211131, Validation Loss: 5.283978101949765
2024-07-30 20:48:31.911044787 +00:00 Epoch 245: Training Loss: 12.53351857787591, Validation Loss: 5.283703691249624
2024-07-30 20:48:36.671347289 +00:00 Epoch 246: Training Loss: 12.533252587315868, Validation Loss: 5.28342299339803
2024-07-30 20:48:41.390032081 +00:00 Epoch 247: Training Loss: 12.532987469907267, Validation Loss: 5.283137442660066
2024-07-30 20:48:46.110515734 +00:00 Epoch 248: Training Loss: 12.53272326893584, Validation Loss: 5.282846661713528
2024-07-30 20:48:50.807981110 +00:00 Epoch 249: Training Loss: 12.532459007881753, Validation Loss: 5.282549871934335
2024-07-30 20:48:55.514735310 +00:00 Epoch 250: Training Loss: 12.532194419800513, Validation Loss: 5.282249009932295
2024-07-30 20:48:55.545847970 +00:00 Extending knot vectors from 20 to 50
2024-07-30 20:49:12.840132099 +00:00 Epoch 251: Training Loss: 12.622625422365637, Validation Loss: 5.371432513347235
2024-07-30 20:49:30.175625639 +00:00 Epoch 252: Training Loss: 12.61973681600394, Validation Loss: 5.371104618651822
2024-07-30 20:49:47.594337083 +00:00 Epoch 253: Training Loss: 12.618867569318134, Validation Loss: 5.370901619166729
2024-07-30 20:50:05.226672818 +00:00 Epoch 254: Training Loss: 12.617860988695544, Validation Loss: 5.370776317500401
2024-07-30 20:50:22.624036726 +00:00 Epoch 255: Training Loss: 12.616910813468303, Validation Loss: 5.370698979131009
2024-07-30 20:50:40.080823141 +00:00 Epoch 256: Training Loss: 12.615939101542546, Validation Loss: 5.370602335434086
2024-07-30 20:50:57.285162680 +00:00 Epoch 257: Training Loss: 12.615107902275767, Validation Loss: 5.37044454885028
2024-07-30 20:51:14.775218449 +00:00 Epoch 258: Training Loss: 12.614435197177693, Validation Loss: 5.370267926725608
2024-07-30 20:51:31.953299477 +00:00 Epoch 259: Training Loss: 12.613797795916044, Validation Loss: 5.370081413096714
2024-07-30 20:51:49.111401695 +00:00 Epoch 260: Training Loss: 12.613184930783165, Validation Loss: 5.369892977058555
2024-07-30 20:52:06.293901224 +00:00 Epoch 261: Training Loss: 12.612618830847863, Validation Loss: 5.369693470621766
2024-07-30 20:52:23.514905246 +00:00 Epoch 262: Training Loss: 12.612071210573694, Validation Loss: 5.369490751749844
2024-07-30 20:52:40.791941396 +00:00 Epoch 263: Training Loss: 12.61155020457268, Validation Loss: 5.3692755252677005
2024-07-30 20:52:58.277968744 +00:00 Epoch 264: Training Loss: 12.611045977526466, Validation Loss: 5.3690623588881765
2024-07-30 20:53:15.550883810 +00:00 Epoch 265: Training Loss: 12.610565099727804, Validation Loss: 5.36883360959732
2024-07-30 20:53:33.099988474 +00:00 Epoch 266: Training Loss: 12.610097792876076, Validation Loss: 5.368611945949333
2024-07-30 20:53:50.570522765 +00:00 Epoch 267: Training Loss: 12.609647543589585, Validation Loss: 5.368372460683318
2024-07-30 20:54:08.103257794 +00:00 Epoch 268: Training Loss: 12.609204155892282, Validation Loss: 5.368148621970948
2024-07-30 20:54:25.485070573 +00:00 Epoch 269: Training Loss: 12.60877327792494, Validation Loss: 5.367900494031433
2024-07-30 20:54:42.749237408 +00:00 Epoch 270: Training Loss: 12.608344107400482, Validation Loss: 5.36767649562786
2024-07-30 20:55:00.339357797 +00:00 Epoch 271: Training Loss: 12.607927510034548, Validation Loss: 5.367418537102079
2024-07-30 20:55:17.862094180 +00:00 Epoch 272: Training Loss: 12.607504471856751, Validation Loss: 5.3672048577205915
2024-07-30 20:55:35.081879941 +00:00 Epoch 273: Training Loss: 12.607098250623086, Validation Loss: 5.366938288348795
2024-07-30 20:55:52.574534188 +00:00 Epoch 274: Training Loss: 12.606702064111767, Validation Loss: 5.366723628195989
2024-07-30 20:56:09.853445244 +00:00 Epoch 275: Training Loss: 12.606329089184236, Validation Loss: 5.366424629740505
2024-07-30 20:56:27.314772954 +00:00 Epoch 276: Training Loss: 12.6059510422782, Validation Loss: 5.366233223557567
2024-07-30 20:56:44.747661344 +00:00 Epoch 277: Training Loss: 12.605592480199023, Validation Loss: 5.365914504792598
2024-07-30 20:57:02.040057443 +00:00 Epoch 278: Training Loss: 12.605214439349492, Validation Loss: 5.365748382104279
2024-07-30 20:57:19.470276935 +00:00 Epoch 279: Training Loss: 12.604846478643053, Validation Loss: 5.36542785337097
2024-07-30 20:57:36.618794035 +00:00 Epoch 280: Training Loss: 12.604474195172392, Validation Loss: 5.365275165833599
2024-07-30 20:57:54.038168826 +00:00 Epoch 281: Training Loss: 12.604116950406898, Validation Loss: 5.364959814904586
2024-07-30 20:58:11.322108987 +00:00 Epoch 282: Training Loss: 12.603762698070716, Validation Loss: 5.3648092758813455
2024-07-30 20:58:28.615446530 +00:00 Epoch 283: Training Loss: 12.603404413671248, Validation Loss: 5.364498580193142
2024-07-30 20:58:45.916260919 +00:00 Epoch 284: Training Loss: 12.603037613732004, Validation Loss: 5.364378978031407
2024-07-30 20:59:02.837014390 +00:00 Epoch 285: Training Loss: 12.602714149994764, Validation Loss: 5.3640648475260315
2024-07-30 20:59:20.331897889 +00:00 Epoch 286: Training Loss: 12.602368584720807, Validation Loss: 5.3639482154728935
2024-07-30 20:59:37.546047589 +00:00 Epoch 287: Training Loss: 12.602049633357923, Validation Loss: 5.363649167659889
2024-07-30 20:59:54.885412525 +00:00 Epoch 288: Training Loss: 12.601732938822348, Validation Loss: 5.363526172128803
2024-07-30 21:00:12.217998199 +00:00 Epoch 289: Training Loss: 12.601401831168161, Validation Loss: 5.363228237043753
2024-07-30 21:00:29.496993772 +00:00 Epoch 290: Training Loss: 12.601050089512965, Validation Loss: 5.36315637909884
2024-07-30 21:00:46.855939102 +00:00 Epoch 291: Training Loss: 12.600792716944014, Validation Loss: 5.362818143493521
2024-07-30 21:01:04.156765698 +00:00 Epoch 292: Training Loss: 12.600423641752368, Validation Loss: 5.362762286128784
2024-07-30 21:01:21.202408731 +00:00 Epoch 293: Training Loss: 12.600154056683008, Validation Loss: 5.36245020888842
2024-07-30 21:01:38.407144469 +00:00 Epoch 294: Training Loss: 12.599817157438054, Validation Loss: 5.362387488001441
2024-07-30 21:01:55.531580851 +00:00 Epoch 295: Training Loss: 12.599552478375438, Validation Loss: 5.362078756579864
2024-07-30 21:02:12.695537844 +00:00 Epoch 296: Training Loss: 12.59921589293046, Validation Loss: 5.362030032741182
2024-07-30 21:02:29.938676731 +00:00 Epoch 297: Training Loss: 12.598983289026004, Validation Loss: 5.3617124013413555
2024-07-30 21:02:47.435228289 +00:00 Epoch 298: Training Loss: 12.598636992703248, Validation Loss: 5.361684779646099
2024-07-30 21:03:04.895718042 +00:00 Epoch 299: Training Loss: 12.598427132647712, Validation Loss: 5.361356572334466
2024-07-30 21:03:22.294586029 +00:00 Epoch 300: Training Loss: 12.598056061399099, Validation Loss: 5.3613314473236455
2024-07-30 21:03:39.720100889 +00:00 Epoch 301: Training Loss: 12.5978321857838, Validation Loss: 5.361046108144992
2024-07-30 21:03:57.235368814 +00:00 Epoch 302: Training Loss: 12.597563762875717, Validation Loss: 5.360970520467187
2024-07-30 21:04:14.585977251 +00:00 Epoch 303: Training Loss: 12.597266781488603, Validation Loss: 5.36070615381745
2024-07-30 21:04:31.881302010 +00:00 Epoch 304: Training Loss: 12.596928869824067, Validation Loss: 5.360694352186113
2024-07-30 21:04:49.150161186 +00:00 Epoch 305: Training Loss: 12.596785912180128, Validation Loss: 5.360358293991944
2024-07-30 21:05:06.503959895 +00:00 Epoch 306: Training Loss: 12.596416262846628, Validation Loss: 5.360356706964972
2024-07-30 21:05:23.919670460 +00:00 Epoch 307: Training Loss: 12.596224404933368, Validation Loss: 5.36008400645371
2024-07-30 21:05:41.254365522 +00:00 Epoch 308: Training Loss: 12.595881704622773, Validation Loss: 5.360059006065291
2024-07-30 21:05:58.674611552 +00:00 Epoch 309: Training Loss: 12.595690181737321, Validation Loss: 5.359771237069235
2024-07-30 21:06:16.276716567 +00:00 Epoch 310: Training Loss: 12.59528248130803, Validation Loss: 5.359790159652917
2024-07-30 21:06:33.824117481 +00:00 Epoch 311: Training Loss: 12.595185488626623, Validation Loss: 5.359468541114374
2024-07-30 21:06:51.348659474 +00:00 Epoch 312: Training Loss: 12.594747225782124, Validation Loss: 5.359507931165038
2024-07-30 21:07:09.793879135 +00:00 Epoch 313: Training Loss: 12.594727637784153, Validation Loss: 5.359144057400087
2024-07-30 21:07:27.245786038 +00:00 Epoch 314: Training Loss: 12.594252312975128, Validation Loss: 5.359199192519067
2024-07-30 21:07:44.303412374 +00:00 Epoch 315: Training Loss: 12.59418537151177, Validation Loss: 5.358909135816002
2024-07-30 21:08:01.476106692 +00:00 Epoch 316: Training Loss: 12.593834360901822, Validation Loss: 5.358868750750224
2024-07-30 21:08:18.769438649 +00:00 Epoch 317: Training Loss: 12.593766126760817, Validation Loss: 5.358561182788186
2024-07-30 21:08:35.958167397 +00:00 Epoch 318: Training Loss: 12.593246101972458, Validation Loss: 5.358639022662122
2024-07-30 21:08:53.392087548 +00:00 Epoch 319: Training Loss: 12.593179727515096, Validation Loss: 5.358343282580447
2024-07-30 21:09:10.814734360 +00:00 Epoch 320: Training Loss: 12.592845812024162, Validation Loss: 5.358341674451132
2024-07-30 21:09:28.317370828 +00:00 Epoch 321: Training Loss: 12.592780323630508, Validation Loss: 5.358033391964309
2024-07-30 21:09:45.723201393 +00:00 Epoch 322: Training Loss: 12.592244748580905, Validation Loss: 5.358093004134206
2024-07-30 21:10:03.220046788 +00:00 Epoch 323: Training Loss: 12.592191413072728, Validation Loss: 5.357787287769947
2024-07-30 21:10:20.602904554 +00:00 Epoch 324: Training Loss: 12.591905374049919, Validation Loss: 5.357894044341726
2024-07-30 21:10:37.790074247 +00:00 Epoch 325: Training Loss: 12.591821879719577, Validation Loss: 5.357527613651331
2024-07-30 21:10:55.085263951 +00:00 Epoch 326: Training Loss: 12.59146620255137, Validation Loss: 5.357549143882247
2024-07-30 21:11:12.514488324 +00:00 Epoch 327: Training Loss: 12.591321980411779, Validation Loss: 5.35726706298785
2024-07-30 21:11:30.141038050 +00:00 Epoch 328: Training Loss: 12.590988295184701, Validation Loss: 5.357361020310158
2024-07-30 21:11:47.539633580 +00:00 Epoch 329: Training Loss: 12.591101221691348, Validation Loss: 5.356953003738754
2024-07-30 21:12:04.782138855 +00:00 Epoch 330: Training Loss: 12.590510836012925, Validation Loss: 5.356939545979047
2024-07-30 21:12:21.708145064 +00:00 Epoch 331: Training Loss: 12.590269678255561, Validation Loss: 5.356806864349869
2024-07-30 21:12:37.689068745 +00:00 Epoch 332: Training Loss: 12.590014872957747, Validation Loss: 5.356763192657864
2024-07-30 21:12:53.388744170 +00:00 Epoch 333: Training Loss: 12.589926184662069, Validation Loss: 5.356531447875893
2024-07-30 21:13:09.024254700 +00:00 Epoch 334: Training Loss: 12.589932286476115, Validation Loss: 5.3564424169140485
2024-07-30 21:13:24.627135316 +00:00 Epoch 335: Training Loss: 12.589727866898986, Validation Loss: 5.356146165337771
2024-07-30 21:13:40.204318534 +00:00 Epoch 336: Training Loss: 12.589444450761478, Validation Loss: 5.356192843466671
2024-07-30 21:13:55.744016301 +00:00 Epoch 337: Training Loss: 12.58939263935207, Validation Loss: 5.355990140648142
2024-07-30 21:14:11.363692738 +00:00 Epoch 338: Training Loss: 12.58881702151135, Validation Loss: 5.3558776551506355
2024-07-30 21:14:26.929856245 +00:00 Epoch 339: Training Loss: 12.588860998377571, Validation Loss: 5.355892139754152
2024-07-30 21:14:42.487915496 +00:00 Epoch 340: Training Loss: 12.588746877752095, Validation Loss: 5.355529599639895
2024-07-30 21:14:58.073471354 +00:00 Epoch 341: Training Loss: 12.588258983802891, Validation Loss: 5.355553808378419
2024-07-30 21:15:13.738169286 +00:00 Epoch 342: Training Loss: 12.588295467285645, Validation Loss: 5.355309958438622
2024-07-30 21:15:29.287264318 +00:00 Epoch 343: Training Loss: 12.587818088307268, Validation Loss: 5.355341476426487
2024-07-30 21:15:45.135755160 +00:00 Epoch 344: Training Loss: 12.587813114503486, Validation Loss: 5.35509074808406
2024-07-30 21:16:01.414784603 +00:00 Epoch 345: Training Loss: 12.587490861017198, Validation Loss: 5.355169106815932
2024-07-30 21:16:18.028895339 +00:00 Epoch 346: Training Loss: 12.587566351660907, Validation Loss: 5.354875891467436
2024-07-30 21:16:34.767489733 +00:00 Epoch 347: Training Loss: 12.587082531654952, Validation Loss: 5.354766937814005
2024-07-30 21:16:51.830773140 +00:00 Epoch 348: Training Loss: 12.586960977884937, Validation Loss: 5.354827649105229
2024-07-30 21:17:08.863900408 +00:00 Epoch 349: Training Loss: 12.58679481328703, Validation Loss: 5.354471435561512
2024-07-30 21:17:25.985930376 +00:00 Epoch 350: Training Loss: 12.586731459749702, Validation Loss: 5.354503958478496
2024-07-30 21:17:43.095384969 +00:00 Epoch 351: Training Loss: 12.586370472283535, Validation Loss: 5.354308728321723
2024-07-30 21:18:00.214355700 +00:00 Epoch 352: Training Loss: 12.58617958131567, Validation Loss: 5.354379283021299
2024-07-30 21:18:17.234127667 +00:00 Epoch 353: Training Loss: 12.58613039342275, Validation Loss: 5.354081034887744
2024-07-30 21:18:34.162384050 +00:00 Epoch 354: Training Loss: 12.585556820786907, Validation Loss: 5.354068169206019
2024-07-30 21:18:51.415758994 +00:00 Epoch 355: Training Loss: 12.58536718380263, Validation Loss: 5.354054389069315
2024-07-30 21:19:08.616809437 +00:00 Epoch 356: Training Loss: 12.585534792784385, Validation Loss: 5.353827508050641
2024-07-30 21:19:25.995280301 +00:00 Epoch 357: Training Loss: 12.585355891849305, Validation Loss: 5.353734767476113
2024-07-30 21:19:43.154185696 +00:00 Epoch 358: Training Loss: 12.585374454702313, Validation Loss: 5.353581988916488
2024-07-30 21:20:00.394165366 +00:00 Epoch 359: Training Loss: 12.584961628760682, Validation Loss: 5.353487972457694
2024-07-30 21:20:17.555444299 +00:00 Epoch 360: Training Loss: 12.584544998291292, Validation Loss: 5.353536275009353
2024-07-30 21:20:35.053489550 +00:00 Epoch 361: Training Loss: 12.584712586107127, Validation Loss: 5.353294177314146
2024-07-30 21:20:52.337591103 +00:00 Epoch 362: Training Loss: 12.584064389553076, Validation Loss: 5.353319916469307
2024-07-30 21:21:09.677072810 +00:00 Epoch 363: Training Loss: 12.583813118897448, Validation Loss: 5.353364850253427
2024-07-30 21:21:27.124197742 +00:00 Epoch 364: Training Loss: 12.583924849446667, Validation Loss: 5.352993011778715
2024-07-30 21:21:44.477935980 +00:00 Epoch 365: Training Loss: 12.583973534270365, Validation Loss: 5.353101339305255
2024-07-30 21:22:01.654593074 +00:00 Epoch 366: Training Loss: 12.583386432441362, Validation Loss: 5.352885045937237
2024-07-30 21:22:18.633736221 +00:00 Epoch 367: Training Loss: 12.583421803649511, Validation Loss: 5.352997202790868
2024-07-30 21:22:35.554513505 +00:00 Epoch 368: Training Loss: 12.583290539525098, Validation Loss: 5.352809939430677
2024-07-30 21:22:52.507096857 +00:00 Epoch 369: Training Loss: 12.582893574811758, Validation Loss: 5.352713364325595
2024-07-30 21:23:09.482055588 +00:00 Epoch 370: Training Loss: 12.583053719157897, Validation Loss: 5.3527550395347845
2024-07-30 21:23:26.433044777 +00:00 Epoch 371: Training Loss: 12.582303874085449, Validation Loss: 5.352643575039129
2024-07-30 21:23:43.445865145 +00:00 Epoch 372: Training Loss: 12.582194032460418, Validation Loss: 5.352622749901716
2024-07-30 21:24:00.489297944 +00:00 Epoch 373: Training Loss: 12.582287473672253, Validation Loss: 5.352421165452734
2024-07-30 21:24:17.410807147 +00:00 Epoch 374: Training Loss: 12.58233862946289, Validation Loss: 5.3524044037319465
2024-07-30 21:24:34.619490400 +00:00 Epoch 375: Training Loss: 12.58181159412638, Validation Loss: 5.352360118393023
2024-07-30 21:24:51.937005660 +00:00 Epoch 376: Training Loss: 12.582052134999829, Validation Loss: 5.352110639927932
2024-07-30 21:25:09.116891467 +00:00 Epoch 377: Training Loss: 12.581454407253295, Validation Loss: 5.352241556951424
2024-07-30 21:25:26.155181179 +00:00 Epoch 378: Training Loss: 12.581403235599753, Validation Loss: 5.352038085840128
2024-07-30 21:25:43.155045042 +00:00 Epoch 379: Training Loss: 12.581425656434414, Validation Loss: 5.352162487388466
2024-07-30 21:26:00.268743951 +00:00 Epoch 380: Training Loss: 12.580812531850034, Validation Loss: 5.352086782647368
2024-07-30 21:26:17.366901303 +00:00 Epoch 381: Training Loss: 12.580630366942291, Validation Loss: 5.351997628435841
2024-07-30 21:26:34.404838696 +00:00 Epoch 382: Training Loss: 12.580960584608528, Validation Loss: 5.3520243762867725
2024-07-30 21:26:51.439415933 +00:00 Epoch 383: Training Loss: 12.580770443858874, Validation Loss: 5.351911342810708
2024-07-30 21:27:08.491721830 +00:00 Epoch 384: Training Loss: 12.580351096282353, Validation Loss: 5.3518828642356
2024-07-30 21:27:25.519000816 +00:00 Epoch 385: Training Loss: 12.58050185559667, Validation Loss: 5.35189278783778
2024-07-30 21:27:42.523776705 +00:00 Epoch 386: Training Loss: 12.580057028722969, Validation Loss: 5.351641844127808
2024-07-30 21:27:59.422159101 +00:00 Epoch 387: Training Loss: 12.58016867913717, Validation Loss: 5.351779789709636
2024-07-30 21:28:16.577668748 +00:00 Epoch 388: Training Loss: 12.580106861223271, Validation Loss: 5.351658159798184
2024-07-30 21:28:33.633472948 +00:00 Epoch 389: Training Loss: 12.579736323937771, Validation Loss: 5.351661125561235
2024-07-30 21:28:50.539019699 +00:00 Epoch 390: Training Loss: 12.579293690835714, Validation Loss: 5.351810402269096
2024-07-30 21:29:07.573933132 +00:00 Epoch 391: Training Loss: 12.579477080812634, Validation Loss: 5.351548307447902
2024-07-30 21:29:24.663701728 +00:00 Epoch 392: Training Loss: 12.579149531862017, Validation Loss: 5.351440064883377
2024-07-30 21:29:41.651048872 +00:00 Epoch 393: Training Loss: 12.579332538809505, Validation Loss: 5.351517219916529
2024-07-30 21:29:58.305838719 +00:00 Epoch 394: Training Loss: 12.578740117069371, Validation Loss: 5.351488031124091
2024-07-30 21:30:15.270325773 +00:00 Epoch 395: Training Loss: 12.578927801692203, Validation Loss: 5.351446289692429
2024-07-30 21:30:32.171593086 +00:00 Epoch 396: Training Loss: 12.578616513517348, Validation Loss: 5.35140417918738
2024-07-30 21:30:49.378122704 +00:00 Epoch 397: Training Loss: 12.578132765001483, Validation Loss: 5.351450898634625
2024-07-30 21:31:06.515906475 +00:00 Epoch 398: Training Loss: 12.57797321364994, Validation Loss: 5.351358101765147
2024-07-30 21:31:23.571846687 +00:00 Epoch 399: Training Loss: 12.578264338931668, Validation Loss: 5.351367915709836
2024-07-30 21:31:40.759014055 +00:00 Epoch 400: Training Loss: 12.577835108615313, Validation Loss: 5.351185675987903
2024-07-30 21:31:57.688506289 +00:00 Epoch 401: Training Loss: 12.577998542422208, Validation Loss: 5.351267666044216
2024-07-30 21:32:14.671908932 +00:00 Epoch 402: Training Loss: 12.577748391497552, Validation Loss: 5.351164104329865
2024-07-30 21:32:31.741200324 +00:00 Epoch 403: Training Loss: 12.57751738132831, Validation Loss: 5.351242839809097
2024-07-30 21:32:48.681054765 +00:00 Epoch 404: Training Loss: 12.577508275682229, Validation Loss: 5.351216832078
2024-07-30 21:33:05.383675073 +00:00 Epoch 405: Training Loss: 12.577265666085047, Validation Loss: 5.35127401361383
2024-07-30 21:33:22.152834642 +00:00 Epoch 406: Training Loss: 12.576980484846759, Validation Loss: 5.351261983183411
2024-07-30 21:33:38.806582106 +00:00 Epoch 407: Training Loss: 12.57689212299056, Validation Loss: 5.350991740706119
2024-07-30 21:33:55.560161836 +00:00 Epoch 408: Training Loss: 12.57711556121196, Validation Loss: 5.350901665822619
2024-07-30 21:34:12.308919265 +00:00 Epoch 409: Training Loss: 12.576893598407505, Validation Loss: 5.350987202234481
2024-07-30 21:34:29.184081702 +00:00 Epoch 410: Training Loss: 12.576701254587876, Validation Loss: 5.35092809143892
2024-07-30 21:34:46.149839084 +00:00 Epoch 411: Training Loss: 12.576533283015692, Validation Loss: 5.350948580798186
2024-07-30 21:35:02.898255557 +00:00 Epoch 412: Training Loss: 12.576334363023078, Validation Loss: 5.350879733207334
2024-07-30 21:35:19.597549320 +00:00 Epoch 413: Training Loss: 12.57607480402131, Validation Loss: 5.35090790679385
2024-07-30 21:35:36.501995568 +00:00 Epoch 414: Training Loss: 12.576033292059877, Validation Loss: 5.350764971177175
2024-07-30 21:35:53.145604385 +00:00 Epoch 415: Training Loss: 12.575730770060678, Validation Loss: 5.350888403555893
2024-07-30 21:36:09.610962317 +00:00 Epoch 416: Training Loss: 12.57558692522263, Validation Loss: 5.350623588739781
2024-07-30 21:36:26.440348055 +00:00 Epoch 417: Training Loss: 12.57579333111131, Validation Loss: 5.350623711298073
2024-07-30 21:36:43.442436023 +00:00 Epoch 418: Training Loss: 12.575550761115712, Validation Loss: 5.350547797874524
2024-07-30 21:37:00.309839121 +00:00 Epoch 419: Training Loss: 12.575429523776714, Validation Loss: 5.350700032830589
2024-07-30 21:37:16.998393022 +00:00 Epoch 420: Training Loss: 12.5752070083444, Validation Loss: 5.350469973734655
2024-07-30 21:37:33.902408680 +00:00 Epoch 421: Training Loss: 12.575092113064176, Validation Loss: 5.35069828257015
2024-07-30 21:37:50.863114352 +00:00 Epoch 422: Training Loss: 12.574757630379894, Validation Loss: 5.350450731345398
2024-07-30 21:38:07.713947 +00:00 Epoch 423: Training Loss: 12.574746840851786, Validation Loss: 5.3506732971744455
2024-07-30 21:38:24.638775091 +00:00 Epoch 424: Training Loss: 12.574065191740127, Validation Loss: 5.350414502996589
2024-07-30 21:38:41.721995843 +00:00 Epoch 425: Training Loss: 12.57450402320828, Validation Loss: 5.350457551881839
2024-07-30 21:38:58.620144157 +00:00 Epoch 426: Training Loss: 12.574455714584277, Validation Loss: 5.350152535154064
2024-07-30 21:39:15.556594278 +00:00 Epoch 427: Training Loss: 12.57423930361438, Validation Loss: 5.350531839948661
2024-07-30 21:39:32.028961950 +00:00 Epoch 428: Training Loss: 12.574134170774828, Validation Loss: 5.350139965455132
2024-07-30 21:39:48.783112648 +00:00 Epoch 429: Training Loss: 12.574065035373351, Validation Loss: 5.350303229220184
2024-07-30 21:40:05.799517886 +00:00 Epoch 430: Training Loss: 12.57379310628024, Validation Loss: 5.35004885916304
2024-07-30 21:40:22.642464922 +00:00 Epoch 431: Training Loss: 12.573675088343055, Validation Loss: 5.350337248682393
2024-07-30 21:40:39.067443122 +00:00 Epoch 432: Training Loss: 12.573526078776785, Validation Loss: 5.3500643392803084
2024-07-30 21:40:55.577132090 +00:00 Epoch 433: Training Loss: 12.573512092208059, Validation Loss: 5.350155710155904
2024-07-30 21:41:12.192037629 +00:00 Epoch 434: Training Loss: 12.573183600693774, Validation Loss: 5.349885295565235
2024-07-30 21:41:28.641266461 +00:00 Epoch 435: Training Loss: 12.573321542118219, Validation Loss: 5.350041212845887
2024-07-30 21:41:45.298903898 +00:00 Epoch 436: Training Loss: 12.573023306681335, Validation Loss: 5.349748714031747
2024-07-30 21:42:02.235998926 +00:00 Epoch 437: Training Loss: 12.572838741995856, Validation Loss: 5.350084720556393
2024-07-30 21:42:18.748100243 +00:00 Epoch 438: Training Loss: 12.572896549518969, Validation Loss: 5.3497620971268525
2024-07-30 21:42:34.788714768 +00:00 Epoch 439: Training Loss: 12.57280948575608, Validation Loss: 5.349982683658445
2024-07-30 21:42:51.277253249 +00:00 Epoch 440: Training Loss: 12.57247389221252, Validation Loss: 5.349543017979047
2024-07-30 21:43:08.279659871 +00:00 Epoch 441: Training Loss: 12.572566703666118, Validation Loss: 5.349835364895322
2024-07-30 21:43:25.021013683 +00:00 Epoch 442: Training Loss: 12.57212566305349, Validation Loss: 5.3495745082066195
2024-07-30 21:43:41.412815767 +00:00 Epoch 443: Training Loss: 12.572265567925019, Validation Loss: 5.349799336503073
2024-07-30 21:43:58.416364716 +00:00 Epoch 444: Training Loss: 12.572049329196034, Validation Loss: 5.349374291103051
2024-07-30 21:44:15.261835502 +00:00 Epoch 445: Training Loss: 12.571960335667356, Validation Loss: 5.349669689165358
2024-07-30 21:44:32.015622351 +00:00 Epoch 446: Training Loss: 12.571706992751551, Validation Loss: 5.349327607891971
2024-07-30 21:44:48.966990390 +00:00 Epoch 447: Training Loss: 12.571686959640253, Validation Loss: 5.349595530707549
2024-07-30 21:45:06.162752644 +00:00 Epoch 448: Training Loss: 12.57143089979788, Validation Loss: 5.349267945689146
2024-07-30 21:45:23.102777854 +00:00 Epoch 449: Training Loss: 12.57140161521874, Validation Loss: 5.349549934497567
2024-07-30 21:45:39.937509925 +00:00 Epoch 450: Training Loss: 12.570968348677827, Validation Loss: 5.349271511228208
2024-07-30 21:45:57.128793881 +00:00 Epoch 451: Training Loss: 12.571367543527682, Validation Loss: 5.349520925532044
2024-07-30 21:46:14.317257370 +00:00 Epoch 452: Training Loss: 12.571098415931024, Validation Loss: 5.349186754221525
2024-07-30 21:46:31.322313975 +00:00 Epoch 453: Training Loss: 12.570990704419444, Validation Loss: 5.349443144716505
2024-07-30 21:46:48.348016260 +00:00 Epoch 454: Training Loss: 12.57070128601025, Validation Loss: 5.349094483387496
2024-07-30 21:47:05.364056329 +00:00 Epoch 455: Training Loss: 12.57067140218385, Validation Loss: 5.349367868731337
2024-07-30 21:47:22.456802495 +00:00 Epoch 456: Training Loss: 12.569913727799054, Validation Loss: 5.349089177980119
2024-07-30 21:47:39.511117326 +00:00 Epoch 457: Training Loss: 12.569685083711637, Validation Loss: 5.349400987686205
2024-07-30 21:47:56.712105320 +00:00 Epoch 458: Training Loss: 12.56923549654386, Validation Loss: 5.348848076930129
2024-07-30 21:48:13.941997891 +00:00 Epoch 459: Training Loss: 12.569065095774468, Validation Loss: 5.349195534104578
2024-07-30 21:48:30.959395895 +00:00 Epoch 460: Training Loss: 12.568648159278696, Validation Loss: 5.3487492342978875
2024-07-30 21:48:48.067219019 +00:00 Epoch 461: Training Loss: 12.568650902825592, Validation Loss: 5.349101900326488
2024-07-30 21:49:05.319715632 +00:00 Epoch 462: Training Loss: 12.568166000459348, Validation Loss: 5.3486212706804785
2024-07-30 21:49:22.560708607 +00:00 Epoch 463: Training Loss: 12.568252908266413, Validation Loss: 5.34897501356134
2024-07-30 21:49:40.027476607 +00:00 Epoch 464: Training Loss: 12.568154025655085, Validation Loss: 5.348489445312766
2024-07-30 21:49:57.188558817 +00:00 Epoch 465: Training Loss: 12.568134413978871, Validation Loss: 5.348707667853816
2024-07-30 21:50:14.201774212 +00:00 Epoch 466: Training Loss: 12.567762599939217, Validation Loss: 5.3483006203707015
2024-07-30 21:50:31.528118171 +00:00 Epoch 467: Training Loss: 12.567857318896312, Validation Loss: 5.348667137012397
2024-07-30 21:50:48.954285602 +00:00 Epoch 468: Training Loss: 12.567486709829652, Validation Loss: 5.348175005709743
2024-07-30 21:51:06.306700001 +00:00 Epoch 469: Training Loss: 12.567569228503674, Validation Loss: 5.3485688000833616
2024-07-30 21:51:23.523963243 +00:00 Epoch 470: Training Loss: 12.567209771260417, Validation Loss: 5.348071256056202
2024-07-30 21:51:40.668910642 +00:00 Epoch 471: Training Loss: 12.567294128949198, Validation Loss: 5.348484086709116
2024-07-30 21:51:57.949931175 +00:00 Epoch 472: Training Loss: 12.56692724677648, Validation Loss: 5.3479842613918365
2024-07-30 21:52:15.019751823 +00:00 Epoch 473: Training Loss: 12.56701642674542, Validation Loss: 5.348406635741837
2024-07-30 21:52:32.073982577 +00:00 Epoch 474: Training Loss: 12.566652876430892, Validation Loss: 5.347900249434929
2024-07-30 21:52:49.224797517 +00:00 Epoch 475: Training Loss: 12.566749288372096, Validation Loss: 5.34833479643318
2024-07-30 21:53:06.518680871 +00:00 Epoch 476: Training Loss: 12.566380270895813, Validation Loss: 5.34782173962926
2024-07-30 21:53:23.909449463 +00:00 Epoch 477: Training Loss: 12.566482801307824, Validation Loss: 5.348264040005879
2024-07-30 21:53:41.360154172 +00:00 Epoch 478: Training Loss: 12.566112264296086, Validation Loss: 5.347743472221982
2024-07-30 21:53:58.791994612 +00:00 Epoch 479: Training Loss: 12.566220245478537, Validation Loss: 5.3481922572282645
2024-07-30 21:54:15.822303229 +00:00 Epoch 480: Training Loss: 12.565848221363057, Validation Loss: 5.347664556820471
2024-07-30 21:54:33.002088352 +00:00 Epoch 481: Training Loss: 12.56595767017534, Validation Loss: 5.348117024389752
2024-07-30 21:54:50.359240636 +00:00 Epoch 482: Training Loss: 12.56558688632296, Validation Loss: 5.347583066919339
2024-07-30 21:55:07.648521013 +00:00 Epoch 483: Training Loss: 12.565696201293926, Validation Loss: 5.348039673793903
2024-07-30 21:55:24.888692284 +00:00 Epoch 484: Training Loss: 12.56532791342081, Validation Loss: 5.347500665264804
2024-07-30 21:55:42.310682931 +00:00 Epoch 485: Training Loss: 12.565436460414755, Validation Loss: 5.347960874979604
2024-07-30 21:55:59.489090659 +00:00 Epoch 486: Training Loss: 12.565071919321674, Validation Loss: 5.3474167233818175
2024-07-30 21:56:18.430366627 +00:00 Epoch 487: Training Loss: 12.565178735997964, Validation Loss: 5.347883338490504
2024-07-30 21:56:35.589871614 +00:00 Epoch 488: Training Loss: 12.564816733804268, Validation Loss: 5.347331548380554
2024-07-30 21:56:52.755446434 +00:00 Epoch 489: Training Loss: 12.564924521961423, Validation Loss: 5.347810352031181
2024-07-30 21:57:09.858047789 +00:00 Epoch 490: Training Loss: 12.56456417557902, Validation Loss: 5.347251334163332
2024-07-30 21:57:26.927994578 +00:00 Epoch 491: Training Loss: 12.564669260735656, Validation Loss: 5.347742794516547
2024-07-30 21:57:44.147133436 +00:00 Epoch 492: Training Loss: 12.564309824581803, Validation Loss: 5.347182497746863
2024-07-30 21:58:01.217394466 +00:00 Epoch 493: Training Loss: 12.564409501598764, Validation Loss: 5.347681205030459
2024-07-30 21:58:18.394386416 +00:00 Epoch 494: Training Loss: 12.56405489957171, Validation Loss: 5.34712339172531
2024-07-30 21:58:35.636282348 +00:00 Epoch 495: Training Loss: 12.564147518655238, Validation Loss: 5.347626176616127
2024-07-30 21:58:53.012625804 +00:00 Epoch 496: Training Loss: 12.56380369680562, Validation Loss: 5.347065282075688
2024-07-30 21:59:10.392809519 +00:00 Epoch 497: Training Loss: 12.563892028944569, Validation Loss: 5.347578736729116
2024-07-30 21:59:27.796299841 +00:00 Epoch 498: Training Loss: 12.563555170421633, Validation Loss: 5.3470108173933575
2024-07-30 21:59:45.059402013 +00:00 Epoch 499: Training Loss: 12.563637610695885, Validation Loss: 5.347535387127344
2024-07-30 22:00:02.303141206 +00:00 Epoch 500: Training Loss: 12.563306189577663, Validation Loss: 5.346962823140881
