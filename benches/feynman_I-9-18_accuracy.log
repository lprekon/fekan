2ef7f78db3404205649df7398b507226f84a8700
Using arguments Cli { command: Build(BuildArgs { model_type: Regressor(RegressorArgs { labels: None, params: GenericBuildParams { degree: 3, num_coefficients: 4, hidden_layer_sizes: Some([4, 2, 1]), training_parameters: TrainArgs { data_file: "/tmp/tmp.ZTyc8mUkX2.json", num_epochs: 500, knot_update_interval: 100, knot_adaptivity: 0.1, learning_rate: 0.001, knot_extension_targets: Some([10, 20, 50]), knot_extension_times: Some([50, 100, 250]), validate_each_epoch: true, validation_split: 0.2, model_output_file: None, no_save: true } } }) }), log_output: true, num_threads: None }
Thread count not specified. Using 4 threads
Loading regression data from file: "/tmp/tmp.ZTyc8mUkX2.json"
creating validation set
Data loaded. Training: 80000, Validation: 20000
2024-07-22 23:09:28.178276115 +00:00 Epoch 1: Training Loss: 77.71358722339966, Validation Loss: 3.2688308153003423
2024-07-22 23:09:53.390911611 +00:00 Epoch 2: Training Loss: 77.71665997858946, Validation Loss: 3.2754163537121967
2024-07-22 23:10:18.419025877 +00:00 Epoch 3: Training Loss: 77.7135242024472, Validation Loss: 3.271063887238427
2024-07-22 23:10:43.532100791 +00:00 Epoch 4: Training Loss: 77.71689789793432, Validation Loss: 3.2610255197646265
2024-07-22 23:11:08.680498667 +00:00 Epoch 5: Training Loss: 77.71945525798354, Validation Loss: 3.2568281592796846
2024-07-22 23:11:34.069459252 +00:00 Epoch 6: Training Loss: 77.71751220601949, Validation Loss: 3.2660720918601163
2024-07-22 23:11:59.105984811 +00:00 Epoch 7: Training Loss: 77.70581542923804, Validation Loss: 3.2525885237743015
2024-07-22 23:12:24.014227822 +00:00 Epoch 8: Training Loss: 77.69917278627803, Validation Loss: 3.270095072872666
2024-07-22 23:12:48.978572249 +00:00 Epoch 9: Training Loss: 77.71046899336292, Validation Loss: 3.2708121636107683
2024-07-22 23:13:13.900892050 +00:00 Epoch 10: Training Loss: 77.68735176046958, Validation Loss: 3.2716668138159153
2024-07-22 23:13:38.758536546 +00:00 Epoch 11: Training Loss: 77.7002498729992, Validation Loss: 3.281516281606481
2024-07-22 23:14:04.062792547 +00:00 Epoch 12: Training Loss: 77.68839842525756, Validation Loss: 3.2358192146895113
2024-07-22 23:14:29.034863536 +00:00 Epoch 13: Training Loss: 77.7013144555849, Validation Loss: 3.238014945057565
2024-07-22 23:14:54.006472086 +00:00 Epoch 14: Training Loss: 77.73206594796127, Validation Loss: 3.218927215728763
2024-07-22 23:15:18.989625816 +00:00 Epoch 15: Training Loss: 77.69047699922146, Validation Loss: 3.2332890798550498
2024-07-22 23:15:43.857198733 +00:00 Epoch 16: Training Loss: 77.72277874062522, Validation Loss: 3.2700350214297074
2024-07-22 23:16:08.802465051 +00:00 Epoch 17: Training Loss: 77.7419842127378, Validation Loss: 3.254258140103863
2024-07-22 23:16:34.031517535 +00:00 Epoch 18: Training Loss: 77.73888017349961, Validation Loss: 3.2887475719322343
2024-07-22 23:16:58.869284914 +00:00 Epoch 19: Training Loss: 77.76496216415744, Validation Loss: 3.292907188222064
2024-07-22 23:17:23.919997959 +00:00 Epoch 20: Training Loss: 77.74425373541702, Validation Loss: 3.2723443873191957
2024-07-22 23:17:48.781043383 +00:00 Epoch 21: Training Loss: 77.71272036466675, Validation Loss: 3.2483323778444677
2024-07-22 23:18:13.914040569 +00:00 Epoch 22: Training Loss: 77.69894016632024, Validation Loss: 3.255484208842619
2024-07-22 23:18:39.244699012 +00:00 Epoch 23: Training Loss: 77.68945822926767, Validation Loss: 3.257499589479377
2024-07-22 23:19:04.626052973 +00:00 Epoch 24: Training Loss: 77.73672139072504, Validation Loss: 3.2549151564559162
2024-07-22 23:19:29.929805600 +00:00 Epoch 25: Training Loss: 77.7254719723713, Validation Loss: 3.2815706270265625
2024-07-22 23:19:54.691939648 +00:00 Epoch 26: Training Loss: 77.70774537074166, Validation Loss: 3.2496537574295346
2024-07-22 23:20:19.640677184 +00:00 Epoch 27: Training Loss: 77.71088089025902, Validation Loss: 3.244010427879951
2024-07-22 23:20:44.347665171 +00:00 Epoch 28: Training Loss: 77.68458845474596, Validation Loss: 3.233686764030028
2024-07-22 23:21:09.097325060 +00:00 Epoch 29: Training Loss: 77.68968490996384, Validation Loss: 3.2528440209657177
2024-07-22 23:21:34.396339140 +00:00 Epoch 30: Training Loss: 77.6876114111842, Validation Loss: 3.2576507725851886
2024-07-22 23:21:58.959603269 +00:00 Epoch 31: Training Loss: 77.68926474139765, Validation Loss: 3.2412208318040046
2024-07-22 23:22:23.787306386 +00:00 Epoch 32: Training Loss: 77.71535507085572, Validation Loss: 3.2225557640129168
2024-07-22 23:22:48.560095988 +00:00 Epoch 33: Training Loss: 77.69483297358843, Validation Loss: 3.3234263687995735
2024-07-22 23:23:13.299492533 +00:00 Epoch 34: Training Loss: 77.73127103468585, Validation Loss: 3.2785899893004005
2024-07-22 23:23:38.296053899 +00:00 Epoch 35: Training Loss: 77.70897419177902, Validation Loss: 3.2898984537709306
2024-07-22 23:24:03.450210649 +00:00 Epoch 36: Training Loss: 77.70617369724633, Validation Loss: 3.293517786612464
2024-07-22 23:24:28.356832861 +00:00 Epoch 37: Training Loss: 77.67588061749275, Validation Loss: 3.246566034137919
2024-07-22 23:24:53.111569924 +00:00 Epoch 38: Training Loss: 77.7173614962809, Validation Loss: 3.2720329470393295
2024-07-22 23:25:18.285820518 +00:00 Epoch 39: Training Loss: 77.74871443744003, Validation Loss: 3.2862197545899696
2024-07-22 23:25:43.604241325 +00:00 Epoch 40: Training Loss: 77.72742782103319, Validation Loss: 3.2792392441343696
2024-07-22 23:26:08.492573796 +00:00 Epoch 41: Training Loss: 77.71781819150625, Validation Loss: 3.2658335022107146
2024-07-22 23:26:33.658210785 +00:00 Epoch 42: Training Loss: 77.70161419467347, Validation Loss: 3.276136961787624
2024-07-22 23:26:58.522641043 +00:00 Epoch 43: Training Loss: 77.70032034578067, Validation Loss: 3.2414251254734383
2024-07-22 23:27:23.358851146 +00:00 Epoch 44: Training Loss: 77.66999091926176, Validation Loss: 3.280555838241979
2024-07-22 23:27:48.142967710 +00:00 Epoch 45: Training Loss: 77.68591805430836, Validation Loss: 3.2436269281114436
2024-07-22 23:28:12.997502263 +00:00 Epoch 46: Training Loss: 77.66887463528624, Validation Loss: 3.2889467884634076
2024-07-22 23:28:37.790184296 +00:00 Epoch 47: Training Loss: 77.68842655179287, Validation Loss: 3.257764872499548
2024-07-22 23:29:03.109345401 +00:00 Epoch 48: Training Loss: 77.6694426831171, Validation Loss: 3.2555896486228013
2024-07-22 23:29:27.932174184 +00:00 Epoch 49: Training Loss: 77.66717206463595, Validation Loss: 3.2405777674173137
2024-07-22 23:29:52.791931355 +00:00 Epoch 50: Training Loss: 77.68831651039437, Validation Loss: 3.222892173237825
2024-07-22 23:29:52.802450137 +00:00 Extending knot vectors from 8 to 10
2024-07-22 23:30:20.899864597 +00:00 Epoch 51: Training Loss: 77.6645299526808, Validation Loss: 3.2220224054317264
2024-07-22 23:30:49.084225216 +00:00 Epoch 52: Training Loss: 77.66414709786015, Validation Loss: 3.257736372062876
2024-07-22 23:31:17.311136067 +00:00 Epoch 53: Training Loss: 77.66362047698192, Validation Loss: 3.2234754766381446
2024-07-22 23:31:45.593909230 +00:00 Epoch 54: Training Loss: 77.69467799591209, Validation Loss: 3.2079871488533134
2024-07-22 23:32:13.393399365 +00:00 Epoch 55: Training Loss: 77.65079614419999, Validation Loss: 3.2374205540460044
2024-07-22 23:32:41.248897099 +00:00 Epoch 56: Training Loss: 77.655695689126, Validation Loss: 3.2199412271037677
2024-07-22 23:33:09.058958040 +00:00 Epoch 57: Training Loss: 77.65892521450712, Validation Loss: 3.231987690800345
2024-07-22 23:33:36.877459769 +00:00 Epoch 58: Training Loss: 77.70587530209285, Validation Loss: 3.2354703598428807
2024-07-22 23:34:05.232270841 +00:00 Epoch 59: Training Loss: 77.64887123063036, Validation Loss: 3.2426213596929463
2024-07-22 23:34:33.150258844 +00:00 Epoch 60: Training Loss: 77.67225929512222, Validation Loss: 3.219846397720601
2024-07-22 23:35:01.151442321 +00:00 Epoch 61: Training Loss: 77.66358876977564, Validation Loss: 3.231062096017614
2024-07-22 23:35:29.022197665 +00:00 Epoch 62: Training Loss: 77.65520151788361, Validation Loss: 3.2142286482807214
2024-07-22 23:35:56.894266933 +00:00 Epoch 63: Training Loss: 77.66375958626803, Validation Loss: 3.2170046446789327
2024-07-22 23:36:24.944673181 +00:00 Epoch 64: Training Loss: 77.71249455873534, Validation Loss: 3.234745699771387
2024-07-22 23:36:52.955803506 +00:00 Epoch 65: Training Loss: 77.6636840520637, Validation Loss: 3.226659125474242
2024-07-22 23:37:20.908745195 +00:00 Epoch 66: Training Loss: 77.67583959635226, Validation Loss: 3.283247160508486
2024-07-22 23:37:48.695247706 +00:00 Epoch 67: Training Loss: 77.71496635196867, Validation Loss: 3.2903314593387107
2024-07-22 23:38:16.431657341 +00:00 Epoch 68: Training Loss: 77.70247433145785, Validation Loss: 3.279599103811801
2024-07-22 23:38:44.600556934 +00:00 Epoch 69: Training Loss: 77.70915352854321, Validation Loss: 3.2999105643653603
2024-07-22 23:39:12.784751302 +00:00 Epoch 70: Training Loss: 77.73937174111909, Validation Loss: 3.2556279845813894
2024-07-22 23:39:40.560472665 +00:00 Epoch 71: Training Loss: 77.69845158825618, Validation Loss: 3.2830430146339844
2024-07-22 23:40:08.528121799 +00:00 Epoch 72: Training Loss: 77.73393099807947, Validation Loss: 3.273164971696741
2024-07-22 23:40:36.410982502 +00:00 Epoch 73: Training Loss: 77.69375853531943, Validation Loss: 3.273378708265382
2024-07-22 23:41:04.605972068 +00:00 Epoch 74: Training Loss: 77.70752439288255, Validation Loss: 3.27079583576074
2024-07-22 23:41:32.918832066 +00:00 Epoch 75: Training Loss: 77.70446750530304, Validation Loss: 3.2664420748399996
2024-07-22 23:42:01.175889538 +00:00 Epoch 76: Training Loss: 77.71582653669215, Validation Loss: 3.2455291861457254
2024-07-22 23:42:29.254778657 +00:00 Epoch 77: Training Loss: 77.71345264531423, Validation Loss: 3.2324512715095888
2024-07-22 23:42:57.169703035 +00:00 Epoch 78: Training Loss: 77.6707413729776, Validation Loss: 3.2540919917112787
2024-07-22 23:43:25.148642066 +00:00 Epoch 79: Training Loss: 77.69578373822388, Validation Loss: 3.2316185367611436
2024-07-22 23:43:53.133204753 +00:00 Epoch 80: Training Loss: 77.69604095126954, Validation Loss: 3.2275406375912774
2024-07-22 23:44:21.099343218 +00:00 Epoch 81: Training Loss: 77.66730016785515, Validation Loss: 3.242706844624527
2024-07-22 23:44:48.926596194 +00:00 Epoch 82: Training Loss: 77.69655448254501, Validation Loss: 3.240907969731545
2024-07-22 23:45:16.833024520 +00:00 Epoch 83: Training Loss: 77.68201238006561, Validation Loss: 3.2275037663914414
2024-07-22 23:45:44.519997917 +00:00 Epoch 84: Training Loss: 77.67500349477861, Validation Loss: 3.2159967175184256
2024-07-22 23:46:12.340280549 +00:00 Epoch 85: Training Loss: 77.6624164817918, Validation Loss: 3.2265753897174037
2024-07-22 23:46:40.416691358 +00:00 Epoch 86: Training Loss: 77.66522674341536, Validation Loss: 3.2478016883098206
2024-07-22 23:47:08.326008683 +00:00 Epoch 87: Training Loss: 77.66561264153209, Validation Loss: 3.2297473601138247
2024-07-22 23:47:36.781080182 +00:00 Epoch 88: Training Loss: 77.65476942139796, Validation Loss: 3.244528163834389
2024-07-22 23:48:04.919470947 +00:00 Epoch 89: Training Loss: 77.65366660600141, Validation Loss: 3.280020923402671
2024-07-22 23:48:33.155935403 +00:00 Epoch 90: Training Loss: 77.6898489469563, Validation Loss: 3.218983365941352
2024-07-22 23:49:01.545761129 +00:00 Epoch 91: Training Loss: 77.65527482606805, Validation Loss: 3.2398487429513745
2024-07-22 23:49:29.526348023 +00:00 Epoch 92: Training Loss: 77.64837422888918, Validation Loss: 3.2296119726040184
2024-07-22 23:49:57.210124063 +00:00 Epoch 93: Training Loss: 77.643667234293, Validation Loss: 3.225788824513068
2024-07-22 23:50:25.269215767 +00:00 Epoch 94: Training Loss: 77.68462121290673, Validation Loss: 3.2185955394773607
2024-07-22 23:50:53.303591604 +00:00 Epoch 95: Training Loss: 77.65241921474824, Validation Loss: 3.221703181476741
2024-07-22 23:51:21.540721919 +00:00 Epoch 96: Training Loss: 77.64478309479225, Validation Loss: 3.222779495707782
2024-07-22 23:51:49.411180405 +00:00 Epoch 97: Training Loss: 77.66498870953383, Validation Loss: 3.2236253374119745
2024-07-22 23:52:17.419281380 +00:00 Epoch 98: Training Loss: 77.65184188925562, Validation Loss: 3.2237262748432327
2024-07-22 23:52:45.338164760 +00:00 Epoch 99: Training Loss: 77.64426124234258, Validation Loss: 3.2187617321698765
2024-07-22 23:53:13.294089326 +00:00 Epoch 100: Training Loss: 77.65517087451772, Validation Loss: 3.226731296530614
2024-07-22 23:53:13.312002123 +00:00 Extending knot vectors from 10 to 20
2024-07-22 23:53:55.712656697 +00:00 Epoch 101: Training Loss: 77.65125677944388, Validation Loss: 3.250774342069091
2024-07-22 23:54:38.079020679 +00:00 Epoch 102: Training Loss: 77.64551915917428, Validation Loss: 3.2216141091894848
2024-07-22 23:55:20.191251748 +00:00 Epoch 103: Training Loss: 77.64147194267537, Validation Loss: 3.2277742884366156
2024-07-22 23:56:02.588474119 +00:00 Epoch 104: Training Loss: 77.63817393946017, Validation Loss: 3.216927218037728
2024-07-22 23:56:44.937618516 +00:00 Epoch 105: Training Loss: 77.63685291800502, Validation Loss: 3.2288619143869455
2024-07-22 23:57:26.880281676 +00:00 Epoch 106: Training Loss: 77.63446478978165, Validation Loss: 3.2183365385662923
2024-07-22 23:58:08.680116525 +00:00 Epoch 107: Training Loss: 77.65149084359815, Validation Loss: 3.233520746603393
2024-07-22 23:58:50.737093528 +00:00 Epoch 108: Training Loss: 77.63059216130233, Validation Loss: 3.217394093967951
2024-07-22 23:59:32.684798476 +00:00 Epoch 109: Training Loss: 77.62740666211128, Validation Loss: 3.2169107508715418
2024-07-23 00:00:15.157192631 +00:00 Epoch 110: Training Loss: 77.64879858482641, Validation Loss: 3.2227486185226706
2024-07-23 00:00:57.814111927 +00:00 Epoch 111: Training Loss: 77.64118118366282, Validation Loss: 3.2150828002160257
2024-07-23 00:01:39.868929170 +00:00 Epoch 112: Training Loss: 77.64436676905794, Validation Loss: 3.2334966582967724
2024-07-23 00:02:22.568656956 +00:00 Epoch 113: Training Loss: 77.6328367926535, Validation Loss: 3.2186969819871742
2024-07-23 00:03:04.986502363 +00:00 Epoch 114: Training Loss: 77.64472198590305, Validation Loss: 3.210951529467586
2024-07-23 00:03:47.092749932 +00:00 Epoch 115: Training Loss: 77.6337199198501, Validation Loss: 3.21094162956724
2024-07-23 00:04:29.388066171 +00:00 Epoch 116: Training Loss: 77.63314566979325, Validation Loss: 3.2149362976815445
2024-07-23 00:05:11.054094596 +00:00 Epoch 117: Training Loss: 77.62977722426547, Validation Loss: 3.225687886947761
2024-07-23 00:05:52.866563541 +00:00 Epoch 118: Training Loss: 77.63132820085117, Validation Loss: 3.217970453767824
2024-07-23 00:06:34.943443827 +00:00 Epoch 119: Training Loss: 77.64294847792922, Validation Loss: 3.2170153674229174
2024-07-23 00:07:17.412826117 +00:00 Epoch 120: Training Loss: 77.63863739281184, Validation Loss: 3.214045145108702
2024-07-23 00:07:59.710037490 +00:00 Epoch 121: Training Loss: 77.64165653173514, Validation Loss: 3.2298194219503724
2024-07-23 00:08:41.691121190 +00:00 Epoch 122: Training Loss: 77.63292939951235, Validation Loss: 3.213941312959478
2024-07-23 00:09:23.783535974 +00:00 Epoch 123: Training Loss: 77.65708113347684, Validation Loss: 3.2112877338212007
2024-07-23 00:10:06.154401711 +00:00 Epoch 124: Training Loss: 77.63618222182296, Validation Loss: 3.209880205318807
2024-07-23 00:10:48.734192950 +00:00 Epoch 125: Training Loss: 77.63252734414789, Validation Loss: 3.212692467603391
2024-07-23 00:11:31.432130004 +00:00 Epoch 126: Training Loss: 77.62553309513726, Validation Loss: 3.216259049032616
2024-07-23 00:12:14.142735860 +00:00 Epoch 127: Training Loss: 77.63759402269442, Validation Loss: 3.2228558325557146
2024-07-23 00:12:56.780700063 +00:00 Epoch 128: Training Loss: 77.63051708008432, Validation Loss: 3.2275955847118993
2024-07-23 00:13:38.903922105 +00:00 Epoch 129: Training Loss: 77.63889027159324, Validation Loss: 3.2196389996952237
2024-07-23 00:14:21.250047027 +00:00 Epoch 130: Training Loss: 77.63758274115865, Validation Loss: 3.214884537584233
2024-07-23 00:15:03.965947419 +00:00 Epoch 131: Training Loss: 77.63393064962357, Validation Loss: 3.2161280079823142
2024-07-23 00:15:46.174795909 +00:00 Epoch 132: Training Loss: 77.63024368522544, Validation Loss: 3.2338262937690088
2024-07-23 00:16:28.314507120 +00:00 Epoch 133: Training Loss: 77.64130009238981, Validation Loss: 3.2155991612702457
2024-07-23 00:17:10.462644360 +00:00 Epoch 134: Training Loss: 77.6373370966674, Validation Loss: 3.222969135532917
2024-07-23 00:17:52.589806017 +00:00 Epoch 135: Training Loss: 77.64172781310552, Validation Loss: 3.2237120221141367
2024-07-23 00:18:35.056168724 +00:00 Epoch 136: Training Loss: 77.62999201584616, Validation Loss: 3.216916154303955
2024-07-23 00:19:17.358017101 +00:00 Epoch 137: Training Loss: 77.63463273180577, Validation Loss: 3.245660138740111
2024-07-23 00:19:59.224960711 +00:00 Epoch 138: Training Loss: 77.63236930788972, Validation Loss: 3.2384731156001307
2024-07-23 00:20:41.233197979 +00:00 Epoch 139: Training Loss: 77.63578311015793, Validation Loss: 3.2148235034687644
2024-07-23 00:21:23.247363741 +00:00 Epoch 140: Training Loss: 77.63084461605801, Validation Loss: 3.2187204179327984
2024-07-23 00:22:05.134159125 +00:00 Epoch 141: Training Loss: 77.63412229283944, Validation Loss: 3.2129057535557006
2024-07-23 00:22:46.951492360 +00:00 Epoch 142: Training Loss: 77.64093196797201, Validation Loss: 3.2104934181335043
2024-07-23 00:23:28.965420773 +00:00 Epoch 143: Training Loss: 77.62884460715244, Validation Loss: 3.225136328481491
2024-07-23 00:24:11.192207686 +00:00 Epoch 144: Training Loss: 77.63809996782659, Validation Loss: 3.2258009748588576
2024-07-23 00:24:52.974129141 +00:00 Epoch 145: Training Loss: 77.6376340530634, Validation Loss: 3.226607112641062
2024-07-23 00:25:34.925246294 +00:00 Epoch 146: Training Loss: 77.6417573496665, Validation Loss: 3.2203143343973695
2024-07-23 00:26:16.764032157 +00:00 Epoch 147: Training Loss: 77.63295490382201, Validation Loss: 3.2184037919688393
2024-07-23 00:26:58.388606041 +00:00 Epoch 148: Training Loss: 77.62954131813692, Validation Loss: 3.2102094632579217
2024-07-23 00:27:40.172441988 +00:00 Epoch 149: Training Loss: 77.62976379524794, Validation Loss: 3.223034646089917
2024-07-23 00:28:22.341481032 +00:00 Epoch 150: Training Loss: 77.62709832309065, Validation Loss: 3.2108475825150236
2024-07-23 00:29:04.141086576 +00:00 Epoch 151: Training Loss: 77.6296504916596, Validation Loss: 3.2161089348777967
2024-07-23 00:29:46.035148718 +00:00 Epoch 152: Training Loss: 77.62835923344342, Validation Loss: 3.2134156372654665
2024-07-23 00:30:28.415702138 +00:00 Epoch 153: Training Loss: 77.6211348294845, Validation Loss: 3.2191468625505424
2024-07-23 00:31:10.681624043 +00:00 Epoch 154: Training Loss: 77.63284551089377, Validation Loss: 3.2146960287347444
2024-07-23 00:31:52.763561280 +00:00 Epoch 155: Training Loss: 77.63599367442043, Validation Loss: 3.2179757910646685
2024-07-23 00:32:34.772334223 +00:00 Epoch 156: Training Loss: 77.63265081830993, Validation Loss: 3.2197237216463104
2024-07-23 00:33:16.602105439 +00:00 Epoch 157: Training Loss: 77.6343662868893, Validation Loss: 3.2102538137919345
2024-07-23 00:33:58.758896884 +00:00 Epoch 158: Training Loss: 77.63848191891056, Validation Loss: 3.2235528246518683
2024-07-23 00:34:40.702704334 +00:00 Epoch 159: Training Loss: 77.62726476500502, Validation Loss: 3.220451009992638
2024-07-23 00:35:22.757649667 +00:00 Epoch 160: Training Loss: 77.6171966116231, Validation Loss: 3.2202306896215953
2024-07-23 00:36:04.602570545 +00:00 Epoch 161: Training Loss: 77.62334783937035, Validation Loss: 3.2120504033995774
2024-07-23 00:36:46.938114991 +00:00 Epoch 162: Training Loss: 77.6258421364129, Validation Loss: 3.219678558612097
2024-07-23 00:37:28.881758443 +00:00 Epoch 163: Training Loss: 77.63365690140087, Validation Loss: 3.2281277777156783
2024-07-23 00:38:11.078211878 +00:00 Epoch 164: Training Loss: 77.6313560654079, Validation Loss: 3.241400360548541
2024-07-23 00:38:52.893988182 +00:00 Epoch 165: Training Loss: 77.63672102321753, Validation Loss: 3.216824130415973
2024-07-23 00:39:34.702289602 +00:00 Epoch 166: Training Loss: 77.62218870114428, Validation Loss: 3.2129222997603497
2024-07-23 00:40:17.235542397 +00:00 Epoch 167: Training Loss: 77.63074102372659, Validation Loss: 3.222763899068455
2024-07-23 00:40:59.493253456 +00:00 Epoch 168: Training Loss: 77.64193970524983, Validation Loss: 3.2131194181387874
2024-07-23 00:41:41.581034839 +00:00 Epoch 169: Training Loss: 77.62671048768057, Validation Loss: 3.246586456941437
2024-07-23 00:42:23.669507823 +00:00 Epoch 170: Training Loss: 77.62178945648374, Validation Loss: 3.222957007346234
2024-07-23 00:43:05.805853230 +00:00 Epoch 171: Training Loss: 77.65998437236986, Validation Loss: 3.232619915533895
2024-07-23 00:43:48.583841143 +00:00 Epoch 172: Training Loss: 77.63215679637285, Validation Loss: 3.2156877153368515
2024-07-23 00:44:30.770058480 +00:00 Epoch 173: Training Loss: 77.62630081852697, Validation Loss: 3.215795943015453
2024-07-23 00:45:13.034757749 +00:00 Epoch 174: Training Loss: 77.62909653715381, Validation Loss: 3.216467211146482
2024-07-23 00:45:55.107727805 +00:00 Epoch 175: Training Loss: 77.61677403372269, Validation Loss: 3.233807854797745
2024-07-23 00:46:37.391863366 +00:00 Epoch 176: Training Loss: 77.61767932350463, Validation Loss: 3.2341343435465078
2024-07-23 00:47:19.691100056 +00:00 Epoch 177: Training Loss: 77.63311898918305, Validation Loss: 3.2232763860822162
2024-07-23 00:48:02.206845132 +00:00 Epoch 178: Training Loss: 77.62334081356349, Validation Loss: 3.2180375386502282
2024-07-23 00:48:44.229176638 +00:00 Epoch 179: Training Loss: 77.63511233044831, Validation Loss: 3.223318661466181
2024-07-23 00:49:26.320767652 +00:00 Epoch 180: Training Loss: 77.62603257432941, Validation Loss: 3.2179104008272894
2024-07-23 00:50:08.272408065 +00:00 Epoch 181: Training Loss: 77.64549126303116, Validation Loss: 3.214971999492699
2024-07-23 00:50:50.186175740 +00:00 Epoch 182: Training Loss: 77.63162835169226, Validation Loss: 3.218140715585987
2024-07-23 00:51:32.153208353 +00:00 Epoch 183: Training Loss: 77.62484164129167, Validation Loss: 3.217784044061678
2024-07-23 00:52:14.317966163 +00:00 Epoch 184: Training Loss: 77.62368993688153, Validation Loss: 3.221920803473624
2024-07-23 00:52:56.148315280 +00:00 Epoch 185: Training Loss: 77.63984767667462, Validation Loss: 3.214046014433911
2024-07-23 00:53:38.134552263 +00:00 Epoch 186: Training Loss: 77.63136470210914, Validation Loss: 3.2162123256092006
2024-07-23 00:54:20.350887401 +00:00 Epoch 187: Training Loss: 77.62928618867305, Validation Loss: 3.2429175402285177
2024-07-23 00:55:02.709837397 +00:00 Epoch 188: Training Loss: 77.63343916369526, Validation Loss: 3.2181042997636298
2024-07-23 00:55:45.142935567 +00:00 Epoch 189: Training Loss: 77.63422204916485, Validation Loss: 3.2505607997269728
2024-07-23 00:56:27.162481666 +00:00 Epoch 190: Training Loss: 77.62857766675609, Validation Loss: 3.2206946869760347
2024-07-23 00:57:09.177728225 +00:00 Epoch 191: Training Loss: 77.65234367747806, Validation Loss: 3.2417409456083357
2024-07-23 00:57:51.479607580 +00:00 Epoch 192: Training Loss: 77.63672642189952, Validation Loss: 3.237718004113674
2024-07-23 00:58:33.742535692 +00:00 Epoch 193: Training Loss: 77.64845971902834, Validation Loss: 3.2210889043686115
2024-07-23 00:59:16.005204613 +00:00 Epoch 194: Training Loss: 77.65452191792065, Validation Loss: 3.2313265560190434
2024-07-23 00:59:58.176425930 +00:00 Epoch 195: Training Loss: 77.66003591178061, Validation Loss: 3.2305869142821475
2024-07-23 01:00:41.420793964 +00:00 Epoch 196: Training Loss: 77.65542229977099, Validation Loss: 3.2437343362976265
2024-07-23 01:01:24.088515150 +00:00 Epoch 197: Training Loss: 77.65144886320181, Validation Loss: 3.233914888524248
2024-07-23 01:02:06.468398163 +00:00 Epoch 198: Training Loss: 77.6447254988517, Validation Loss: 3.2279394620282424
2024-07-23 01:02:49.409457813 +00:00 Epoch 199: Training Loss: 77.64891505171116, Validation Loss: 3.242818058273132
2024-07-23 01:03:31.874695666 +00:00 Epoch 200: Training Loss: 77.63723006898968, Validation Loss: 3.2173803051705896
2024-07-23 01:04:14.150624299 +00:00 Epoch 201: Training Loss: 77.64517831537775, Validation Loss: 3.2538798161451825
2024-07-23 01:04:56.145251967 +00:00 Epoch 202: Training Loss: 77.65328929401697, Validation Loss: 3.2405145820007752
2024-07-23 01:05:38.208095664 +00:00 Epoch 203: Training Loss: 77.6434488702643, Validation Loss: 3.2303603578789417
2024-07-23 01:06:20.766570846 +00:00 Epoch 204: Training Loss: 77.64497349672125, Validation Loss: 3.2153420969631417
2024-07-23 01:07:02.958486459 +00:00 Epoch 205: Training Loss: 77.64557712240851, Validation Loss: 3.2258593896586607
2024-07-23 01:07:45.283586353 +00:00 Epoch 206: Training Loss: 77.63190396976607, Validation Loss: 3.2154872829946877
2024-07-23 01:08:27.930744187 +00:00 Epoch 207: Training Loss: 77.64453316146917, Validation Loss: 3.2309332053860373
2024-07-23 01:09:10.262984060 +00:00 Epoch 208: Training Loss: 77.63344875682357, Validation Loss: 3.21832384563821
2024-07-23 01:09:52.300223148 +00:00 Epoch 209: Training Loss: 77.63864233255141, Validation Loss: 3.2173464535042533
2024-07-23 01:10:34.663807407 +00:00 Epoch 210: Training Loss: 77.64965533536346, Validation Loss: 3.222150897164377
2024-07-23 01:11:16.686609409 +00:00 Epoch 211: Training Loss: 77.6296919415187, Validation Loss: 3.216039232497014
2024-07-23 01:11:58.750749200 +00:00 Epoch 212: Training Loss: 77.64017453757306, Validation Loss: 3.2143662848573493
2024-07-23 01:12:40.849322036 +00:00 Epoch 213: Training Loss: 77.65301155902202, Validation Loss: 3.21769819133773
2024-07-23 01:13:23.251654582 +00:00 Epoch 214: Training Loss: 77.70623177156983, Validation Loss: 3.34014462314729
2024-07-23 01:14:05.658183249 +00:00 Epoch 215: Training Loss: 77.73886063443203, Validation Loss: 3.2347285504929415
2024-07-23 01:14:48.056401143 +00:00 Epoch 216: Training Loss: 77.69903501226042, Validation Loss: 3.22358952107135
2024-07-23 01:15:30.046754096 +00:00 Epoch 217: Training Loss: 77.6581717286139, Validation Loss: 3.237978164682802
2024-07-23 01:16:12.117626895 +00:00 Epoch 218: Training Loss: 77.6598535718165, Validation Loss: 3.216710154777484
2024-07-23 01:16:54.401562373 +00:00 Epoch 219: Training Loss: 77.65436023254256, Validation Loss: 3.218895865804143
2024-07-23 01:17:36.563428172 +00:00 Epoch 220: Training Loss: 77.6566401875663, Validation Loss: 3.2279547658954213
2024-07-23 01:18:18.823868312 +00:00 Epoch 221: Training Loss: 77.65687669734835, Validation Loss: 3.2144432260924485
2024-07-23 01:19:00.961331501 +00:00 Epoch 222: Training Loss: 77.67995656297933, Validation Loss: 3.20823008650728
2024-07-23 01:19:43.355729971 +00:00 Epoch 223: Training Loss: 77.64981606624698, Validation Loss: 3.2191119422734484
2024-07-23 01:20:25.370569112 +00:00 Epoch 224: Training Loss: 77.646612879958, Validation Loss: 3.214469366841389
2024-07-23 01:21:07.831711228 +00:00 Epoch 225: Training Loss: 77.64678009118484, Validation Loss: 3.242784525642267
2024-07-23 01:21:50.152505660 +00:00 Epoch 226: Training Loss: 77.63871173404002, Validation Loss: 3.217156035294128
2024-07-23 01:22:32.138858034 +00:00 Epoch 227: Training Loss: 77.65728146097476, Validation Loss: 3.241882456589296
2024-07-23 01:23:14.626339347 +00:00 Epoch 228: Training Loss: 77.646520624405, Validation Loss: 3.2139147971350313
2024-07-23 01:23:56.626678449 +00:00 Epoch 229: Training Loss: 77.64434770202047, Validation Loss: 3.222440830141917
2024-07-23 01:24:38.534477800 +00:00 Epoch 230: Training Loss: 77.64559661767902, Validation Loss: 3.2173797306128256
2024-07-23 01:25:20.517726434 +00:00 Epoch 231: Training Loss: 77.68112729803295, Validation Loss: 3.2128639335093423
2024-07-23 01:26:02.910919612 +00:00 Epoch 232: Training Loss: 77.63904953450283, Validation Loss: 3.2116310330579103
2024-07-23 01:26:44.977116564 +00:00 Epoch 233: Training Loss: 77.67328018276231, Validation Loss: 3.2147149910581967
2024-07-23 01:27:27.338227216 +00:00 Epoch 234: Training Loss: 77.65408182432563, Validation Loss: 3.2124546177862956
2024-07-23 01:28:09.865264459 +00:00 Epoch 235: Training Loss: 77.64114423438411, Validation Loss: 3.207787770566627
2024-07-23 01:28:51.714334433 +00:00 Epoch 236: Training Loss: 77.64172495031045, Validation Loss: 3.2128969271195107
2024-07-23 01:29:33.727660525 +00:00 Epoch 237: Training Loss: 77.63969797912726, Validation Loss: 3.210478116234811
2024-07-23 01:30:15.872001560 +00:00 Epoch 238: Training Loss: 77.64620509250106, Validation Loss: 3.2085413708881356
2024-07-23 01:30:58.574060108 +00:00 Epoch 239: Training Loss: 77.64658753485698, Validation Loss: 3.2393983639592077
2024-07-23 01:31:40.828863375 +00:00 Epoch 240: Training Loss: 77.65447995218312, Validation Loss: 3.210891032500507
2024-07-23 01:32:22.723556401 +00:00 Epoch 241: Training Loss: 77.6591502426283, Validation Loss: 3.2196367027940758
2024-07-23 01:33:04.501716414 +00:00 Epoch 242: Training Loss: 77.63877772740206, Validation Loss: 3.2288050629118015
2024-07-23 01:33:46.449445978 +00:00 Epoch 243: Training Loss: 77.64303616360938, Validation Loss: 3.217541620240575
2024-07-23 01:34:28.241208569 +00:00 Epoch 244: Training Loss: 77.64564866059914, Validation Loss: 3.224774097999741
2024-07-23 01:35:10.499908940 +00:00 Epoch 245: Training Loss: 77.64174792622222, Validation Loss: 3.238375617284224
2024-07-23 01:35:53.014951888 +00:00 Epoch 246: Training Loss: 77.64185400259161, Validation Loss: 3.219463938556003
2024-07-23 01:36:35.643548069 +00:00 Epoch 247: Training Loss: 77.64550047182371, Validation Loss: 3.2102969991746733
2024-07-23 01:37:18.091752553 +00:00 Epoch 248: Training Loss: 77.67846186789752, Validation Loss: 3.2264023852197434
2024-07-23 01:38:00.095899765 +00:00 Epoch 249: Training Loss: 77.63656484976073, Validation Loss: 3.2096058440560404
2024-07-23 01:38:42.456723424 +00:00 Epoch 250: Training Loss: 77.64128091940074, Validation Loss: 3.212115893224975
2024-07-23 01:38:42.500955093 +00:00 Extending knot vectors from 20 to 50
2024-07-23 01:39:54.807632968 +00:00 Epoch 251: Training Loss: 77.64845818004916, Validation Loss: 3.2120625979592585
2024-07-23 01:41:07.567003449 +00:00 Epoch 252: Training Loss: 77.65104120167328, Validation Loss: 3.205138780994893
2024-07-23 01:42:20.436734996 +00:00 Epoch 253: Training Loss: 77.66740611415769, Validation Loss: 3.202784484287817
2024-07-23 01:43:34.131084619 +00:00 Epoch 254: Training Loss: 77.65433995589478, Validation Loss: 3.2151345691810675
2024-07-23 01:44:47.297271356 +00:00 Epoch 255: Training Loss: 77.65673359673758, Validation Loss: 3.217158960012184
2024-07-23 01:45:59.577023395 +00:00 Epoch 256: Training Loss: 77.65721258704725, Validation Loss: 3.211312772654702
2024-07-23 01:47:11.837252431 +00:00 Epoch 257: Training Loss: 77.65306589170402, Validation Loss: 3.220592113389447
2024-07-23 01:48:24.372323045 +00:00 Epoch 258: Training Loss: 77.64961841857509, Validation Loss: 3.2151259718033556
2024-07-23 01:49:37.271242229 +00:00 Epoch 259: Training Loss: 77.66987174175141, Validation Loss: 3.2195443380128372
2024-07-23 01:50:49.994731982 +00:00 Epoch 260: Training Loss: 77.64519587031444, Validation Loss: 3.2224690642631
2024-07-23 01:52:03.155721983 +00:00 Epoch 261: Training Loss: 77.6606191171467, Validation Loss: 3.2218003038225436
2024-07-23 01:53:15.530632643 +00:00 Epoch 262: Training Loss: 77.66760096963326, Validation Loss: 3.2194453592547854
2024-07-23 01:54:27.844046697 +00:00 Epoch 263: Training Loss: 77.64877920798895, Validation Loss: 3.2106719107192903
2024-07-23 01:55:41.331309334 +00:00 Epoch 264: Training Loss: 77.64408567057355, Validation Loss: 3.2292423706322846
2024-07-23 01:56:54.607568006 +00:00 Epoch 265: Training Loss: 77.64775448588372, Validation Loss: 3.224214449544088
2024-07-23 01:58:06.732430083 +00:00 Epoch 266: Training Loss: 77.64453628028666, Validation Loss: 3.2252919491058605
2024-07-23 01:59:19.518745328 +00:00 Epoch 267: Training Loss: 77.64661720323114, Validation Loss: 3.227642748566743
2024-07-23 02:00:32.574277592 +00:00 Epoch 268: Training Loss: 77.64498199481092, Validation Loss: 3.2230210571820495
2024-07-23 02:01:45.624062647 +00:00 Epoch 269: Training Loss: 77.64207284179591, Validation Loss: 3.211141232126725
2024-07-23 02:02:58.673003079 +00:00 Epoch 270: Training Loss: 77.66662007264509, Validation Loss: 3.22803725602267
2024-07-23 02:04:12.456037338 +00:00 Epoch 271: Training Loss: 77.64387591045613, Validation Loss: 3.2210847772071802
2024-07-23 02:05:26.424860417 +00:00 Epoch 272: Training Loss: 77.64576145419676, Validation Loss: 3.2347817187910355
2024-07-23 02:06:39.771552517 +00:00 Epoch 273: Training Loss: 77.6452476495936, Validation Loss: 3.216200843082218
2024-07-23 02:07:52.560957516 +00:00 Epoch 274: Training Loss: 77.67469851385381, Validation Loss: 3.219931713445823
2024-07-23 02:09:04.934200127 +00:00 Epoch 275: Training Loss: 77.65265026311542, Validation Loss: 3.2298139851751184
2024-07-23 02:10:17.905163722 +00:00 Epoch 276: Training Loss: 77.65520562089148, Validation Loss: 3.2352527537979516
2024-07-23 02:11:30.703074736 +00:00 Epoch 277: Training Loss: 77.6423651114401, Validation Loss: 3.2199382903305933
2024-07-23 02:12:43.165847869 +00:00 Epoch 278: Training Loss: 77.63960158498543, Validation Loss: 3.2244998910857627
2024-07-23 02:13:55.437233301 +00:00 Epoch 279: Training Loss: 77.63933926150887, Validation Loss: 3.215207090809288
2024-07-23 02:15:07.849502805 +00:00 Epoch 280: Training Loss: 77.64310733557895, Validation Loss: 3.210514130276392
2024-07-23 02:16:20.927833116 +00:00 Epoch 281: Training Loss: 77.65118727019546, Validation Loss: 3.2112537521096725
2024-07-23 02:17:33.526783258 +00:00 Epoch 282: Training Loss: 77.64864121402893, Validation Loss: 3.211045099002798
2024-07-23 02:18:46.276313432 +00:00 Epoch 283: Training Loss: 77.6452845421868, Validation Loss: 3.234959311834138
2024-07-23 02:19:58.784078804 +00:00 Epoch 284: Training Loss: 77.67604596037818, Validation Loss: 3.213034903350503
2024-07-23 02:21:12.282093545 +00:00 Epoch 285: Training Loss: 77.64554445495915, Validation Loss: 3.2147452901278353
2024-07-23 02:22:26.506150862 +00:00 Epoch 286: Training Loss: 77.66734797280662, Validation Loss: 3.222201563423034
2024-07-23 02:23:40.500269860 +00:00 Epoch 287: Training Loss: 77.64459495001357, Validation Loss: 3.2115950088818392
2024-07-23 02:24:53.925329718 +00:00 Epoch 288: Training Loss: 77.66846033944843, Validation Loss: 3.228950343880086
2024-07-23 02:26:07.561406029 +00:00 Epoch 289: Training Loss: 77.64470990774672, Validation Loss: 3.2143841981324455
2024-07-23 02:27:21.212215920 +00:00 Epoch 290: Training Loss: 77.63910684680779, Validation Loss: 3.2108584089420016
2024-07-23 02:28:35.478083247 +00:00 Epoch 291: Training Loss: 77.67463796916131, Validation Loss: 3.2175633975827678
2024-07-23 02:29:50.113611516 +00:00 Epoch 292: Training Loss: 77.6583601986225, Validation Loss: 3.245705121206695
2024-07-23 02:31:06.533994092 +00:00 Epoch 293: Training Loss: 77.6823373427881, Validation Loss: 3.243237761554142
2024-07-23 02:32:19.578654577 +00:00 Epoch 294: Training Loss: 77.64895949376302, Validation Loss: 3.2168580069715764
2024-07-23 02:33:32.579667217 +00:00 Epoch 295: Training Loss: 77.6504849919988, Validation Loss: 3.223910886495923
2024-07-23 02:34:45.638191025 +00:00 Epoch 296: Training Loss: 77.66154543542306, Validation Loss: 3.2229959546129816
2024-07-23 02:35:59.211746147 +00:00 Epoch 297: Training Loss: 77.6562408997603, Validation Loss: 3.2146515818050045
2024-07-23 02:37:12.928855034 +00:00 Epoch 298: Training Loss: 77.64302213326962, Validation Loss: 3.2172345838468375
2024-07-23 02:38:26.289227574 +00:00 Epoch 299: Training Loss: 77.66376861732071, Validation Loss: 3.226934337021666
2024-07-23 02:39:38.726232118 +00:00 Epoch 300: Training Loss: 77.64244104505181, Validation Loss: 3.231439222624652
2024-07-23 02:40:51.072750144 +00:00 Epoch 301: Training Loss: 77.6415143923308, Validation Loss: 3.215780669892303
2024-07-23 02:42:02.950836527 +00:00 Epoch 302: Training Loss: 77.64536792501008, Validation Loss: 3.212719840271075
2024-07-23 02:43:15.069500437 +00:00 Epoch 303: Training Loss: 77.64330405768393, Validation Loss: 3.2138461984932447
2024-07-23 02:44:27.139521613 +00:00 Epoch 304: Training Loss: 77.64447776744738, Validation Loss: 3.2152216508597005
2024-07-23 02:45:39.177434449 +00:00 Epoch 305: Training Loss: 77.63838221540888, Validation Loss: 3.208264195953431
2024-07-23 02:46:51.391184522 +00:00 Epoch 306: Training Loss: 77.63853916422961, Validation Loss: 3.2067769290140986
2024-07-23 02:48:03.415011994 +00:00 Epoch 307: Training Loss: 77.6542645935647, Validation Loss: 3.2141891298777185
2024-07-23 02:49:15.612594832 +00:00 Epoch 308: Training Loss: 77.6393499471614, Validation Loss: 3.2215074370191434
2024-07-23 02:50:28.337301585 +00:00 Epoch 309: Training Loss: 77.64329660692583, Validation Loss: 3.204027770043623
2024-07-23 02:51:40.914303462 +00:00 Epoch 310: Training Loss: 77.6473254543968, Validation Loss: 3.2013959823634095
2024-07-23 02:52:53.287922681 +00:00 Epoch 311: Training Loss: 77.6543352317565, Validation Loss: 3.252460790741117
2024-07-23 02:54:05.497844073 +00:00 Epoch 312: Training Loss: 77.63783079506395, Validation Loss: 3.210230835717362
2024-07-23 02:55:17.553795439 +00:00 Epoch 313: Training Loss: 77.64077872004619, Validation Loss: 3.213400691948283
2024-07-23 02:56:29.968979277 +00:00 Epoch 314: Training Loss: 77.63849158709814, Validation Loss: 3.2060688919895552
2024-07-23 02:57:42.041545626 +00:00 Epoch 315: Training Loss: 77.6414604687034, Validation Loss: 3.2131487918554433
2024-07-23 02:58:54.048186300 +00:00 Epoch 316: Training Loss: 77.6417753564995, Validation Loss: 3.20922137934442
2024-07-23 03:00:06.193120077 +00:00 Epoch 317: Training Loss: 77.64070534746749, Validation Loss: 3.2118365293000064
2024-07-23 03:01:19.252417745 +00:00 Epoch 318: Training Loss: 77.62835716902279, Validation Loss: 3.207621758773397
2024-07-23 03:02:31.243428375 +00:00 Epoch 319: Training Loss: 77.64199763128484, Validation Loss: 3.206170564557707
2024-07-23 03:03:43.575382122 +00:00 Epoch 320: Training Loss: 77.64130106889291, Validation Loss: 3.2158060860487376
2024-07-23 03:04:55.892969747 +00:00 Epoch 321: Training Loss: 77.63651522977672, Validation Loss: 3.2042387753318753
2024-07-23 03:06:08.150430938 +00:00 Epoch 322: Training Loss: 77.63873502116908, Validation Loss: 3.21008174140161
2024-07-23 03:07:20.182446502 +00:00 Epoch 323: Training Loss: 77.66396451291199, Validation Loss: 3.210106463800231
2024-07-23 03:08:33.172967271 +00:00 Epoch 324: Training Loss: 77.63677537247838, Validation Loss: 3.219547898051864
2024-07-23 03:09:45.523958 +00:00 Epoch 325: Training Loss: 77.64581179864489, Validation Loss: 3.2051412364455762
2024-07-23 03:10:58.186805575 +00:00 Epoch 326: Training Loss: 77.64279636756604, Validation Loss: 3.213997093387089
2024-07-23 03:12:10.655245284 +00:00 Epoch 327: Training Loss: 77.65046126623115, Validation Loss: 3.2167608266137946
2024-07-23 03:13:22.822129461 +00:00 Epoch 328: Training Loss: 77.63743031290831, Validation Loss: 3.214940789042232
2024-07-23 03:14:35.339103245 +00:00 Epoch 329: Training Loss: 77.64728174764866, Validation Loss: 3.2373598616269113
2024-07-23 03:15:48.169640446 +00:00 Epoch 330: Training Loss: 77.64126543643195, Validation Loss: 3.2189094556551883
2024-07-23 03:17:01.083721574 +00:00 Epoch 331: Training Loss: 77.67646685394426, Validation Loss: 3.22491879615375
2024-07-23 03:18:14.649965312 +00:00 Epoch 332: Training Loss: 77.65590128510429, Validation Loss: 3.2034108967755124
2024-07-23 03:19:27.695675738 +00:00 Epoch 333: Training Loss: 77.67177083245451, Validation Loss: 3.2071473630731067
2024-07-23 03:20:40.496894330 +00:00 Epoch 334: Training Loss: 77.64444421497863, Validation Loss: 3.210181510102087
2024-07-23 03:21:53.067608114 +00:00 Epoch 335: Training Loss: 77.64264997060249, Validation Loss: 3.2099573315311725
2024-07-23 03:23:05.820806242 +00:00 Epoch 336: Training Loss: 77.6690067100691, Validation Loss: 3.211632588858745
2024-07-23 03:24:18.754767603 +00:00 Epoch 337: Training Loss: 77.65078398541208, Validation Loss: 3.208784076758862
2024-07-23 03:25:31.807383307 +00:00 Epoch 338: Training Loss: 77.64871068655604, Validation Loss: 3.2278951154819278
2024-07-23 03:26:44.251300157 +00:00 Epoch 339: Training Loss: 77.6364650313446, Validation Loss: 3.20487939456427
2024-07-23 03:27:56.597261801 +00:00 Epoch 340: Training Loss: 77.64834092173874, Validation Loss: 3.2115768513352605
2024-07-23 03:29:09.509988663 +00:00 Epoch 341: Training Loss: 77.6361547585155, Validation Loss: 3.2076191467588244
2024-07-23 03:30:22.554678871 +00:00 Epoch 342: Training Loss: 77.64871307583608, Validation Loss: 3.2069744751215645
2024-07-23 03:31:35.838846273 +00:00 Epoch 343: Training Loss: 77.64109882414186, Validation Loss: 3.211579554551047
2024-07-23 03:32:48.937265876 +00:00 Epoch 344: Training Loss: 77.67049146476798, Validation Loss: 3.219976590928025
2024-07-23 03:34:01.416631606 +00:00 Epoch 345: Training Loss: 77.63916757889248, Validation Loss: 3.202803550412142
2024-07-23 03:35:13.622281624 +00:00 Epoch 346: Training Loss: 77.63863511345443, Validation Loss: 3.2054311468383876
2024-07-23 03:36:25.893003136 +00:00 Epoch 347: Training Loss: 77.64093143030563, Validation Loss: 3.22441670875105
2024-07-23 03:37:37.965811881 +00:00 Epoch 348: Training Loss: 77.64026819149609, Validation Loss: 3.220839516431553
2024-07-23 03:38:51.286579632 +00:00 Epoch 349: Training Loss: 77.64186434452894, Validation Loss: 3.2055624986728875
2024-07-23 03:40:04.395908096 +00:00 Epoch 350: Training Loss: 77.6447371853125, Validation Loss: 3.20995874133808
2024-07-23 03:41:16.834052964 +00:00 Epoch 351: Training Loss: 77.64123361930992, Validation Loss: 3.202175450849505
2024-07-23 03:42:28.965548224 +00:00 Epoch 352: Training Loss: 77.64461331054905, Validation Loss: 3.2031316491803703
2024-07-23 03:43:40.990858709 +00:00 Epoch 353: Training Loss: 77.63512867612107, Validation Loss: 3.208648814621637
2024-07-23 03:44:53.341508279 +00:00 Epoch 354: Training Loss: 77.63953069808083, Validation Loss: 3.2063094293914
2024-07-23 03:46:06.005869149 +00:00 Epoch 355: Training Loss: 77.64075484059165, Validation Loss: 3.205978431257234
2024-07-23 03:47:18.019406436 +00:00 Epoch 356: Training Loss: 77.6377043924139, Validation Loss: 3.208864694915035
2024-07-23 03:48:29.894850469 +00:00 Epoch 357: Training Loss: 77.64041453512844, Validation Loss: 3.2221057461531726
2024-07-23 03:49:42.158324034 +00:00 Epoch 358: Training Loss: 77.64062873747812, Validation Loss: 3.2158751845715114
2024-07-23 03:50:54.709236559 +00:00 Epoch 359: Training Loss: 77.6480967297375, Validation Loss: 3.2070840525286153
2024-07-23 03:52:07.188852985 +00:00 Epoch 360: Training Loss: 77.63516945526648, Validation Loss: 3.212837347538457
2024-07-23 03:53:19.110181948 +00:00 Epoch 361: Training Loss: 77.64095778367584, Validation Loss: 3.2179662126760165
2024-07-23 03:54:31.180964235 +00:00 Epoch 362: Training Loss: 77.63577119517697, Validation Loss: 3.2075527663634773
2024-07-23 03:55:43.662259195 +00:00 Epoch 363: Training Loss: 77.63715787073568, Validation Loss: 3.21237145077586
2024-07-23 03:56:56.211835783 +00:00 Epoch 364: Training Loss: 77.63819405446536, Validation Loss: 3.2064507096873824
2024-07-23 03:58:08.585637527 +00:00 Epoch 365: Training Loss: 77.63435112726016, Validation Loss: 3.213129284775645
2024-07-23 03:59:20.466941989 +00:00 Epoch 366: Training Loss: 77.63515495578258, Validation Loss: 3.2074129833009475
2024-07-23 04:00:33.664305518 +00:00 Epoch 367: Training Loss: 77.63745908039334, Validation Loss: 3.2100621855779234
2024-07-23 04:01:46.247339833 +00:00 Epoch 368: Training Loss: 77.63977492308501, Validation Loss: 3.207571642684519
2024-07-23 04:02:58.643801031 +00:00 Epoch 369: Training Loss: 77.63768985347426, Validation Loss: 3.2179042456978246
2024-07-23 04:04:10.527070235 +00:00 Epoch 370: Training Loss: 77.6374926917772, Validation Loss: 3.203095265577181
2024-07-23 04:05:22.406888727 +00:00 Epoch 371: Training Loss: 77.64402778844088, Validation Loss: 3.2061444971102113
2024-07-23 04:06:34.570936418 +00:00 Epoch 372: Training Loss: 77.63262419604607, Validation Loss: 3.20534559099246
2024-07-23 04:07:46.935997312 +00:00 Epoch 373: Training Loss: 77.65108195358665, Validation Loss: 3.2087654266341668
2024-07-23 04:08:59.467069638 +00:00 Epoch 374: Training Loss: 77.63771583718169, Validation Loss: 3.2022367540294794
2024-07-23 04:10:11.300498753 +00:00 Epoch 375: Training Loss: 77.63793013645814, Validation Loss: 3.220187653204438
2024-07-23 04:11:23.771950770 +00:00 Epoch 376: Training Loss: 77.64228074039868, Validation Loss: 3.2082514408510154
2024-07-23 04:12:36.283214094 +00:00 Epoch 377: Training Loss: 77.64967776437422, Validation Loss: 3.207198626105091
2024-07-23 04:13:49.018862983 +00:00 Epoch 378: Training Loss: 77.63715651835017, Validation Loss: 3.204231202581353
2024-07-23 04:15:01.702681068 +00:00 Epoch 379: Training Loss: 77.63455169837275, Validation Loss: 3.206368509559002
2024-07-23 04:16:14.042903115 +00:00 Epoch 380: Training Loss: 77.63449248806728, Validation Loss: 3.202068341164053
2024-07-23 04:17:26.172427711 +00:00 Epoch 381: Training Loss: 77.63596050124552, Validation Loss: 3.2028177391682484
2024-07-23 04:18:37.867677123 +00:00 Epoch 382: Training Loss: 77.63501591478685, Validation Loss: 3.205088780356499
2024-07-23 04:19:49.401871538 +00:00 Epoch 383: Training Loss: 77.63688672935588, Validation Loss: 3.2140627211751562
2024-07-23 04:21:01.274133787 +00:00 Epoch 384: Training Loss: 77.63673272620309, Validation Loss: 3.201698019124827
2024-07-23 04:22:13.176533328 +00:00 Epoch 385: Training Loss: 77.66649649728296, Validation Loss: 3.2047136783088743
2024-07-23 04:23:25.267556449 +00:00 Epoch 386: Training Loss: 77.63636038647881, Validation Loss: 3.2199995124030805
2024-07-23 04:24:37.277417525 +00:00 Epoch 387: Training Loss: 77.63407824097224, Validation Loss: 3.214165433899977
2024-07-23 04:25:49.213466286 +00:00 Epoch 388: Training Loss: 77.63457560786212, Validation Loss: 3.2030706972042053
2024-07-23 04:27:01.062441422 +00:00 Epoch 389: Training Loss: 77.6333102113526, Validation Loss: 3.223140494587461
2024-07-23 04:28:13.251762735 +00:00 Epoch 390: Training Loss: 77.63423057492312, Validation Loss: 3.2031215150737946
2024-07-23 04:29:25.508921012 +00:00 Epoch 391: Training Loss: 77.63551046092587, Validation Loss: 3.205317486317962
2024-07-23 04:30:37.731700781 +00:00 Epoch 392: Training Loss: 77.63192617973303, Validation Loss: 3.217360805789608
2024-07-23 04:31:49.761499068 +00:00 Epoch 393: Training Loss: 77.65041579104951, Validation Loss: 3.2033434011546817
2024-07-23 04:33:01.647832359 +00:00 Epoch 394: Training Loss: 77.64054670656863, Validation Loss: 3.2251077158855628
2024-07-23 04:34:13.665231152 +00:00 Epoch 395: Training Loss: 77.63673487263311, Validation Loss: 3.2156341442399023
2024-07-23 04:35:25.064161703 +00:00 Epoch 396: Training Loss: 77.63904663547514, Validation Loss: 3.20312139474398
2024-07-23 04:36:37.017775435 +00:00 Epoch 397: Training Loss: 77.63342146865328, Validation Loss: 3.2136527757722555
2024-07-23 04:37:48.424028374 +00:00 Epoch 398: Training Loss: 77.64357786936658, Validation Loss: 3.2045182916083688
2024-07-23 04:39:00.691574958 +00:00 Epoch 399: Training Loss: 77.6438021158737, Validation Loss: 3.207700328646801
2024-07-23 04:40:12.447135210 +00:00 Epoch 400: Training Loss: 77.67225152614512, Validation Loss: 3.2084469468889973
2024-07-23 04:41:24.091888969 +00:00 Epoch 401: Training Loss: 77.63963539506831, Validation Loss: 3.2061602264357867
2024-07-23 04:42:35.604635050 +00:00 Epoch 402: Training Loss: 77.64401292674981, Validation Loss: 3.2022175038340928
2024-07-23 04:43:46.954045027 +00:00 Epoch 403: Training Loss: 77.63397144353726, Validation Loss: 3.208243559568227
2024-07-23 04:44:58.457641403 +00:00 Epoch 404: Training Loss: 77.63815075776188, Validation Loss: 3.210036650258236
2024-07-23 04:46:10.127337371 +00:00 Epoch 405: Training Loss: 77.64418025051812, Validation Loss: 3.212932468684422
2024-07-23 04:47:21.686150764 +00:00 Epoch 406: Training Loss: 77.64467408998249, Validation Loss: 3.2210032087497273
2024-07-23 04:48:33.233177467 +00:00 Epoch 407: Training Loss: 77.64443947281791, Validation Loss: 3.2130593884275584
2024-07-23 04:49:44.733342833 +00:00 Epoch 408: Training Loss: 77.63484462530045, Validation Loss: 3.214677165553581
2024-07-23 04:50:55.987800116 +00:00 Epoch 409: Training Loss: 77.64292659630048, Validation Loss: 3.2048229155684145
2024-07-23 04:52:07.274397122 +00:00 Epoch 410: Training Loss: 77.64454356123827, Validation Loss: 3.241240751554199
2024-07-23 04:53:18.824865122 +00:00 Epoch 411: Training Loss: 77.65647845235418, Validation Loss: 3.215207302558191
2024-07-23 04:54:30.354944091 +00:00 Epoch 412: Training Loss: 77.63527593867155, Validation Loss: 3.2067312764491094
2024-07-23 04:55:41.948276672 +00:00 Epoch 413: Training Loss: 77.63356263364857, Validation Loss: 3.2147395923819073
2024-07-23 04:56:53.720170198 +00:00 Epoch 414: Training Loss: 77.64018397007892, Validation Loss: 3.213250112944391
2024-07-23 04:58:05.022347793 +00:00 Epoch 415: Training Loss: 77.63440865612819, Validation Loss: 3.2079980340966183
2024-07-23 04:59:16.296846003 +00:00 Epoch 416: Training Loss: 77.63491985237691, Validation Loss: 3.205800951826024
2024-07-23 05:00:28.059463584 +00:00 Epoch 417: Training Loss: 77.63679175365324, Validation Loss: 3.214332492956286
2024-07-23 05:01:39.650972630 +00:00 Epoch 418: Training Loss: 77.63559569694964, Validation Loss: 3.20543111212679
2024-07-23 05:02:50.638232638 +00:00 Epoch 419: Training Loss: 77.63937705924427, Validation Loss: 3.2077897087610707
2024-07-23 05:04:02.635490311 +00:00 Epoch 420: Training Loss: 77.64230111003016, Validation Loss: 3.204880337363835
2024-07-23 05:05:14.137754052 +00:00 Epoch 421: Training Loss: 77.6354378691323, Validation Loss: 3.2158551079523376
2024-07-23 05:06:26.130216670 +00:00 Epoch 422: Training Loss: 77.63644746861532, Validation Loss: 3.2371193228069473
2024-07-23 05:07:39.235742986 +00:00 Epoch 423: Training Loss: 77.66747155473593, Validation Loss: 3.2122252728252696
2024-07-23 05:08:51.953376641 +00:00 Epoch 424: Training Loss: 77.63966952351102, Validation Loss: 3.2149222452529744
2024-07-23 05:10:04.593048562 +00:00 Epoch 425: Training Loss: 77.63831209269513, Validation Loss: 3.204092347383717
2024-07-23 05:11:16.201236520 +00:00 Epoch 426: Training Loss: 77.63464176817608, Validation Loss: 3.2116417335049094
2024-07-23 05:12:28.033707770 +00:00 Epoch 427: Training Loss: 77.63844988272196, Validation Loss: 3.2078626986340053
2024-07-23 05:13:43.522450588 +00:00 Epoch 428: Training Loss: 77.63800483655426, Validation Loss: 3.2086223706216095
2024-07-23 05:15:00.951527185 +00:00 Epoch 429: Training Loss: 77.63657342481586, Validation Loss: 3.23383118002346
2024-07-23 05:16:19.043359355 +00:00 Epoch 430: Training Loss: 77.64063661476472, Validation Loss: 3.2053293598083448
2024-07-23 05:17:36.134628796 +00:00 Epoch 431: Training Loss: 77.63683152203546, Validation Loss: 3.2213220447445625
2024-07-23 05:18:53.614978970 +00:00 Epoch 432: Training Loss: 77.63866281451884, Validation Loss: 3.208326535710861
2024-07-23 05:20:09.873382819 +00:00 Epoch 433: Training Loss: 77.64408470693975, Validation Loss: 3.206576882328525
2024-07-23 05:21:28.114831234 +00:00 Epoch 434: Training Loss: 77.66910532987512, Validation Loss: 3.213146324114322
2024-07-23 05:22:45.621187545 +00:00 Epoch 435: Training Loss: 77.63486791465903, Validation Loss: 3.2142175201819065
2024-07-23 05:24:02.398050036 +00:00 Epoch 436: Training Loss: 77.63742061452177, Validation Loss: 3.212997941776868
2024-07-23 05:25:17.998693395 +00:00 Epoch 437: Training Loss: 77.6401730412093, Validation Loss: 3.214885518462746
2024-07-23 05:26:33.637359809 +00:00 Epoch 438: Training Loss: 77.63685381136719, Validation Loss: 3.2044432021438944
2024-07-23 05:27:47.859726231 +00:00 Epoch 439: Training Loss: 77.64399038794171, Validation Loss: 3.2132004554599622
2024-07-23 05:29:00.443255593 +00:00 Epoch 440: Training Loss: 77.63831365790752, Validation Loss: 3.202669855998067
2024-07-23 05:30:12.253085078 +00:00 Epoch 441: Training Loss: 77.65483566591375, Validation Loss: 3.222819247810917
2024-07-23 05:31:24.988124374 +00:00 Epoch 442: Training Loss: 77.63481763132822, Validation Loss: 3.2080053915618527
2024-07-23 05:32:37.686547265 +00:00 Epoch 443: Training Loss: 77.63948794984111, Validation Loss: 3.223893855947823
2024-07-23 05:33:49.939312668 +00:00 Epoch 444: Training Loss: 77.63663829842166, Validation Loss: 3.2009752673684213
2024-07-23 05:35:01.230368403 +00:00 Epoch 445: Training Loss: 77.63859609890253, Validation Loss: 3.2293424084616293
2024-07-23 05:36:12.273839829 +00:00 Epoch 446: Training Loss: 77.6340474198405, Validation Loss: 3.2198416643146097
2024-07-23 05:37:24.920523520 +00:00 Epoch 447: Training Loss: 77.66769710179138, Validation Loss: 3.2093671933615906
2024-07-23 05:38:38.048361280 +00:00 Epoch 448: Training Loss: 77.66377583594505, Validation Loss: 3.210709401276062
2024-07-23 05:39:49.988420868 +00:00 Epoch 449: Training Loss: 77.64851709368064, Validation Loss: 3.206279976369305
2024-07-23 05:41:01.447044667 +00:00 Epoch 450: Training Loss: 77.63747466760299, Validation Loss: 3.2040570281611456
2024-07-23 05:42:12.725491572 +00:00 Epoch 451: Training Loss: 77.6507238962177, Validation Loss: 3.2311637126744133
2024-07-23 05:43:26.030404039 +00:00 Epoch 452: Training Loss: 77.63922095993253, Validation Loss: 3.2072268240015656
2024-07-23 05:44:41.430443033 +00:00 Epoch 453: Training Loss: 77.64384903960466, Validation Loss: 3.2208415583803753
2024-07-23 05:45:58.797729099 +00:00 Epoch 454: Training Loss: 77.64098541629336, Validation Loss: 3.2036127391868305
2024-07-23 05:47:14.831541911 +00:00 Epoch 455: Training Loss: 77.6440753795778, Validation Loss: 3.206339936392875
2024-07-23 05:48:31.875803871 +00:00 Epoch 456: Training Loss: 77.64128023177187, Validation Loss: 3.2132467706481354
2024-07-23 05:49:49.030400888 +00:00 Epoch 457: Training Loss: 77.6434715758381, Validation Loss: 3.2134207159627044
2024-07-23 05:51:06.436456664 +00:00 Epoch 458: Training Loss: 77.6668404718568, Validation Loss: 3.2030560014348652
2024-07-23 05:52:23.135912495 +00:00 Epoch 459: Training Loss: 77.6419185724211, Validation Loss: 3.20100129013921
2024-07-23 05:53:39.844137125 +00:00 Epoch 460: Training Loss: 77.63659130995838, Validation Loss: 3.213596984832801
2024-07-23 05:54:56.865973559 +00:00 Epoch 461: Training Loss: 77.6363356160661, Validation Loss: 3.2084169369147495
2024-07-23 05:56:13.891382133 +00:00 Epoch 462: Training Loss: 77.6351642536112, Validation Loss: 3.205245712893807
2024-07-23 05:57:30.596680124 +00:00 Epoch 463: Training Loss: 77.63867764335406, Validation Loss: 3.2163968995454
2024-07-23 05:58:47.190636120 +00:00 Epoch 464: Training Loss: 77.63420795410575, Validation Loss: 3.208680209832811
2024-07-23 06:00:02.732035143 +00:00 Epoch 465: Training Loss: 77.63852588857954, Validation Loss: 3.20827129633199
2024-07-23 06:01:19.600838513 +00:00 Epoch 466: Training Loss: 77.63464299299481, Validation Loss: 3.221790587538662
2024-07-23 06:02:35.002124832 +00:00 Epoch 467: Training Loss: 77.6367066075543, Validation Loss: 3.212923711147055
2024-07-23 06:03:47.226376795 +00:00 Epoch 468: Training Loss: 77.63566421927811, Validation Loss: 3.2138639122104493
2024-07-23 06:04:59.141933039 +00:00 Epoch 469: Training Loss: 77.66762623900796, Validation Loss: 3.213662259082582
2024-07-23 06:06:10.976431535 +00:00 Epoch 470: Training Loss: 77.64214161940707, Validation Loss: 3.205505919913445
2024-07-23 06:07:23.079385593 +00:00 Epoch 471: Training Loss: 77.63772649457384, Validation Loss: 3.20241306294139
2024-07-23 06:08:35.805603543 +00:00 Epoch 472: Training Loss: 77.64307508822374, Validation Loss: 3.2035623565981055
2024-07-23 06:09:48.707246172 +00:00 Epoch 473: Training Loss: 77.64153552897518, Validation Loss: 3.2057252180844964
2024-07-23 06:11:02.452322602 +00:00 Epoch 474: Training Loss: 77.63634685985556, Validation Loss: 3.208081676665881
2024-07-23 06:12:15.988837117 +00:00 Epoch 475: Training Loss: 77.63967789162659, Validation Loss: 3.2105993917522127
2024-07-23 06:13:27.409007743 +00:00 Epoch 476: Training Loss: 77.6359135569928, Validation Loss: 3.2062410334779763
2024-07-23 06:14:40.424358651 +00:00 Epoch 477: Training Loss: 77.63709947412787, Validation Loss: 3.2052468542121764
2024-07-23 06:15:53.621159288 +00:00 Epoch 478: Training Loss: 77.6351126184542, Validation Loss: 3.202010091100297
2024-07-23 06:17:06.328372367 +00:00 Epoch 479: Training Loss: 77.64400696723195, Validation Loss: 3.2077719128128557
2024-07-23 06:18:19.406731291 +00:00 Epoch 480: Training Loss: 77.63632821315048, Validation Loss: 3.206967559745938
2024-07-23 06:19:31.661813601 +00:00 Epoch 481: Training Loss: 77.63436107398618, Validation Loss: 3.202801349883053
2024-07-23 06:20:44.832708252 +00:00 Epoch 482: Training Loss: 77.63934565925425, Validation Loss: 3.201565789796738
2024-07-23 06:21:58.254048690 +00:00 Epoch 483: Training Loss: 77.67112785085001, Validation Loss: 3.21055418403411
2024-07-23 06:23:10.392966262 +00:00 Epoch 484: Training Loss: 77.64353438133892, Validation Loss: 3.201785449360095
2024-07-23 06:24:21.807282236 +00:00 Epoch 485: Training Loss: 77.64306216142359, Validation Loss: 3.201867523855891
2024-07-23 06:25:34.259135924 +00:00 Epoch 486: Training Loss: 77.64132824862182, Validation Loss: 3.2034628312065863
2024-07-23 06:26:45.939097905 +00:00 Epoch 487: Training Loss: 77.63852630899895, Validation Loss: 3.2090112054125783
2024-07-23 06:27:57.229089144 +00:00 Epoch 488: Training Loss: 77.63839888865542, Validation Loss: 3.226186026878927
2024-07-23 06:29:08.607882186 +00:00 Epoch 489: Training Loss: 77.63539903807688, Validation Loss: 3.2087725921470476
2024-07-23 06:30:20.103543533 +00:00 Epoch 490: Training Loss: 77.63736867679916, Validation Loss: 3.2279126623513035
2024-07-23 06:31:32.620752323 +00:00 Epoch 491: Training Loss: 77.6351965307045, Validation Loss: 3.2034718989258275
2024-07-23 06:32:46.930585355 +00:00 Epoch 492: Training Loss: 77.64190285906552, Validation Loss: 3.211734697137114
2024-07-23 06:33:59.576801534 +00:00 Epoch 493: Training Loss: 77.63372816611525, Validation Loss: 3.207172775542817
2024-07-23 06:35:11.306318735 +00:00 Epoch 494: Training Loss: 77.63434685632018, Validation Loss: 3.2062806031182984
2024-07-23 06:36:23.961219977 +00:00 Epoch 495: Training Loss: 77.63847067909647, Validation Loss: 3.2078840867911995
2024-07-23 06:37:36.719100402 +00:00 Epoch 496: Training Loss: 77.65542940547427, Validation Loss: 3.213685473437294
2024-07-23 06:38:53.610405260 +00:00 Epoch 497: Training Loss: 77.63335692860868, Validation Loss: 3.216762461121695
2024-07-23 06:40:09.610960532 +00:00 Epoch 498: Training Loss: 77.63570791537502, Validation Loss: 3.2073010765701686
2024-07-23 06:41:27.018210830 +00:00 Epoch 499: Training Loss: 77.63518047215008, Validation Loss: 3.2227852398576404
2024-07-23 06:42:44.401543532 +00:00 Epoch 500: Training Loss: 77.64339741814612, Validation Loss: 3.213887342970836
